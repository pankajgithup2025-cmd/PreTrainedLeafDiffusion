{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d9iwlBR9kBW",
        "outputId": "17f7cd30-b350-442d-e6d7-45f25d369e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGFQ20hCPfwi",
        "outputId": "f3226612-cae0-4be1-f204-d72e6b9a1e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🚀 Starting Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1] - Total Loss: 1.1535: 100%|██████████| 24/24 [00:18<00:00,  1.27it/s]\n",
            "Epoch [2] - Total Loss: 1.1019: 100%|██████████| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [3] - Total Loss: 1.0819: 100%|██████████| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [4] - Total Loss: 1.0183: 100%|██████████| 24/24 [00:01<00:00, 17.66it/s]\n",
            "Epoch [5] - Total Loss: 1.0287: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [6] - Total Loss: 1.0188: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [7] - Total Loss: 1.0167: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [8] - Total Loss: 1.0604: 100%|██████████| 24/24 [00:01<00:00, 17.49it/s]\n",
            "Epoch [9] - Total Loss: 1.0642: 100%|██████████| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [10] - Total Loss: 1.0355: 100%|██████████| 24/24 [00:01<00:00, 17.52it/s]\n",
            "Epoch [11] - Total Loss: 1.0544: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [12] - Total Loss: 1.0293: 100%|██████████| 24/24 [00:01<00:00, 17.56it/s]\n",
            "Epoch [13] - Total Loss: 1.0341: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [14] - Total Loss: 1.0313: 100%|██████████| 24/24 [00:01<00:00, 17.44it/s]\n",
            "Epoch [15] - Total Loss: 1.0350: 100%|██████████| 24/24 [00:01<00:00, 17.55it/s]\n",
            "Epoch [16] - Total Loss: 1.0383: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [17] - Total Loss: 1.0406: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [18] - Total Loss: 1.0377: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [19] - Total Loss: 1.0114: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [20] - Total Loss: 0.9910: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch20.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [21] - Total Loss: 1.0090: 100%|██████████| 24/24 [00:04<00:00,  5.43it/s]\n",
            "Epoch [22] - Total Loss: 1.0356: 100%|██████████| 24/24 [00:01<00:00, 16.80it/s]\n",
            "Epoch [23] - Total Loss: 1.0255: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [24] - Total Loss: 1.0231: 100%|██████████| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [25] - Total Loss: 1.0049: 100%|██████████| 24/24 [00:01<00:00, 17.58it/s]\n",
            "Epoch [26] - Total Loss: 1.0423: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [27] - Total Loss: 1.0115: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [28] - Total Loss: 1.0380: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [29] - Total Loss: 1.0197: 100%|██████████| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [30] - Total Loss: 1.0060: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [31] - Total Loss: 1.0166: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [32] - Total Loss: 0.9779: 100%|██████████| 24/24 [00:01<00:00, 16.89it/s]\n",
            "Epoch [33] - Total Loss: 0.9615: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [34] - Total Loss: 0.9985: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [35] - Total Loss: 1.0253: 100%|██████████| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [36] - Total Loss: 1.0144: 100%|██████████| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [37] - Total Loss: 0.9971: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [38] - Total Loss: 0.9961: 100%|██████████| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [39] - Total Loss: 0.9785: 100%|██████████| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [40] - Total Loss: 0.9822: 100%|██████████| 24/24 [00:01<00:00, 16.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch40.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [41] - Total Loss: 0.9607: 100%|██████████| 24/24 [00:04<00:00,  5.53it/s]\n",
            "Epoch [42] - Total Loss: 0.9523: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [43] - Total Loss: 0.9957: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [44] - Total Loss: 0.9962: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [45] - Total Loss: 0.9466: 100%|██████████| 24/24 [00:01<00:00, 16.68it/s]\n",
            "Epoch [46] - Total Loss: 0.9749: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [47] - Total Loss: 0.9605: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [48] - Total Loss: 0.9831: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [49] - Total Loss: 0.9522: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [50] - Total Loss: 0.9734: 100%|██████████| 24/24 [00:01<00:00, 17.43it/s]\n",
            "Epoch [51] - Total Loss: 0.9435: 100%|██████████| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [52] - Total Loss: 0.9537: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [53] - Total Loss: 0.9609: 100%|██████████| 24/24 [00:01<00:00, 16.64it/s]\n",
            "Epoch [54] - Total Loss: 0.9777: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [55] - Total Loss: 0.9350: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [56] - Total Loss: 0.9346: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [57] - Total Loss: 0.9509: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [58] - Total Loss: 0.9994: 100%|██████████| 24/24 [00:01<00:00, 17.56it/s]\n",
            "Epoch [59] - Total Loss: 1.0002: 100%|██████████| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [60] - Total Loss: 0.9931: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch60.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [61] - Total Loss: 0.9419: 100%|██████████| 24/24 [00:03<00:00,  7.14it/s]\n",
            "Epoch [62] - Total Loss: 0.9838: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [63] - Total Loss: 0.9371: 100%|██████████| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [64] - Total Loss: 0.9635: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [65] - Total Loss: 0.9086: 100%|██████████| 24/24 [00:02<00:00, 10.50it/s]\n",
            "Epoch [66] - Total Loss: 0.9200: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [67] - Total Loss: 0.9297: 100%|██████████| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [68] - Total Loss: 0.9741: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [69] - Total Loss: 0.9341: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [70] - Total Loss: 0.9160: 100%|██████████| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [71] - Total Loss: 0.9506: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [72] - Total Loss: 0.9478: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [73] - Total Loss: 0.9383: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [74] - Total Loss: 0.9135: 100%|██████████| 24/24 [00:01<00:00, 17.44it/s]\n",
            "Epoch [75] - Total Loss: 0.9504: 100%|██████████| 24/24 [00:01<00:00, 16.79it/s]\n",
            "Epoch [76] - Total Loss: 0.9416: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [77] - Total Loss: 0.9246: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [78] - Total Loss: 0.9119: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [79] - Total Loss: 0.9046: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [80] - Total Loss: 0.9436: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch80.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [81] - Total Loss: 0.8900: 100%|██████████| 24/24 [00:03<00:00,  6.81it/s]\n",
            "Epoch [82] - Total Loss: 0.9183: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [83] - Total Loss: 0.8882: 100%|██████████| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [84] - Total Loss: 0.9051: 100%|██████████| 24/24 [00:01<00:00, 12.65it/s]\n",
            "Epoch [85] - Total Loss: 0.9176: 100%|██████████| 24/24 [00:01<00:00, 15.93it/s]\n",
            "Epoch [86] - Total Loss: 0.9166: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [87] - Total Loss: 0.9228: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [88] - Total Loss: 0.9039: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [89] - Total Loss: 0.9181: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [90] - Total Loss: 0.9173: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [91] - Total Loss: 0.9173: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [92] - Total Loss: 0.9055: 100%|██████████| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [93] - Total Loss: 0.9411: 100%|██████████| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [94] - Total Loss: 0.9103: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [95] - Total Loss: 0.9055: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [96] - Total Loss: 0.8945: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [97] - Total Loss: 0.8864: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [98] - Total Loss: 0.9026: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [99] - Total Loss: 0.8734: 100%|██████████| 24/24 [00:01<00:00, 16.93it/s]\n",
            "Epoch [100] - Total Loss: 0.8809: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch100.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [101] - Total Loss: 0.8736: 100%|██████████| 24/24 [00:04<00:00,  5.89it/s]\n",
            "Epoch [102] - Total Loss: 0.8532: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [103] - Total Loss: 0.9203: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [104] - Total Loss: 0.8843: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [105] - Total Loss: 0.8691: 100%|██████████| 24/24 [00:01<00:00, 17.50it/s]\n",
            "Epoch [106] - Total Loss: 0.8521: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [107] - Total Loss: 0.8788: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [108] - Total Loss: 0.8945: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [109] - Total Loss: 0.8806: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [110] - Total Loss: 0.8714: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [111] - Total Loss: 0.8675: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [112] - Total Loss: 0.8946: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [113] - Total Loss: 0.9192: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [114] - Total Loss: 0.9233: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [115] - Total Loss: 0.8447: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [116] - Total Loss: 0.8681: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [117] - Total Loss: 0.8466: 100%|██████████| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [118] - Total Loss: 0.8730: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [119] - Total Loss: 0.9114: 100%|██████████| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [120] - Total Loss: 0.8840: 100%|██████████| 24/24 [00:01<00:00, 16.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch120.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [121] - Total Loss: 0.8675: 100%|██████████| 24/24 [00:04<00:00,  5.53it/s]\n",
            "Epoch [122] - Total Loss: 0.8595: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [123] - Total Loss: 0.8580: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [124] - Total Loss: 0.8536: 100%|██████████| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [125] - Total Loss: 0.8826: 100%|██████████| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [126] - Total Loss: 0.8626: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [127] - Total Loss: 0.8496: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [128] - Total Loss: 0.8336: 100%|██████████| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [129] - Total Loss: 0.8394: 100%|██████████| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [130] - Total Loss: 0.8563: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [131] - Total Loss: 0.8281: 100%|██████████| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [132] - Total Loss: 0.8714: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [133] - Total Loss: 0.8784: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [134] - Total Loss: 0.8245: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [135] - Total Loss: 0.8632: 100%|██████████| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [136] - Total Loss: 0.8763: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [137] - Total Loss: 0.8903: 100%|██████████| 24/24 [00:01<00:00, 17.43it/s]\n",
            "Epoch [138] - Total Loss: 0.8576: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [139] - Total Loss: 0.8372: 100%|██████████| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [140] - Total Loss: 0.8197: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch140.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [141] - Total Loss: 0.8362: 100%|██████████| 24/24 [00:03<00:00,  6.87it/s]\n",
            "Epoch [142] - Total Loss: 0.8401: 100%|██████████| 24/24 [00:01<00:00, 17.43it/s]\n",
            "Epoch [143] - Total Loss: 0.8091: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [144] - Total Loss: 0.8447: 100%|██████████| 24/24 [00:02<00:00, 11.56it/s]\n",
            "Epoch [145] - Total Loss: 0.8339: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [146] - Total Loss: 0.8396: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [147] - Total Loss: 0.8306: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [148] - Total Loss: 0.8415: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [149] - Total Loss: 0.8311: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [150] - Total Loss: 0.8746: 100%|██████████| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [151] - Total Loss: 0.8658: 100%|██████████| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [152] - Total Loss: 0.8303: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [153] - Total Loss: 0.8537: 100%|██████████| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [154] - Total Loss: 0.8420: 100%|██████████| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [155] - Total Loss: 0.7957: 100%|██████████| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [156] - Total Loss: 0.8625: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [157] - Total Loss: 0.8095: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [158] - Total Loss: 0.8287: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [159] - Total Loss: 0.7990: 100%|██████████| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [160] - Total Loss: 0.8000: 100%|██████████| 24/24 [00:01<00:00, 17.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch160.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [161] - Total Loss: 0.8275: 100%|██████████| 24/24 [00:04<00:00,  5.80it/s]\n",
            "Epoch [162] - Total Loss: 0.8170: 100%|██████████| 24/24 [00:01<00:00, 17.47it/s]\n",
            "Epoch [163] - Total Loss: 0.8024: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [164] - Total Loss: 0.8423: 100%|██████████| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [165] - Total Loss: 0.8109: 100%|██████████| 24/24 [00:01<00:00, 15.35it/s]\n",
            "Epoch [166] - Total Loss: 0.8270: 100%|██████████| 24/24 [00:01<00:00, 17.50it/s]\n",
            "Epoch [167] - Total Loss: 0.7689: 100%|██████████| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [168] - Total Loss: 0.7763: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [169] - Total Loss: 0.8402: 100%|██████████| 24/24 [00:01<00:00, 16.93it/s]\n",
            "Epoch [170] - Total Loss: 0.8054: 100%|██████████| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [171] - Total Loss: 0.8228: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [172] - Total Loss: 0.7996: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [173] - Total Loss: 0.8406: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [174] - Total Loss: 0.7930: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [175] - Total Loss: 0.8912: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [176] - Total Loss: 0.7824: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [177] - Total Loss: 0.7918: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [178] - Total Loss: 0.8114: 100%|██████████| 24/24 [00:01<00:00, 16.88it/s]\n",
            "Epoch [179] - Total Loss: 0.8574: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [180] - Total Loss: 0.8158: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch180.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [181] - Total Loss: 0.8483: 100%|██████████| 24/24 [00:04<00:00,  5.73it/s]\n",
            "Epoch [182] - Total Loss: 0.7903: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [183] - Total Loss: 0.8199: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [184] - Total Loss: 0.8169: 100%|██████████| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [185] - Total Loss: 0.8062: 100%|██████████| 24/24 [00:01<00:00, 14.97it/s]\n",
            "Epoch [186] - Total Loss: 0.8234: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [187] - Total Loss: 0.7856: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [188] - Total Loss: 0.8357: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [189] - Total Loss: 0.7638: 100%|██████████| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [190] - Total Loss: 0.7952: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [191] - Total Loss: 0.7697: 100%|██████████| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [192] - Total Loss: 0.7854: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [193] - Total Loss: 0.7878: 100%|██████████| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [194] - Total Loss: 0.8503: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [195] - Total Loss: 0.8229: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [196] - Total Loss: 0.8079: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [197] - Total Loss: 0.7943: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [198] - Total Loss: 0.7928: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [199] - Total Loss: 0.7915: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [200] - Total Loss: 0.8216: 100%|██████████| 24/24 [00:01<00:00, 16.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch200.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [201] - Total Loss: 0.7971: 100%|██████████| 24/24 [00:04<00:00,  5.69it/s]\n",
            "Epoch [202] - Total Loss: 0.8296: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [203] - Total Loss: 0.7881: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [204] - Total Loss: 0.8202: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [205] - Total Loss: 0.7778: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [206] - Total Loss: 0.7568: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [207] - Total Loss: 0.7688: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [208] - Total Loss: 0.7628: 100%|██████████| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [209] - Total Loss: 0.7895: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [210] - Total Loss: 0.8131: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [211] - Total Loss: 0.7497: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [212] - Total Loss: 0.8156: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [213] - Total Loss: 0.7679: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [214] - Total Loss: 0.8178: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [215] - Total Loss: 0.8200: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [216] - Total Loss: 0.8031: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [217] - Total Loss: 0.7633: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [218] - Total Loss: 0.7514: 100%|██████████| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [219] - Total Loss: 0.7446: 100%|██████████| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [220] - Total Loss: 0.8117: 100%|██████████| 24/24 [00:01<00:00, 16.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch220.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [221] - Total Loss: 0.7443: 100%|██████████| 24/24 [00:03<00:00,  6.71it/s]\n",
            "Epoch [222] - Total Loss: 0.7814: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [223] - Total Loss: 0.7754: 100%|██████████| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [224] - Total Loss: 0.7566: 100%|██████████| 24/24 [00:01<00:00, 17.50it/s]\n",
            "Epoch [225] - Total Loss: 0.8199: 100%|██████████| 24/24 [00:01<00:00, 16.12it/s]\n",
            "Epoch [226] - Total Loss: 0.7762: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [227] - Total Loss: 0.7267: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [228] - Total Loss: 0.7687: 100%|██████████| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [229] - Total Loss: 0.7598: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [230] - Total Loss: 0.7938: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [231] - Total Loss: 0.7377: 100%|██████████| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [232] - Total Loss: 0.7929: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [233] - Total Loss: 0.7667: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [234] - Total Loss: 0.7704: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [235] - Total Loss: 0.8037: 100%|██████████| 24/24 [00:01<00:00, 16.92it/s]\n",
            "Epoch [236] - Total Loss: 0.7782: 100%|██████████| 24/24 [00:01<00:00, 16.73it/s]\n",
            "Epoch [237] - Total Loss: 0.7726: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [238] - Total Loss: 0.7918: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [239] - Total Loss: 0.8141: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [240] - Total Loss: 0.8014: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch240.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [241] - Total Loss: 0.7452: 100%|██████████| 24/24 [00:03<00:00,  6.49it/s]\n",
            "Epoch [242] - Total Loss: 0.7491: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [243] - Total Loss: 0.7863: 100%|██████████| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [244] - Total Loss: 0.7548: 100%|██████████| 24/24 [00:01<00:00, 17.51it/s]\n",
            "Epoch [245] - Total Loss: 0.8132: 100%|██████████| 24/24 [00:02<00:00, 11.52it/s]\n",
            "Epoch [246] - Total Loss: 0.7935: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [247] - Total Loss: 0.7839: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [248] - Total Loss: 0.7452: 100%|██████████| 24/24 [00:01<00:00, 16.89it/s]\n",
            "Epoch [249] - Total Loss: 0.7397: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [250] - Total Loss: 0.7427: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [251] - Total Loss: 0.7896: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [252] - Total Loss: 0.7688: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [253] - Total Loss: 0.7889: 100%|██████████| 24/24 [00:01<00:00, 17.53it/s]\n",
            "Epoch [254] - Total Loss: 0.8089: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [255] - Total Loss: 0.7591: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [256] - Total Loss: 0.7399: 100%|██████████| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [257] - Total Loss: 0.7626: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [258] - Total Loss: 0.8156: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [259] - Total Loss: 0.8799: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [260] - Total Loss: 0.7862: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch260.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [261] - Total Loss: 0.7510: 100%|██████████| 24/24 [00:03<00:00,  6.00it/s]\n",
            "Epoch [262] - Total Loss: 0.7880: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [263] - Total Loss: 0.7939: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [264] - Total Loss: 0.7854: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [265] - Total Loss: 0.7422: 100%|██████████| 24/24 [00:01<00:00, 13.30it/s]\n",
            "Epoch [266] - Total Loss: 0.7717: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [267] - Total Loss: 0.8133: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [268] - Total Loss: 0.7361: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [269] - Total Loss: 0.7348: 100%|██████████| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [270] - Total Loss: 0.7778: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [271] - Total Loss: 0.7779: 100%|██████████| 24/24 [00:01<00:00, 16.86it/s]\n",
            "Epoch [272] - Total Loss: 0.7806: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [273] - Total Loss: 0.7371: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [274] - Total Loss: 0.7732: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [275] - Total Loss: 0.7769: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [276] - Total Loss: 0.7738: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [277] - Total Loss: 0.7307: 100%|██████████| 24/24 [00:01<00:00, 17.50it/s]\n",
            "Epoch [278] - Total Loss: 0.7499: 100%|██████████| 24/24 [00:01<00:00, 16.74it/s]\n",
            "Epoch [279] - Total Loss: 0.7625: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [280] - Total Loss: 0.7350: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch280.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [281] - Total Loss: 0.7528: 100%|██████████| 24/24 [00:03<00:00,  6.28it/s]\n",
            "Epoch [282] - Total Loss: 0.7587: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [283] - Total Loss: 0.7386: 100%|██████████| 24/24 [00:01<00:00, 16.82it/s]\n",
            "Epoch [284] - Total Loss: 0.7828: 100%|██████████| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [285] - Total Loss: 0.8177: 100%|██████████| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [286] - Total Loss: 0.7542: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [287] - Total Loss: 0.7459: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [288] - Total Loss: 0.7175: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [289] - Total Loss: 0.7403: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [290] - Total Loss: 0.7462: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [291] - Total Loss: 0.8262: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [292] - Total Loss: 0.7407: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [293] - Total Loss: 0.7277: 100%|██████████| 24/24 [00:01<00:00, 16.79it/s]\n",
            "Epoch [294] - Total Loss: 0.7268: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [295] - Total Loss: 0.7586: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [296] - Total Loss: 0.7690: 100%|██████████| 24/24 [00:01<00:00, 17.45it/s]\n",
            "Epoch [297] - Total Loss: 0.7296: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [298] - Total Loss: 0.7319: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [299] - Total Loss: 0.7708: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [300] - Total Loss: 0.8011: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch300.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [301] - Total Loss: 0.7816: 100%|██████████| 24/24 [00:03<00:00,  6.05it/s]\n",
            "Epoch [302] - Total Loss: 0.7656: 100%|██████████| 24/24 [00:01<00:00, 16.84it/s]\n",
            "Epoch [303] - Total Loss: 0.7236: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [304] - Total Loss: 0.7214: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [305] - Total Loss: 0.8032: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [306] - Total Loss: 0.6943: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [307] - Total Loss: 0.8095: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [308] - Total Loss: 0.7180: 100%|██████████| 24/24 [00:01<00:00, 17.43it/s]\n",
            "Epoch [309] - Total Loss: 0.7874: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [310] - Total Loss: 0.7219: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [311] - Total Loss: 0.7278: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [312] - Total Loss: 0.7601: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [313] - Total Loss: 0.7911: 100%|██████████| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [314] - Total Loss: 0.7547: 100%|██████████| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [315] - Total Loss: 0.6975: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [316] - Total Loss: 0.7485: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [317] - Total Loss: 0.6728: 100%|██████████| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [318] - Total Loss: 0.8182: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [319] - Total Loss: 0.6865: 100%|██████████| 24/24 [00:01<00:00, 17.49it/s]\n",
            "Epoch [320] - Total Loss: 0.8147: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch320.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [321] - Total Loss: 0.7784: 100%|██████████| 24/24 [00:03<00:00,  6.87it/s]\n",
            "Epoch [322] - Total Loss: 0.7219: 100%|██████████| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [323] - Total Loss: 0.7501: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [324] - Total Loss: 0.8006: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [325] - Total Loss: 0.7121: 100%|██████████| 24/24 [00:02<00:00, 10.57it/s]\n",
            "Epoch [326] - Total Loss: 0.7455: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [327] - Total Loss: 0.7923: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [328] - Total Loss: 0.7244: 100%|██████████| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [329] - Total Loss: 0.7162: 100%|██████████| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [330] - Total Loss: 0.7895: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [331] - Total Loss: 0.7614: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [332] - Total Loss: 0.8064: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [333] - Total Loss: 0.7472: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [334] - Total Loss: 0.7000: 100%|██████████| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [335] - Total Loss: 0.7399: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [336] - Total Loss: 0.7539: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [337] - Total Loss: 0.7374: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [338] - Total Loss: 0.7022: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [339] - Total Loss: 0.7225: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [340] - Total Loss: 0.7430: 100%|██████████| 24/24 [00:01<00:00, 17.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch340.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [341] - Total Loss: 0.8095: 100%|██████████| 24/24 [00:03<00:00,  6.69it/s]\n",
            "Epoch [342] - Total Loss: 0.6980: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [343] - Total Loss: 0.7002: 100%|██████████| 24/24 [00:01<00:00, 17.47it/s]\n",
            "Epoch [344] - Total Loss: 0.7134: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [345] - Total Loss: 0.7696: 100%|██████████| 24/24 [00:02<00:00, 10.96it/s]\n",
            "Epoch [346] - Total Loss: 0.7889: 100%|██████████| 24/24 [00:01<00:00, 17.54it/s]\n",
            "Epoch [347] - Total Loss: 0.6943: 100%|██████████| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [348] - Total Loss: 0.7449: 100%|██████████| 24/24 [00:01<00:00, 16.75it/s]\n",
            "Epoch [349] - Total Loss: 0.7514: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [350] - Total Loss: 0.7616: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [351] - Total Loss: 0.7703: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [352] - Total Loss: 0.7461: 100%|██████████| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [353] - Total Loss: 0.7290: 100%|██████████| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [354] - Total Loss: 0.6998: 100%|██████████| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [355] - Total Loss: 0.7145: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [356] - Total Loss: 0.6979: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [357] - Total Loss: 0.7420: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [358] - Total Loss: 0.7019: 100%|██████████| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [359] - Total Loss: 0.7243: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [360] - Total Loss: 0.7906: 100%|██████████| 24/24 [00:01<00:00, 17.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch360.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [361] - Total Loss: 0.7980: 100%|██████████| 24/24 [00:04<00:00,  5.90it/s]\n",
            "Epoch [362] - Total Loss: 0.7634: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [363] - Total Loss: 0.8061: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [364] - Total Loss: 0.7294: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [365] - Total Loss: 0.7545: 100%|██████████| 24/24 [00:01<00:00, 15.05it/s]\n",
            "Epoch [366] - Total Loss: 0.7995: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [367] - Total Loss: 0.7424: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [368] - Total Loss: 0.7192: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [369] - Total Loss: 0.7189: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [370] - Total Loss: 0.7609: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [371] - Total Loss: 0.7316: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [372] - Total Loss: 0.7275: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [373] - Total Loss: 0.6930: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [374] - Total Loss: 0.7245: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [375] - Total Loss: 0.7001: 100%|██████████| 24/24 [00:01<00:00, 17.51it/s]\n",
            "Epoch [376] - Total Loss: 0.7180: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [377] - Total Loss: 0.7719: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [378] - Total Loss: 0.7296: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [379] - Total Loss: 0.7148: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [380] - Total Loss: 0.7467: 100%|██████████| 24/24 [00:01<00:00, 16.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch380.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [381] - Total Loss: 0.6885: 100%|██████████| 24/24 [00:03<00:00,  6.54it/s]\n",
            "Epoch [382] - Total Loss: 0.7744: 100%|██████████| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [383] - Total Loss: 0.7584: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [384] - Total Loss: 0.6696: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [385] - Total Loss: 0.6920: 100%|██████████| 24/24 [00:01<00:00, 13.35it/s]\n",
            "Epoch [386] - Total Loss: 0.7458: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [387] - Total Loss: 0.7055: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [388] - Total Loss: 0.7645: 100%|██████████| 24/24 [00:01<00:00, 17.44it/s]\n",
            "Epoch [389] - Total Loss: 0.6969: 100%|██████████| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [390] - Total Loss: 0.7647: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [391] - Total Loss: 0.7168: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [392] - Total Loss: 0.7535: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [393] - Total Loss: 0.6858: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [394] - Total Loss: 0.7092: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [395] - Total Loss: 0.6985: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [396] - Total Loss: 0.8039: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [397] - Total Loss: 0.7168: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [398] - Total Loss: 0.7259: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [399] - Total Loss: 0.6765: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [400] - Total Loss: 0.7303: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch400.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [401] - Total Loss: 0.7268: 100%|██████████| 24/24 [00:04<00:00,  5.49it/s]\n",
            "Epoch [402] - Total Loss: 0.6975: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [403] - Total Loss: 0.7134: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [404] - Total Loss: 0.7381: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [405] - Total Loss: 0.7230: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [406] - Total Loss: 0.7295: 100%|██████████| 24/24 [00:01<00:00, 16.79it/s]\n",
            "Epoch [407] - Total Loss: 0.6850: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [408] - Total Loss: 0.7234: 100%|██████████| 24/24 [00:01<00:00, 17.36it/s]\n",
            "Epoch [409] - Total Loss: 0.7677: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [410] - Total Loss: 0.6782: 100%|██████████| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [411] - Total Loss: 0.7275: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [412] - Total Loss: 0.7276: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [413] - Total Loss: 0.7321: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [414] - Total Loss: 0.7007: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [415] - Total Loss: 0.7321: 100%|██████████| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [416] - Total Loss: 0.7192: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [417] - Total Loss: 0.7872: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [418] - Total Loss: 0.6897: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [419] - Total Loss: 0.6947: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [420] - Total Loss: 0.6829: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch420.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [421] - Total Loss: 0.7730: 100%|██████████| 24/24 [00:04<00:00,  5.60it/s]\n",
            "Epoch [422] - Total Loss: 0.7409: 100%|██████████| 24/24 [00:01<00:00, 17.45it/s]\n",
            "Epoch [423] - Total Loss: 0.8054: 100%|██████████| 24/24 [00:01<00:00, 17.36it/s]\n",
            "Epoch [424] - Total Loss: 0.6904: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [425] - Total Loss: 0.7788: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [426] - Total Loss: 0.7021: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [427] - Total Loss: 0.7493: 100%|██████████| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [428] - Total Loss: 0.7069: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [429] - Total Loss: 0.7105: 100%|██████████| 24/24 [00:01<00:00, 16.61it/s]\n",
            "Epoch [430] - Total Loss: 0.7472: 100%|██████████| 24/24 [00:01<00:00, 16.92it/s]\n",
            "Epoch [431] - Total Loss: 0.7028: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [432] - Total Loss: 0.6793: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [433] - Total Loss: 0.7198: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [434] - Total Loss: 0.6720: 100%|██████████| 24/24 [00:01<00:00, 16.87it/s]\n",
            "Epoch [435] - Total Loss: 0.7331: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [436] - Total Loss: 0.6960: 100%|██████████| 24/24 [00:01<00:00, 16.55it/s]\n",
            "Epoch [437] - Total Loss: 0.6793: 100%|██████████| 24/24 [00:01<00:00, 16.72it/s]\n",
            "Epoch [438] - Total Loss: 0.6923: 100%|██████████| 24/24 [00:01<00:00, 16.79it/s]\n",
            "Epoch [439] - Total Loss: 0.6941: 100%|██████████| 24/24 [00:01<00:00, 16.73it/s]\n",
            "Epoch [440] - Total Loss: 0.6879: 100%|██████████| 24/24 [00:01<00:00, 16.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch440.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [441] - Total Loss: 0.6906: 100%|██████████| 24/24 [00:03<00:00,  6.20it/s]\n",
            "Epoch [442] - Total Loss: 0.6983: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [443] - Total Loss: 0.6899: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [444] - Total Loss: 0.7192: 100%|██████████| 24/24 [00:01<00:00, 12.92it/s]\n",
            "Epoch [445] - Total Loss: 0.7051: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [446] - Total Loss: 0.7578: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [447] - Total Loss: 0.7422: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [448] - Total Loss: 0.7098: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [449] - Total Loss: 0.6538: 100%|██████████| 24/24 [00:01<00:00, 16.52it/s]\n",
            "Epoch [450] - Total Loss: 0.6704: 100%|██████████| 24/24 [00:01<00:00, 16.55it/s]\n",
            "Epoch [451] - Total Loss: 0.6727: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [452] - Total Loss: 0.7288: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [453] - Total Loss: 0.7331: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [454] - Total Loss: 0.7351: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [455] - Total Loss: 0.6899: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [456] - Total Loss: 0.6744: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [457] - Total Loss: 0.6712: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [458] - Total Loss: 0.6585: 100%|██████████| 24/24 [00:01<00:00, 16.52it/s]\n",
            "Epoch [459] - Total Loss: 0.6993: 100%|██████████| 24/24 [00:01<00:00, 16.50it/s]\n",
            "Epoch [460] - Total Loss: 0.7294: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch460.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [461] - Total Loss: 0.7066: 100%|██████████| 24/24 [00:03<00:00,  6.30it/s]\n",
            "Epoch [462] - Total Loss: 0.7190: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [463] - Total Loss: 0.6646: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [464] - Total Loss: 0.7120: 100%|██████████| 24/24 [00:01<00:00, 16.65it/s]\n",
            "Epoch [465] - Total Loss: 0.7181: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [466] - Total Loss: 0.6790: 100%|██████████| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [467] - Total Loss: 0.6983: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [468] - Total Loss: 0.7277: 100%|██████████| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [469] - Total Loss: 0.6819: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [470] - Total Loss: 0.6874: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [471] - Total Loss: 0.6694: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [472] - Total Loss: 0.7361: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [473] - Total Loss: 0.6459: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [474] - Total Loss: 0.6631: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [475] - Total Loss: 0.7366: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [476] - Total Loss: 0.6701: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [477] - Total Loss: 0.6994: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [478] - Total Loss: 0.6888: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [479] - Total Loss: 0.6815: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [480] - Total Loss: 0.7752: 100%|██████████| 24/24 [00:01<00:00, 16.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch480.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [481] - Total Loss: 0.6664: 100%|██████████| 24/24 [00:04<00:00,  5.38it/s]\n",
            "Epoch [482] - Total Loss: 0.7329: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [483] - Total Loss: 0.7592: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [484] - Total Loss: 0.7119: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [485] - Total Loss: 0.6927: 100%|██████████| 24/24 [00:01<00:00, 16.84it/s]\n",
            "Epoch [486] - Total Loss: 0.7353: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [487] - Total Loss: 0.7855: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [488] - Total Loss: 0.6854: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [489] - Total Loss: 0.6870: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [490] - Total Loss: 0.6913: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [491] - Total Loss: 0.6797: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [492] - Total Loss: 0.7105: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [493] - Total Loss: 0.6710: 100%|██████████| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [494] - Total Loss: 0.7467: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [495] - Total Loss: 0.7054: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [496] - Total Loss: 0.6874: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [497] - Total Loss: 0.6894: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [498] - Total Loss: 0.7425: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [499] - Total Loss: 0.7374: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [500] - Total Loss: 0.7325: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch500.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [501] - Total Loss: 0.7706: 100%|██████████| 24/24 [00:03<00:00,  7.17it/s]\n",
            "Epoch [502] - Total Loss: 0.7628: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [503] - Total Loss: 0.7524: 100%|██████████| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [504] - Total Loss: 0.6583: 100%|██████████| 24/24 [00:02<00:00, 10.52it/s]\n",
            "Epoch [505] - Total Loss: 0.7011: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [506] - Total Loss: 0.7006: 100%|██████████| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [507] - Total Loss: 0.7948: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [508] - Total Loss: 0.7417: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [509] - Total Loss: 0.7171: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [510] - Total Loss: 0.7577: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [511] - Total Loss: 0.6682: 100%|██████████| 24/24 [00:01<00:00, 16.92it/s]\n",
            "Epoch [512] - Total Loss: 0.6739: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [513] - Total Loss: 0.6870: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [514] - Total Loss: 0.7568: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [515] - Total Loss: 0.6894: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [516] - Total Loss: 0.7248: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [517] - Total Loss: 0.7325: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [518] - Total Loss: 0.7043: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [519] - Total Loss: 0.7301: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [520] - Total Loss: 0.6832: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch520.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [521] - Total Loss: 0.6865: 100%|██████████| 24/24 [00:04<00:00,  5.60it/s]\n",
            "Epoch [522] - Total Loss: 0.6599: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [523] - Total Loss: 0.7279: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [524] - Total Loss: 0.7200: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [525] - Total Loss: 0.6749: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [526] - Total Loss: 0.6989: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [527] - Total Loss: 0.6932: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [528] - Total Loss: 0.7464: 100%|██████████| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [529] - Total Loss: 0.7338: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [530] - Total Loss: 0.7118: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [531] - Total Loss: 0.7240: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [532] - Total Loss: 0.7407: 100%|██████████| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [533] - Total Loss: 0.6561: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [534] - Total Loss: 0.6762: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [535] - Total Loss: 0.6754: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [536] - Total Loss: 0.6864: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [537] - Total Loss: 0.6723: 100%|██████████| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [538] - Total Loss: 0.7314: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [539] - Total Loss: 0.7235: 100%|██████████| 24/24 [00:01<00:00, 17.50it/s]\n",
            "Epoch [540] - Total Loss: 0.6758: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch540.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [541] - Total Loss: 0.8191: 100%|██████████| 24/24 [00:03<00:00,  6.74it/s]\n",
            "Epoch [542] - Total Loss: 0.7184: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [543] - Total Loss: 0.6898: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [544] - Total Loss: 0.6784: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [545] - Total Loss: 0.7442: 100%|██████████| 24/24 [00:01<00:00, 13.66it/s]\n",
            "Epoch [546] - Total Loss: 0.6633: 100%|██████████| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [547] - Total Loss: 0.6565: 100%|██████████| 24/24 [00:01<00:00, 17.54it/s]\n",
            "Epoch [548] - Total Loss: 0.6983: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [549] - Total Loss: 0.6788: 100%|██████████| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [550] - Total Loss: 0.7027: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [551] - Total Loss: 0.7248: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [552] - Total Loss: 0.6418: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [553] - Total Loss: 0.7195: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [554] - Total Loss: 0.6487: 100%|██████████| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [555] - Total Loss: 0.6487: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [556] - Total Loss: 0.6566: 100%|██████████| 24/24 [00:01<00:00, 17.49it/s]\n",
            "Epoch [557] - Total Loss: 0.7680: 100%|██████████| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [558] - Total Loss: 0.7372: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [559] - Total Loss: 0.6941: 100%|██████████| 24/24 [00:01<00:00, 16.87it/s]\n",
            "Epoch [560] - Total Loss: 0.7116: 100%|██████████| 24/24 [00:01<00:00, 16.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch560.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [561] - Total Loss: 0.7213: 100%|██████████| 24/24 [00:04<00:00,  5.48it/s]\n",
            "Epoch [562] - Total Loss: 0.7109: 100%|██████████| 24/24 [00:01<00:00, 17.51it/s]\n",
            "Epoch [563] - Total Loss: 0.6803: 100%|██████████| 24/24 [00:01<00:00, 16.88it/s]\n",
            "Epoch [564] - Total Loss: 0.7366: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [565] - Total Loss: 0.6709: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [566] - Total Loss: 0.6724: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [567] - Total Loss: 0.6547: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [568] - Total Loss: 0.6567: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [569] - Total Loss: 0.7613: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [570] - Total Loss: 0.6977: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [571] - Total Loss: 0.7380: 100%|██████████| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [572] - Total Loss: 0.6779: 100%|██████████| 24/24 [00:01<00:00, 16.74it/s]\n",
            "Epoch [573] - Total Loss: 0.6702: 100%|██████████| 24/24 [00:01<00:00, 16.69it/s]\n",
            "Epoch [574] - Total Loss: 0.6754: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [575] - Total Loss: 0.6562: 100%|██████████| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [576] - Total Loss: 0.7421: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [577] - Total Loss: 0.7430: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [578] - Total Loss: 0.6690: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [579] - Total Loss: 0.6581: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [580] - Total Loss: 0.7087: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch580.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [581] - Total Loss: 0.6384: 100%|██████████| 24/24 [00:03<00:00,  6.59it/s]\n",
            "Epoch [582] - Total Loss: 0.7289: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [583] - Total Loss: 0.7188: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [584] - Total Loss: 0.6980: 100%|██████████| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [585] - Total Loss: 0.6756: 100%|██████████| 24/24 [00:02<00:00, 11.16it/s]\n",
            "Epoch [586] - Total Loss: 0.7254: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [587] - Total Loss: 0.6758: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [588] - Total Loss: 0.6529: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [589] - Total Loss: 0.6626: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [590] - Total Loss: 0.7665: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [591] - Total Loss: 0.6867: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [592] - Total Loss: 0.6856: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [593] - Total Loss: 0.7632: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [594] - Total Loss: 0.6858: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [595] - Total Loss: 0.6463: 100%|██████████| 24/24 [00:01<00:00, 16.69it/s]\n",
            "Epoch [596] - Total Loss: 0.6565: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [597] - Total Loss: 0.6990: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [598] - Total Loss: 0.6447: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [599] - Total Loss: 0.6405: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [600] - Total Loss: 0.6536: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch600.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [601] - Total Loss: 0.6699: 100%|██████████| 24/24 [00:03<00:00,  6.17it/s]\n",
            "Epoch [602] - Total Loss: 0.6558: 100%|██████████| 24/24 [00:01<00:00, 17.48it/s]\n",
            "Epoch [603] - Total Loss: 0.7862: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [604] - Total Loss: 0.6896: 100%|██████████| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [605] - Total Loss: 0.6563: 100%|██████████| 24/24 [00:01<00:00, 13.19it/s]\n",
            "Epoch [606] - Total Loss: 0.7202: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [607] - Total Loss: 0.6795: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [608] - Total Loss: 0.6903: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [609] - Total Loss: 0.6726: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [610] - Total Loss: 0.7435: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [611] - Total Loss: 0.6815: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [612] - Total Loss: 0.6869: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [613] - Total Loss: 0.7230: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [614] - Total Loss: 0.6872: 100%|██████████| 24/24 [00:01<00:00, 16.87it/s]\n",
            "Epoch [615] - Total Loss: 0.6754: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [616] - Total Loss: 0.6499: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [617] - Total Loss: 0.6377: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [618] - Total Loss: 0.6899: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [619] - Total Loss: 0.6740: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [620] - Total Loss: 0.6680: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch620.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [621] - Total Loss: 0.7433: 100%|██████████| 24/24 [00:04<00:00,  5.47it/s]\n",
            "Epoch [622] - Total Loss: 0.6547: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [623] - Total Loss: 0.6821: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [624] - Total Loss: 0.6780: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [625] - Total Loss: 0.7175: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [626] - Total Loss: 0.7624: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [627] - Total Loss: 0.6565: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [628] - Total Loss: 0.6480: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [629] - Total Loss: 0.6704: 100%|██████████| 24/24 [00:01<00:00, 16.67it/s]\n",
            "Epoch [630] - Total Loss: 0.6623: 100%|██████████| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [631] - Total Loss: 0.6852: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [632] - Total Loss: 0.6584: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [633] - Total Loss: 0.6955: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [634] - Total Loss: 0.6768: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [635] - Total Loss: 0.7216: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [636] - Total Loss: 0.7077: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [637] - Total Loss: 0.6397: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [638] - Total Loss: 0.7116: 100%|██████████| 24/24 [00:01<00:00, 16.66it/s]\n",
            "Epoch [639] - Total Loss: 0.6571: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [640] - Total Loss: 0.6888: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch640.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [641] - Total Loss: 0.6849: 100%|██████████| 24/24 [00:03<00:00,  6.73it/s]\n",
            "Epoch [642] - Total Loss: 0.6752: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [643] - Total Loss: 0.7530: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [644] - Total Loss: 0.6481: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [645] - Total Loss: 0.7138: 100%|██████████| 24/24 [00:02<00:00, 10.85it/s]\n",
            "Epoch [646] - Total Loss: 0.7378: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [647] - Total Loss: 0.6608: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [648] - Total Loss: 0.6594: 100%|██████████| 24/24 [00:01<00:00, 17.45it/s]\n",
            "Epoch [649] - Total Loss: 0.6522: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [650] - Total Loss: 0.6298: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [651] - Total Loss: 0.7247: 100%|██████████| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [652] - Total Loss: 0.6769: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [653] - Total Loss: 0.7530: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [654] - Total Loss: 0.6364: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [655] - Total Loss: 0.6493: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [656] - Total Loss: 0.7171: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [657] - Total Loss: 0.6521: 100%|██████████| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [658] - Total Loss: 0.6951: 100%|██████████| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [659] - Total Loss: 0.6822: 100%|██████████| 24/24 [00:01<00:00, 16.68it/s]\n",
            "Epoch [660] - Total Loss: 0.6789: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch660.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [661] - Total Loss: 0.7181: 100%|██████████| 24/24 [00:03<00:00,  6.37it/s]\n",
            "Epoch [662] - Total Loss: 0.6509: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [663] - Total Loss: 0.6371: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [664] - Total Loss: 0.7088: 100%|██████████| 24/24 [00:01<00:00, 16.84it/s]\n",
            "Epoch [665] - Total Loss: 0.6751: 100%|██████████| 24/24 [00:01<00:00, 12.50it/s]\n",
            "Epoch [666] - Total Loss: 0.6954: 100%|██████████| 24/24 [00:01<00:00, 17.55it/s]\n",
            "Epoch [667] - Total Loss: 0.6756: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [668] - Total Loss: 0.6547: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [669] - Total Loss: 0.6540: 100%|██████████| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [670] - Total Loss: 0.6853: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [671] - Total Loss: 0.6455: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [672] - Total Loss: 0.7346: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [673] - Total Loss: 0.7316: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [674] - Total Loss: 0.6891: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [675] - Total Loss: 0.6403: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [676] - Total Loss: 0.6996: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [677] - Total Loss: 0.6707: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [678] - Total Loss: 0.6773: 100%|██████████| 24/24 [00:01<00:00, 16.89it/s]\n",
            "Epoch [679] - Total Loss: 0.7626: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [680] - Total Loss: 0.6232: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch680.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [681] - Total Loss: 0.6830: 100%|██████████| 24/24 [00:04<00:00,  5.71it/s]\n",
            "Epoch [682] - Total Loss: 0.6821: 100%|██████████| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [683] - Total Loss: 0.6584: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [684] - Total Loss: 0.6655: 100%|██████████| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [685] - Total Loss: 0.6772: 100%|██████████| 24/24 [00:01<00:00, 15.92it/s]\n",
            "Epoch [686] - Total Loss: 0.6472: 100%|██████████| 24/24 [00:01<00:00, 16.87it/s]\n",
            "Epoch [687] - Total Loss: 0.7284: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [688] - Total Loss: 0.6818: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [689] - Total Loss: 0.6612: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [690] - Total Loss: 0.6372: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [691] - Total Loss: 0.6758: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [692] - Total Loss: 0.7121: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [693] - Total Loss: 0.7066: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [694] - Total Loss: 0.6259: 100%|██████████| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [695] - Total Loss: 0.6976: 100%|██████████| 24/24 [00:01<00:00, 16.86it/s]\n",
            "Epoch [696] - Total Loss: 0.6820: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [697] - Total Loss: 0.6854: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [698] - Total Loss: 0.6904: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [699] - Total Loss: 0.6596: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [700] - Total Loss: 0.6674: 100%|██████████| 24/24 [00:01<00:00, 16.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch700.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [701] - Total Loss: 0.6854: 100%|██████████| 24/24 [00:03<00:00,  6.74it/s]\n",
            "Epoch [702] - Total Loss: 0.6365: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [703] - Total Loss: 0.7038: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [704] - Total Loss: 0.6448: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [705] - Total Loss: 0.6875: 100%|██████████| 24/24 [00:02<00:00, 10.82it/s]\n",
            "Epoch [706] - Total Loss: 0.7182: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [707] - Total Loss: 0.7466: 100%|██████████| 24/24 [00:01<00:00, 16.88it/s]\n",
            "Epoch [708] - Total Loss: 0.6630: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [709] - Total Loss: 0.6807: 100%|██████████| 24/24 [00:01<00:00, 16.86it/s]\n",
            "Epoch [710] - Total Loss: 0.6836: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [711] - Total Loss: 0.6880: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [712] - Total Loss: 0.6689: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [713] - Total Loss: 0.6577: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [714] - Total Loss: 0.7449: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [715] - Total Loss: 0.6639: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [716] - Total Loss: 0.6311: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [717] - Total Loss: 0.6840: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [718] - Total Loss: 0.6571: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [719] - Total Loss: 0.6204: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [720] - Total Loss: 0.6728: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch720.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [721] - Total Loss: 0.6930: 100%|██████████| 24/24 [00:03<00:00,  6.50it/s]\n",
            "Epoch [722] - Total Loss: 0.7230: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [723] - Total Loss: 0.6566: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [724] - Total Loss: 0.6496: 100%|██████████| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [725] - Total Loss: 0.7054: 100%|██████████| 24/24 [00:02<00:00, 11.69it/s]\n",
            "Epoch [726] - Total Loss: 0.7046: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [727] - Total Loss: 0.6844: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [728] - Total Loss: 0.7152: 100%|██████████| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [729] - Total Loss: 0.6537: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [730] - Total Loss: 0.7957: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [731] - Total Loss: 0.6948: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [732] - Total Loss: 0.6609: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [733] - Total Loss: 0.6966: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [734] - Total Loss: 0.6809: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [735] - Total Loss: 0.6450: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [736] - Total Loss: 0.7493: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [737] - Total Loss: 0.7429: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [738] - Total Loss: 0.6843: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [739] - Total Loss: 0.6434: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [740] - Total Loss: 0.6547: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch740.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [741] - Total Loss: 0.6830: 100%|██████████| 24/24 [00:04<00:00,  5.82it/s]\n",
            "Epoch [742] - Total Loss: 0.6632: 100%|██████████| 24/24 [00:01<00:00, 16.92it/s]\n",
            "Epoch [743] - Total Loss: 0.7338: 100%|██████████| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [744] - Total Loss: 0.6395: 100%|██████████| 24/24 [00:01<00:00, 15.45it/s]\n",
            "Epoch [745] - Total Loss: 0.6427: 100%|██████████| 24/24 [00:01<00:00, 17.36it/s]\n",
            "Epoch [746] - Total Loss: 0.7031: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [747] - Total Loss: 0.6867: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [748] - Total Loss: 0.7416: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [749] - Total Loss: 0.6566: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [750] - Total Loss: 0.7240: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [751] - Total Loss: 0.6570: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [752] - Total Loss: 0.7026: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [753] - Total Loss: 0.6422: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [754] - Total Loss: 0.6693: 100%|██████████| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [755] - Total Loss: 0.6373: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [756] - Total Loss: 0.7670: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [757] - Total Loss: 0.6799: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [758] - Total Loss: 0.6789: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [759] - Total Loss: 0.6496: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [760] - Total Loss: 0.6505: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch760.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [761] - Total Loss: 0.6286: 100%|██████████| 24/24 [00:04<00:00,  5.62it/s]\n",
            "Epoch [762] - Total Loss: 0.6546: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [763] - Total Loss: 0.6317: 100%|██████████| 24/24 [00:01<00:00, 16.89it/s]\n",
            "Epoch [764] - Total Loss: 0.6737: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [765] - Total Loss: 0.6214: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [766] - Total Loss: 0.6828: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [767] - Total Loss: 0.7223: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [768] - Total Loss: 0.6272: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [769] - Total Loss: 0.6683: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [770] - Total Loss: 0.6768: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [771] - Total Loss: 0.6465: 100%|██████████| 24/24 [00:01<00:00, 16.83it/s]\n",
            "Epoch [772] - Total Loss: 0.7015: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [773] - Total Loss: 0.6242: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [774] - Total Loss: 0.5979: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [775] - Total Loss: 0.6666: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [776] - Total Loss: 0.6814: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [777] - Total Loss: 0.6564: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [778] - Total Loss: 0.6752: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [779] - Total Loss: 0.6879: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [780] - Total Loss: 0.6385: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch780.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [781] - Total Loss: 0.6842: 100%|██████████| 24/24 [00:04<00:00,  5.61it/s]\n",
            "Epoch [782] - Total Loss: 0.6375: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [783] - Total Loss: 0.7070: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [784] - Total Loss: 0.6405: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [785] - Total Loss: 0.6420: 100%|██████████| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [786] - Total Loss: 0.6822: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [787] - Total Loss: 0.7655: 100%|██████████| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [788] - Total Loss: 0.6047: 100%|██████████| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [789] - Total Loss: 0.6952: 100%|██████████| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [790] - Total Loss: 0.6522: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [791] - Total Loss: 0.6458: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [792] - Total Loss: 0.6214: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [793] - Total Loss: 0.6899: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [794] - Total Loss: 0.6837: 100%|██████████| 24/24 [00:01<00:00, 16.78it/s]\n",
            "Epoch [795] - Total Loss: 0.6241: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [796] - Total Loss: 0.6965: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [797] - Total Loss: 0.6578: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [798] - Total Loss: 0.6347: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [799] - Total Loss: 0.6912: 100%|██████████| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [800] - Total Loss: 0.6042: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch800.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [801] - Total Loss: 0.7120: 100%|██████████| 24/24 [00:04<00:00,  5.57it/s]\n",
            "Epoch [802] - Total Loss: 0.7178: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [803] - Total Loss: 0.6660: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [804] - Total Loss: 0.6237: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [805] - Total Loss: 0.7267: 100%|██████████| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [806] - Total Loss: 0.6401: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [807] - Total Loss: 0.6350: 100%|██████████| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [808] - Total Loss: 0.6560: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [809] - Total Loss: 0.7652: 100%|██████████| 24/24 [00:01<00:00, 17.77it/s]\n",
            "Epoch [810] - Total Loss: 0.6929: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [811] - Total Loss: 0.6712: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [812] - Total Loss: 0.6808: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [813] - Total Loss: 0.6310: 100%|██████████| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [814] - Total Loss: 0.6593: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [815] - Total Loss: 0.6755: 100%|██████████| 24/24 [00:01<00:00, 16.73it/s]\n",
            "Epoch [816] - Total Loss: 0.6289: 100%|██████████| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [817] - Total Loss: 0.7350: 100%|██████████| 24/24 [00:01<00:00, 17.45it/s]\n",
            "Epoch [818] - Total Loss: 0.6547: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [819] - Total Loss: 0.6359: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [820] - Total Loss: 0.6886: 100%|██████████| 24/24 [00:01<00:00, 17.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch820.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [821] - Total Loss: 0.6515: 100%|██████████| 24/24 [00:03<00:00,  7.28it/s]\n",
            "Epoch [822] - Total Loss: 0.6115: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [823] - Total Loss: 0.6213: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [824] - Total Loss: 0.6696: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [825] - Total Loss: 0.7252: 100%|██████████| 24/24 [00:02<00:00, 11.40it/s]\n",
            "Epoch [826] - Total Loss: 0.7263: 100%|██████████| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [827] - Total Loss: 0.6429: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [828] - Total Loss: 0.6469: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [829] - Total Loss: 0.6484: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [830] - Total Loss: 0.6663: 100%|██████████| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [831] - Total Loss: 0.6915: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [832] - Total Loss: 0.6855: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [833] - Total Loss: 0.6585: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [834] - Total Loss: 0.7039: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [835] - Total Loss: 0.6489: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [836] - Total Loss: 0.6460: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [837] - Total Loss: 0.6301: 100%|██████████| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [838] - Total Loss: 0.6175: 100%|██████████| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [839] - Total Loss: 0.6200: 100%|██████████| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [840] - Total Loss: 0.6420: 100%|██████████| 24/24 [00:01<00:00, 17.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch840.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [841] - Total Loss: 0.6625: 100%|██████████| 24/24 [00:04<00:00,  5.42it/s]\n",
            "Epoch [842] - Total Loss: 0.6858: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [843] - Total Loss: 0.6426: 100%|██████████| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [844] - Total Loss: 0.6823: 100%|██████████| 24/24 [00:01<00:00, 17.48it/s]\n",
            "Epoch [845] - Total Loss: 0.6222: 100%|██████████| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [846] - Total Loss: 0.7405: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [847] - Total Loss: 0.6588: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [848] - Total Loss: 0.6458: 100%|██████████| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [849] - Total Loss: 0.6522: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [850] - Total Loss: 0.7555: 100%|██████████| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [851] - Total Loss: 0.6739: 100%|██████████| 24/24 [00:01<00:00, 16.92it/s]\n",
            "Epoch [852] - Total Loss: 0.6546: 100%|██████████| 24/24 [00:01<00:00, 17.49it/s]\n",
            "Epoch [853] - Total Loss: 0.6613: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [854] - Total Loss: 0.6936: 100%|██████████| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [855] - Total Loss: 0.6902: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [856] - Total Loss: 0.6877: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [857] - Total Loss: 0.6263: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [858] - Total Loss: 0.6222: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [859] - Total Loss: 0.6517: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [860] - Total Loss: 0.7330: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch860.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [861] - Total Loss: 0.6689: 100%|██████████| 24/24 [00:03<00:00,  6.47it/s]\n",
            "Epoch [862] - Total Loss: 0.6618: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [863] - Total Loss: 0.7540: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [864] - Total Loss: 0.6484: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [865] - Total Loss: 0.6429: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [866] - Total Loss: 0.7001: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [867] - Total Loss: 0.6738: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [868] - Total Loss: 0.6340: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [869] - Total Loss: 0.6778: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [870] - Total Loss: 0.6554: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [871] - Total Loss: 0.6101: 100%|██████████| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [872] - Total Loss: 0.7093: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [873] - Total Loss: 0.7114: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [874] - Total Loss: 0.6553: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [875] - Total Loss: 0.6349: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [876] - Total Loss: 0.6933: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [877] - Total Loss: 0.6197: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [878] - Total Loss: 0.6512: 100%|██████████| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [879] - Total Loss: 0.6582: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [880] - Total Loss: 0.6546: 100%|██████████| 24/24 [00:01<00:00, 16.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch880.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [881] - Total Loss: 0.6159: 100%|██████████| 24/24 [00:03<00:00,  6.57it/s]\n",
            "Epoch [882] - Total Loss: 0.6667: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [883] - Total Loss: 0.6810: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [884] - Total Loss: 0.6748: 100%|██████████| 24/24 [00:01<00:00, 16.66it/s]\n",
            "Epoch [885] - Total Loss: 0.6388: 100%|██████████| 24/24 [00:02<00:00, 11.24it/s]\n",
            "Epoch [886] - Total Loss: 0.6422: 100%|██████████| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [887] - Total Loss: 0.6172: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [888] - Total Loss: 0.6447: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [889] - Total Loss: 0.6818: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [890] - Total Loss: 0.6913: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [891] - Total Loss: 0.7547: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [892] - Total Loss: 0.6536: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [893] - Total Loss: 0.6053: 100%|██████████| 24/24 [00:01<00:00, 16.93it/s]\n",
            "Epoch [894] - Total Loss: 0.6293: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [895] - Total Loss: 0.6843: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [896] - Total Loss: 0.6555: 100%|██████████| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [897] - Total Loss: 0.6235: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [898] - Total Loss: 0.7157: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [899] - Total Loss: 0.6483: 100%|██████████| 24/24 [00:01<00:00, 16.85it/s]\n",
            "Epoch [900] - Total Loss: 0.7247: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch900.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [901] - Total Loss: 0.6991: 100%|██████████| 24/24 [00:03<00:00,  6.40it/s]\n",
            "Epoch [902] - Total Loss: 0.7055: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [903] - Total Loss: 0.7682: 100%|██████████| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [904] - Total Loss: 0.6210: 100%|██████████| 24/24 [00:01<00:00, 16.88it/s]\n",
            "Epoch [905] - Total Loss: 0.6392: 100%|██████████| 24/24 [00:01<00:00, 12.29it/s]\n",
            "Epoch [906] - Total Loss: 0.6349: 100%|██████████| 24/24 [00:01<00:00, 16.67it/s]\n",
            "Epoch [907] - Total Loss: 0.6209: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [908] - Total Loss: 0.7216: 100%|██████████| 24/24 [00:01<00:00, 16.93it/s]\n",
            "Epoch [909] - Total Loss: 0.6406: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [910] - Total Loss: 0.7074: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [911] - Total Loss: 0.6490: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [912] - Total Loss: 0.6218: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [913] - Total Loss: 0.6794: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [914] - Total Loss: 0.6421: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [915] - Total Loss: 0.7149: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [916] - Total Loss: 0.6560: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [917] - Total Loss: 0.5944: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [918] - Total Loss: 0.7291: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [919] - Total Loss: 0.7493: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [920] - Total Loss: 0.6497: 100%|██████████| 24/24 [00:01<00:00, 16.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch920.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [921] - Total Loss: 0.7235: 100%|██████████| 24/24 [00:04<00:00,  5.92it/s]\n",
            "Epoch [922] - Total Loss: 0.6143: 100%|██████████| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [923] - Total Loss: 0.6450: 100%|██████████| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [924] - Total Loss: 0.6236: 100%|██████████| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [925] - Total Loss: 0.7044: 100%|██████████| 24/24 [00:01<00:00, 16.70it/s]\n",
            "Epoch [926] - Total Loss: 0.6717: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [927] - Total Loss: 0.6672: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [928] - Total Loss: 0.6770: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [929] - Total Loss: 0.6227: 100%|██████████| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [930] - Total Loss: 0.5993: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [931] - Total Loss: 0.6538: 100%|██████████| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [932] - Total Loss: 0.6532: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [933] - Total Loss: 0.6801: 100%|██████████| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [934] - Total Loss: 0.6589: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [935] - Total Loss: 0.6698: 100%|██████████| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [936] - Total Loss: 0.6653: 100%|██████████| 24/24 [00:01<00:00, 16.88it/s]\n",
            "Epoch [937] - Total Loss: 0.6662: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [938] - Total Loss: 0.6805: 100%|██████████| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [939] - Total Loss: 0.6402: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [940] - Total Loss: 0.6428: 100%|██████████| 24/24 [00:01<00:00, 17.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch940.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [941] - Total Loss: 0.7153: 100%|██████████| 24/24 [00:03<00:00,  7.14it/s]\n",
            "Epoch [942] - Total Loss: 0.6891: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [943] - Total Loss: 0.6734: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [944] - Total Loss: 0.7303: 100%|██████████| 24/24 [00:01<00:00, 16.68it/s]\n",
            "Epoch [945] - Total Loss: 0.6680: 100%|██████████| 24/24 [00:02<00:00, 10.67it/s]\n",
            "Epoch [946] - Total Loss: 0.6317: 100%|██████████| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [947] - Total Loss: 0.6659: 100%|██████████| 24/24 [00:01<00:00, 16.86it/s]\n",
            "Epoch [948] - Total Loss: 0.6966: 100%|██████████| 24/24 [00:01<00:00, 16.81it/s]\n",
            "Epoch [949] - Total Loss: 0.6775: 100%|██████████| 24/24 [00:01<00:00, 16.85it/s]\n",
            "Epoch [950] - Total Loss: 0.6830: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [951] - Total Loss: 0.6691: 100%|██████████| 24/24 [00:01<00:00, 17.36it/s]\n",
            "Epoch [952] - Total Loss: 0.7023: 100%|██████████| 24/24 [00:01<00:00, 16.89it/s]\n",
            "Epoch [953] - Total Loss: 0.6289: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [954] - Total Loss: 0.6222: 100%|██████████| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [955] - Total Loss: 0.6123: 100%|██████████| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [956] - Total Loss: 0.6516: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [957] - Total Loss: 0.6706: 100%|██████████| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [958] - Total Loss: 0.6367: 100%|██████████| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [959] - Total Loss: 0.6276: 100%|██████████| 24/24 [00:01<00:00, 16.93it/s]\n",
            "Epoch [960] - Total Loss: 0.7048: 100%|██████████| 24/24 [00:01<00:00, 17.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch960.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [961] - Total Loss: 0.6389: 100%|██████████| 24/24 [00:03<00:00,  6.37it/s]\n",
            "Epoch [962] - Total Loss: 0.6085: 100%|██████████| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [963] - Total Loss: 0.6361: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [964] - Total Loss: 0.6271: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [965] - Total Loss: 0.6722: 100%|██████████| 24/24 [00:01<00:00, 12.53it/s]\n",
            "Epoch [966] - Total Loss: 0.6714: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [967] - Total Loss: 0.6269: 100%|██████████| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [968] - Total Loss: 0.6422: 100%|██████████| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [969] - Total Loss: 0.6629: 100%|██████████| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [970] - Total Loss: 0.6076: 100%|██████████| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [971] - Total Loss: 0.6192: 100%|██████████| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [972] - Total Loss: 0.6406: 100%|██████████| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [973] - Total Loss: 0.6228: 100%|██████████| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [974] - Total Loss: 0.6152: 100%|██████████| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [975] - Total Loss: 0.6577: 100%|██████████| 24/24 [00:01<00:00, 17.36it/s]\n",
            "Epoch [976] - Total Loss: 0.7421: 100%|██████████| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [977] - Total Loss: 0.6837: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [978] - Total Loss: 0.6173: 100%|██████████| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [979] - Total Loss: 0.6262: 100%|██████████| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [980] - Total Loss: 0.6578: 100%|██████████| 24/24 [00:01<00:00, 16.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch980.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [981] - Total Loss: 0.6667: 100%|██████████| 24/24 [00:03<00:00,  6.04it/s]\n",
            "Epoch [982] - Total Loss: 0.6314: 100%|██████████| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [983] - Total Loss: 0.6599: 100%|██████████| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [984] - Total Loss: 0.6190: 100%|██████████| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [985] - Total Loss: 0.6410: 100%|██████████| 24/24 [00:01<00:00, 13.80it/s]\n",
            "Epoch [986] - Total Loss: 0.6510: 100%|██████████| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [987] - Total Loss: 0.7030: 100%|██████████| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [988] - Total Loss: 0.6308: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [989] - Total Loss: 0.7370: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [990] - Total Loss: 0.6802: 100%|██████████| 24/24 [00:01<00:00, 17.44it/s]\n",
            "Epoch [991] - Total Loss: 0.6432: 100%|██████████| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [992] - Total Loss: 0.6422: 100%|██████████| 24/24 [00:01<00:00, 16.87it/s]\n",
            "Epoch [993] - Total Loss: 0.6774: 100%|██████████| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [994] - Total Loss: 0.6707: 100%|██████████| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [995] - Total Loss: 0.5937: 100%|██████████| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [996] - Total Loss: 0.7323: 100%|██████████| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [997] - Total Loss: 0.6426: 100%|██████████| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [998] - Total Loss: 0.7301: 100%|██████████| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [999] - Total Loss: 0.6041: 100%|██████████| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [1000] - Total Loss: 0.6179: 100%|██████████| 24/24 [00:01<00:00, 17.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved: sample_epoch1000.png and model checkpoints\n"
          ]
        }
      ],
      "source": [
        "#FINAL EXECUTED CODE TRAINING USIN LATENT DIFFUSION MODEL\n",
        "# ✅ FINAL FIXED LDM + DDIM SAMPLING + EMA + CHECKPOINTING (IMPROVED CNN + KL + REALISTIC SAMPLING)\n",
        "import torch, os\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms as T\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch.amp import autocast, GradScaler\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# ✅ CONFIG\n",
        "IMG_SIZE = 512\n",
        "LATENT_DIM = 1024\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 1000\n",
        "WARMUP_EPOCHS = 100\n",
        "LR = 2e-4\n",
        "TIMESTEPS = 1000\n",
        "DATA_PATH = \"/content/drive/MyDrive/ANTHRECNOSE\"\n",
        "\n",
        "# ✅ DEVICE & OUTPUT\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "scaler = GradScaler()\n",
        "os.makedirs(\"ldm3_outputs\", exist_ok=True)\n",
        "\n",
        "# ✅ DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# ✅ LOADER\n",
        "dataset = SingleClassImageDataset(DATA_PATH, transform)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "# ✅ MODELS\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# ✅ TRAINING SETUP\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()) + list(unet.parameters()), lr=LR)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# ✅ KL Loss\n",
        "def kl_divergence(mu):\n",
        "    return -0.5 * torch.sum(1 + 0 - mu.pow(2) - 1, dim=1).mean()\n",
        "\n",
        "# ✅ TRAIN LOOP\n",
        "print(\"\\n🚀 Starting Training...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    encoder.train(); decoder.train(); unet.train()\n",
        "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    for images, _ in pbar:\n",
        "        images = images.to(device)\n",
        "        with autocast(device_type=device.type):\n",
        "            z = encoder(images)\n",
        "            recon = decoder(z)\n",
        "            recon_loss = F.mse_loss(recon, images)\n",
        "            kl_loss = kl_divergence(z)\n",
        "            loss_autoenc = recon_loss + 0.001 * kl_loss\n",
        "\n",
        "            t = torch.randint(0, TIMESTEPS, (z.size(0),), device=device).long()\n",
        "            noise = torch.randn_like(z)\n",
        "            alpha_hat = scheduler_alpha_hat[t][:, None]\n",
        "            noisy_z = (alpha_hat**0.5) * z + ((1 - alpha_hat)**0.5) * noise\n",
        "            pred = unet(noisy_z, t)\n",
        "            diffusion_loss = F.mse_loss(pred, noise)\n",
        "\n",
        "            total_loss = loss_autoenc + diffusion_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(total_loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        pbar.set_description(f\"Epoch [{epoch+1}] - Total Loss: {total_loss.item():.4f}\")\n",
        "\n",
        "    # Save every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        with torch.no_grad():\n",
        "            # Sample latents from real images\n",
        "            sample_images, _ = next(iter(dataloader))\n",
        "            z_sample = encoder(sample_images.to(device))\n",
        "            samples = decoder(z_sample)\n",
        "            save_image((samples + 1) / 2, f\"ldm3_outputs/sample_epoch{epoch+1}.png\", nrow=4)\n",
        "            torch.save(encoder.state_dict(), f\"ldm3_outputs/encoder_epoch{epoch+1}.pth\")\n",
        "            torch.save(decoder.state_dict(), f\"ldm3_outputs/decoder_epoch{epoch+1}.pth\")\n",
        "            torch.save(unet.state_dict(),    f\"ldm3_outputs/unet_epoch{epoch+1}.pth\")\n",
        "            print(f\"✅ Saved: sample_epoch{epoch+1}.png and model checkpoints\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AfXRL3hkIwY",
        "outputId": "999eeaa8-bc3e-48a7-df14-7fc0d8a77185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 50 images generated from real latents\n",
            "✅ Zipped outputs at: ldm3_outputs/generated_best.zip\n"
          ]
        }
      ],
      "source": [
        "#FINAL EXECUTED CODE GENERATION\n",
        "# ✅ GENERATION CODE MATCHING TRAINING QUALITY (REAL LATENTS + DDIM OPTION + ZIP)\n",
        "import torch, os, zipfile\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import trange\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# ✅ CONFIG (same as training)\n",
        "LATENT_DIM = 1024\n",
        "TIMESTEPS = 1000\n",
        "IMG_SIZE = 512\n",
        "DATA_PATH = \"/content/drive/MyDrive/ANTHRECNOSE\"\n",
        "\n",
        "# ✅ DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ Schedulers (same as training)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# ✅ DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "dataset = SingleClassImageDataset(DATA_PATH, transform)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "\n",
        "# ✅ MODELS (same as training)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# ✅ Instantiate models\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "\n",
        "# ✅ Load trained weights\n",
        "encoder.load_state_dict(torch.load(\"ldm3_outputs/encoder_epoch1000.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"ldm3_outputs/decoder_epoch1000.pth\"))\n",
        "unet.load_state_dict(torch.load(\"ldm3_outputs/unet_epoch1000.pth\"))\n",
        "encoder.eval(); decoder.eval(); unet.eval()\n",
        "\n",
        "# ✅ OUTPUT FOLDER\n",
        "output_dir = \"ldm3_outputs/generated_best\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ✅ Option 1: Sampling from real encoded latents\n",
        "@torch.no_grad()\n",
        "def generate_from_real_latents(encoder_model, decoder_model, dataloader, num_samples=50):\n",
        "    count = 0\n",
        "    for images, _ in dataloader:\n",
        "        z = encoder_model(images.to(device))\n",
        "        imgs = decoder_model(z)\n",
        "        imgs = (imgs + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(output_dir, f\"real_latent_{count + j + 1:05}.png\"))\n",
        "        count += len(imgs)\n",
        "        if count >= num_samples:\n",
        "            break\n",
        "    print(f\"✅ {num_samples} images generated from real latents\")\n",
        "\n",
        "# ✅ Option 2: DDIM sampling from noise\n",
        "@torch.no_grad()\n",
        "def generate_ddim(unet_model, decoder_model, steps=200, batch_size=8, total=50):\n",
        "    for i in trange(0, total, batch_size):\n",
        "        bs = min(batch_size, total - i)\n",
        "        z = torch.randn(bs, LATENT_DIM).to(device)\n",
        "        for t in reversed(range(steps)):\n",
        "            t_tensor = torch.full((bs,), t, dtype=torch.long, device=device)\n",
        "            beta = scheduler_betas[t]\n",
        "            alpha = scheduler_alphas[t]\n",
        "            alpha_hat = scheduler_alpha_hat[t]\n",
        "            noise_pred = unet_model(z, t_tensor)\n",
        "            z = (z - beta / torch.sqrt(1 - alpha_hat) * noise_pred) / torch.sqrt(alpha)\n",
        "            if t > 0:\n",
        "                z += torch.randn_like(z) * beta.sqrt()\n",
        "        imgs = (decoder_model(z) + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(output_dir, f\"ddim_sample_{i + j + 1:05}.png\"))\n",
        "    print(f\"✅ {total} images generated using DDIM\")\n",
        "\n",
        "# 🔁 Select mode below:\n",
        "mode = \"real\"  # or \"ddim\"\n",
        "\n",
        "if mode == \"real\":\n",
        "    generate_from_real_latents(encoder, decoder, dataloader, num_samples=50)\n",
        "else:\n",
        "    generate_ddim(unet, decoder, steps=200, batch_size=8, total=50)\n",
        "\n",
        "# ✅ ZIP GENERATED IMAGES\n",
        "zip_path = output_dir + \".zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, _, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), arcname=file)\n",
        "print(f\"✅ Zipped outputs at: {zip_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnJP30F902hQ",
        "outputId": "c7404b86-aaf5-4da1-b627-e5b17b9460f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 5000 images generated from real latents\n",
            "✅ Zipped outputs at: ldm9_outputs/generated_best.zip\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "✅ LPIPS Diversity Score: 0.5961\n",
            "✅ FID Score: 6.62\n"
          ]
        }
      ],
      "source": [
        "# ✅ GENERATION CODE MATCHING TRAINING QUALITY (REAL LATENTS + DDIM OPTION + ZIP + FID/LPIPS)\n",
        "import torch, os, zipfile\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import trange\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from scipy import linalg\n",
        "from itertools import cycle\n",
        "\n",
        "# ✅ CONFIG (same as training)\n",
        "LATENT_DIM = 1024\n",
        "TIMESTEPS = 1000\n",
        "IMG_SIZE = 512\n",
        "DATA_PATH = \"/content/drive/MyDrive/ANTHRECNOSE\"\n",
        "\n",
        "# ✅ DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ Schedulers (same as training)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# ✅ DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "ref_transform = T.Compose([\n",
        "    T.Resize((299, 299)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Real data loader for FID\n",
        "ref_dataset = SingleClassImageDataset(DATA_PATH, ref_transform)\n",
        "ref_loader = DataLoader(ref_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ✅ MODELS (same as training)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# ✅ Instantiate models\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "\n",
        "# ✅ Load trained weights\n",
        "encoder.load_state_dict(torch.load(\"ldm3_outputs/encoder_epoch1000.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"ldm3_outputs/decoder_epoch1000.pth\"))\n",
        "unet.load_state_dict(torch.load(\"ldm3_outputs/unet_epoch1000.pth\"))\n",
        "encoder.eval(); decoder.eval(); unet.eval()\n",
        "\n",
        "# ✅ OUTPUT FOLDER\n",
        "output_dir = \"ldm9_outputs/generated_best\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ✅ Generation function (real latents)\n",
        "@torch.no_grad()\n",
        "def generate_from_real_latents(encoder_model, decoder_model, dataloader, num_samples=5000):\n",
        "    count = 0\n",
        "    loop_loader = cycle(dataloader)  # Infinite loop over dataset\n",
        "    for images, _ in loop_loader:\n",
        "        z = encoder_model(images.to(device))\n",
        "        imgs = decoder_model(z)\n",
        "        imgs = (imgs + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(output_dir, f\"real_latent_{count + j + 1:05}.png\"))\n",
        "        count += len(imgs)\n",
        "        if count >= num_samples:\n",
        "            break\n",
        "    print(f\"✅ {num_samples} images generated from real latents\")\n",
        "\n",
        "# ✅ Generation function (DDIM)\n",
        "@torch.no_grad()\n",
        "def generate_ddim(unet_model, decoder_model, steps=250, batch_size=8, total=5000):\n",
        "    for i in trange(0, total, batch_size):\n",
        "        bs = min(batch_size, total - i)\n",
        "        z = torch.randn(bs, LATENT_DIM).to(device)\n",
        "        for t in reversed(range(steps)):\n",
        "            t_tensor = torch.full((bs,), t, dtype=torch.long, device=device)\n",
        "            beta = scheduler_betas[t]\n",
        "            alpha = scheduler_alphas[t]\n",
        "            alpha_hat = scheduler_alpha_hat[t]\n",
        "            noise_pred = unet_model(z, t_tensor)\n",
        "            z = (z - beta / torch.sqrt(1 - alpha_hat) * noise_pred) / torch.sqrt(alpha)\n",
        "            if t > 0:\n",
        "                z += torch.randn_like(z) * beta.sqrt()\n",
        "        imgs = (decoder_model(z) + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(output_dir, f\"ddim_sample_{i + j + 1:05}.png\"))\n",
        "    print(f\"✅ {total} images generated using DDIM\")\n",
        "\n",
        "# 🔁 Mode selector\n",
        "mode = \"real\"\n",
        "if mode == \"real\":\n",
        "    generate_from_real_latents(encoder, decoder, DataLoader(SingleClassImageDataset(DATA_PATH, transform), batch_size=8, shuffle=True), num_samples=5000)\n",
        "else:\n",
        "    generate_ddim(unet, decoder, steps=250, batch_size=8, total=5000)\n",
        "\n",
        "# ✅ ZIP GENERATED IMAGES\n",
        "zip_path = output_dir + \".zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, _, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), arcname=file)\n",
        "print(f\"✅ Zipped outputs at: {zip_path}\")\n",
        "\n",
        "# ✅ LPIPS Diversity\n",
        "!pip install lpips --quiet\n",
        "import lpips\n",
        "lpips_model = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "img_paths = sorted([os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(\".png\")])[:100]\n",
        "imgs = [transform(Image.open(p).convert(\"RGB\")).unsqueeze(0).to(device) for p in img_paths]\n",
        "\n",
        "div_sum = 0\n",
        "pairs = 0\n",
        "for i in range(len(imgs)):\n",
        "    for j in range(i+1, len(imgs)):\n",
        "        dist = lpips_model(imgs[i], imgs[j])\n",
        "        div_sum += dist.item()\n",
        "        pairs += 1\n",
        "print(f\"✅ LPIPS Diversity Score: {div_sum/pairs:.4f}\")\n",
        "\n",
        "# ✅ FID Score\n",
        "@torch.no_grad()\n",
        "def get_activations(dataloader, model):\n",
        "    model.eval()\n",
        "    activations = []\n",
        "    up = T.Resize((299, 299))\n",
        "    for imgs, _ in dataloader:\n",
        "        imgs = up(imgs).to(device)\n",
        "        preds = model(imgs)\n",
        "        if isinstance(preds, tuple):\n",
        "            preds = preds[0]\n",
        "        preds = preds.view(preds.size(0), -1)\n",
        "        activations.append(preds.cpu().numpy())\n",
        "    return np.concatenate(activations, axis=0)\n",
        "\n",
        "inception = models.inception_v3(pretrained=True, transform_input=False).to(device)\n",
        "inception.fc = nn.Identity()\n",
        "inception.eval()\n",
        "\n",
        "# Generated loader for FID\n",
        "gen_dataset = SingleClassImageDataset(output_dir, ref_transform)\n",
        "gen_loader = DataLoader(gen_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "act1 = get_activations(ref_loader, inception)\n",
        "act2 = get_activations(gen_loader, inception)\n",
        "mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
        "mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
        "\n",
        "fid = np.sum((mu1 - mu2)**2) + np.trace(sigma1 + sigma2 - 2 * linalg.sqrtm(sigma1.dot(sigma2)).real)\n",
        "print(f\"✅ FID Score: {fid:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YYOoN-We-cnd",
        "outputId": "4e014ae2-ed27-44db-b05a-48063b587522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 5000 images generated from real latents\n",
            "✅ Zipped outputs at: ldm10_outputs/generated_best_2.zip\n"
          ]
        }
      ],
      "source": [
        "#GENERATING NEXT 5000 IMAGES\n",
        "# ✅ GENERATION CODE MATCHING TRAINING QUALITY (REAL LATENTS + DDIM OPTION + ZIP + FID/LPIPS)\n",
        "import torch, os, zipfile\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import trange\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from scipy import linalg\n",
        "from itertools import cycle\n",
        "\n",
        "# ✅ CONFIG (same as training)\n",
        "LATENT_DIM = 1024\n",
        "TIMESTEPS = 1000\n",
        "IMG_SIZE = 512\n",
        "DATA_PATH = \"/content/drive/MyDrive/ANTHRECNOSE\"\n",
        "\n",
        "# ✅ DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ Schedulers (same as training)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# ✅ DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "ref_transform = T.Compose([\n",
        "    T.Resize((299, 299)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Real data loader for FID\n",
        "ref_dataset = SingleClassImageDataset(DATA_PATH, ref_transform)\n",
        "ref_loader = DataLoader(ref_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ✅ MODELS (same as training)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# ✅ Instantiate models\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "\n",
        "# ✅ Load trained weights\n",
        "encoder.load_state_dict(torch.load(\"ldm3_outputs/encoder_epoch1000.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"ldm3_outputs/decoder_epoch1000.pth\"))\n",
        "unet.load_state_dict(torch.load(\"ldm3_outputs/unet_epoch1000.pth\"))\n",
        "encoder.eval(); decoder.eval(); unet.eval()\n",
        "\n",
        "# ✅ OUTPUT FOLDER\n",
        "output_dir = \"ldm10_outputs/generated_best_2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ✅ Generation function (real latents)\n",
        "@torch.no_grad()\n",
        "def generate_from_real_latents(encoder_model, decoder_model, dataloader, num_samples=5000, offset=5000):\n",
        "    count = 0\n",
        "    loop_loader = cycle(dataloader)  # Infinite loop over dataset\n",
        "    for images, _ in loop_loader:\n",
        "        z = encoder_model(images.to(device))\n",
        "        imgs = decoder_model(z)\n",
        "        imgs = (imgs + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            index = offset + count + j + 1\n",
        "            save_image(img, os.path.join(output_dir, f\"real_latent_{index:05}.png\"))\n",
        "        count += len(imgs)\n",
        "        if count >= num_samples:\n",
        "            break\n",
        "    print(f\"✅ {num_samples} images generated from real latents\")\n",
        "\n",
        "# ✅ Mode selector\n",
        "mode = \"real\"\n",
        "if mode == \"real\":\n",
        "    generate_from_real_latents(encoder, decoder, DataLoader(SingleClassImageDataset(DATA_PATH, transform), batch_size=8, shuffle=True), num_samples=5000, offset=5000)\n",
        "\n",
        "# ✅ ZIP GENERATED IMAGES\n",
        "zip_path = output_dir + \".zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, _, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), arcname=file)\n",
        "print(f\"✅ Zipped outputs at: {zip_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}