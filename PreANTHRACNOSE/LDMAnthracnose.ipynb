{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d9iwlBR9kBW",
        "outputId": "17f7cd30-b350-442d-e6d7-45f25d369e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGFQ20hCPfwi",
        "outputId": "f3226612-cae0-4be1-f204-d72e6b9a1e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸš€ Starting Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1] - Total Loss: 1.1535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:18<00:00,  1.27it/s]\n",
            "Epoch [2] - Total Loss: 1.1019: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [3] - Total Loss: 1.0819: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [4] - Total Loss: 1.0183: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.66it/s]\n",
            "Epoch [5] - Total Loss: 1.0287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [6] - Total Loss: 1.0188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [7] - Total Loss: 1.0167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [8] - Total Loss: 1.0604: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.49it/s]\n",
            "Epoch [9] - Total Loss: 1.0642: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [10] - Total Loss: 1.0355: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.52it/s]\n",
            "Epoch [11] - Total Loss: 1.0544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [12] - Total Loss: 1.0293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.56it/s]\n",
            "Epoch [13] - Total Loss: 1.0341: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [14] - Total Loss: 1.0313: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.44it/s]\n",
            "Epoch [15] - Total Loss: 1.0350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.55it/s]\n",
            "Epoch [16] - Total Loss: 1.0383: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [17] - Total Loss: 1.0406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [18] - Total Loss: 1.0377: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [19] - Total Loss: 1.0114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [20] - Total Loss: 0.9910: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch20.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [21] - Total Loss: 1.0090: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.43it/s]\n",
            "Epoch [22] - Total Loss: 1.0356: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.80it/s]\n",
            "Epoch [23] - Total Loss: 1.0255: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [24] - Total Loss: 1.0231: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [25] - Total Loss: 1.0049: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.58it/s]\n",
            "Epoch [26] - Total Loss: 1.0423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [27] - Total Loss: 1.0115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [28] - Total Loss: 1.0380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [29] - Total Loss: 1.0197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [30] - Total Loss: 1.0060: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [31] - Total Loss: 1.0166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [32] - Total Loss: 0.9779: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.89it/s]\n",
            "Epoch [33] - Total Loss: 0.9615: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [34] - Total Loss: 0.9985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [35] - Total Loss: 1.0253: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [36] - Total Loss: 1.0144: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [37] - Total Loss: 0.9971: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [38] - Total Loss: 0.9961: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [39] - Total Loss: 0.9785: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [40] - Total Loss: 0.9822: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch40.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [41] - Total Loss: 0.9607: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.53it/s]\n",
            "Epoch [42] - Total Loss: 0.9523: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [43] - Total Loss: 0.9957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [44] - Total Loss: 0.9962: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [45] - Total Loss: 0.9466: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.68it/s]\n",
            "Epoch [46] - Total Loss: 0.9749: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [47] - Total Loss: 0.9605: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [48] - Total Loss: 0.9831: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [49] - Total Loss: 0.9522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [50] - Total Loss: 0.9734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.43it/s]\n",
            "Epoch [51] - Total Loss: 0.9435: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [52] - Total Loss: 0.9537: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [53] - Total Loss: 0.9609: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.64it/s]\n",
            "Epoch [54] - Total Loss: 0.9777: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [55] - Total Loss: 0.9350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [56] - Total Loss: 0.9346: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [57] - Total Loss: 0.9509: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [58] - Total Loss: 0.9994: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.56it/s]\n",
            "Epoch [59] - Total Loss: 1.0002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [60] - Total Loss: 0.9931: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch60.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [61] - Total Loss: 0.9419: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  7.14it/s]\n",
            "Epoch [62] - Total Loss: 0.9838: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [63] - Total Loss: 0.9371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [64] - Total Loss: 0.9635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [65] - Total Loss: 0.9086: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 10.50it/s]\n",
            "Epoch [66] - Total Loss: 0.9200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [67] - Total Loss: 0.9297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [68] - Total Loss: 0.9741: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [69] - Total Loss: 0.9341: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [70] - Total Loss: 0.9160: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [71] - Total Loss: 0.9506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [72] - Total Loss: 0.9478: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [73] - Total Loss: 0.9383: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [74] - Total Loss: 0.9135: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.44it/s]\n",
            "Epoch [75] - Total Loss: 0.9504: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.79it/s]\n",
            "Epoch [76] - Total Loss: 0.9416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [77] - Total Loss: 0.9246: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [78] - Total Loss: 0.9119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [79] - Total Loss: 0.9046: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [80] - Total Loss: 0.9436: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch80.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [81] - Total Loss: 0.8900: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.81it/s]\n",
            "Epoch [82] - Total Loss: 0.9183: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [83] - Total Loss: 0.8882: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [84] - Total Loss: 0.9051: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 12.65it/s]\n",
            "Epoch [85] - Total Loss: 0.9176: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 15.93it/s]\n",
            "Epoch [86] - Total Loss: 0.9166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [87] - Total Loss: 0.9228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [88] - Total Loss: 0.9039: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [89] - Total Loss: 0.9181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [90] - Total Loss: 0.9173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [91] - Total Loss: 0.9173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [92] - Total Loss: 0.9055: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [93] - Total Loss: 0.9411: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [94] - Total Loss: 0.9103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [95] - Total Loss: 0.9055: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [96] - Total Loss: 0.8945: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [97] - Total Loss: 0.8864: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [98] - Total Loss: 0.9026: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [99] - Total Loss: 0.8734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.93it/s]\n",
            "Epoch [100] - Total Loss: 0.8809: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch100.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [101] - Total Loss: 0.8736: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.89it/s]\n",
            "Epoch [102] - Total Loss: 0.8532: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [103] - Total Loss: 0.9203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [104] - Total Loss: 0.8843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [105] - Total Loss: 0.8691: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.50it/s]\n",
            "Epoch [106] - Total Loss: 0.8521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [107] - Total Loss: 0.8788: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [108] - Total Loss: 0.8945: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [109] - Total Loss: 0.8806: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [110] - Total Loss: 0.8714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [111] - Total Loss: 0.8675: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [112] - Total Loss: 0.8946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [113] - Total Loss: 0.9192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [114] - Total Loss: 0.9233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [115] - Total Loss: 0.8447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [116] - Total Loss: 0.8681: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [117] - Total Loss: 0.8466: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [118] - Total Loss: 0.8730: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [119] - Total Loss: 0.9114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [120] - Total Loss: 0.8840: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch120.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [121] - Total Loss: 0.8675: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.53it/s]\n",
            "Epoch [122] - Total Loss: 0.8595: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [123] - Total Loss: 0.8580: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [124] - Total Loss: 0.8536: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [125] - Total Loss: 0.8826: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [126] - Total Loss: 0.8626: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [127] - Total Loss: 0.8496: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [128] - Total Loss: 0.8336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [129] - Total Loss: 0.8394: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [130] - Total Loss: 0.8563: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [131] - Total Loss: 0.8281: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [132] - Total Loss: 0.8714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [133] - Total Loss: 0.8784: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [134] - Total Loss: 0.8245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [135] - Total Loss: 0.8632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [136] - Total Loss: 0.8763: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [137] - Total Loss: 0.8903: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.43it/s]\n",
            "Epoch [138] - Total Loss: 0.8576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [139] - Total Loss: 0.8372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [140] - Total Loss: 0.8197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch140.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [141] - Total Loss: 0.8362: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.87it/s]\n",
            "Epoch [142] - Total Loss: 0.8401: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.43it/s]\n",
            "Epoch [143] - Total Loss: 0.8091: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [144] - Total Loss: 0.8447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 11.56it/s]\n",
            "Epoch [145] - Total Loss: 0.8339: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [146] - Total Loss: 0.8396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [147] - Total Loss: 0.8306: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [148] - Total Loss: 0.8415: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [149] - Total Loss: 0.8311: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [150] - Total Loss: 0.8746: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [151] - Total Loss: 0.8658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [152] - Total Loss: 0.8303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [153] - Total Loss: 0.8537: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [154] - Total Loss: 0.8420: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [155] - Total Loss: 0.7957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [156] - Total Loss: 0.8625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [157] - Total Loss: 0.8095: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [158] - Total Loss: 0.8287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [159] - Total Loss: 0.7990: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [160] - Total Loss: 0.8000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch160.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [161] - Total Loss: 0.8275: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.80it/s]\n",
            "Epoch [162] - Total Loss: 0.8170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.47it/s]\n",
            "Epoch [163] - Total Loss: 0.8024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [164] - Total Loss: 0.8423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [165] - Total Loss: 0.8109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 15.35it/s]\n",
            "Epoch [166] - Total Loss: 0.8270: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.50it/s]\n",
            "Epoch [167] - Total Loss: 0.7689: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [168] - Total Loss: 0.7763: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [169] - Total Loss: 0.8402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.93it/s]\n",
            "Epoch [170] - Total Loss: 0.8054: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [171] - Total Loss: 0.8228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [172] - Total Loss: 0.7996: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [173] - Total Loss: 0.8406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [174] - Total Loss: 0.7930: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [175] - Total Loss: 0.8912: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [176] - Total Loss: 0.7824: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [177] - Total Loss: 0.7918: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [178] - Total Loss: 0.8114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.88it/s]\n",
            "Epoch [179] - Total Loss: 0.8574: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [180] - Total Loss: 0.8158: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch180.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [181] - Total Loss: 0.8483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.73it/s]\n",
            "Epoch [182] - Total Loss: 0.7903: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [183] - Total Loss: 0.8199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [184] - Total Loss: 0.8169: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [185] - Total Loss: 0.8062: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 14.97it/s]\n",
            "Epoch [186] - Total Loss: 0.8234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [187] - Total Loss: 0.7856: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [188] - Total Loss: 0.8357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [189] - Total Loss: 0.7638: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [190] - Total Loss: 0.7952: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [191] - Total Loss: 0.7697: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [192] - Total Loss: 0.7854: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [193] - Total Loss: 0.7878: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [194] - Total Loss: 0.8503: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [195] - Total Loss: 0.8229: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [196] - Total Loss: 0.8079: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [197] - Total Loss: 0.7943: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [198] - Total Loss: 0.7928: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [199] - Total Loss: 0.7915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [200] - Total Loss: 0.8216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch200.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [201] - Total Loss: 0.7971: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.69it/s]\n",
            "Epoch [202] - Total Loss: 0.8296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [203] - Total Loss: 0.7881: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [204] - Total Loss: 0.8202: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [205] - Total Loss: 0.7778: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [206] - Total Loss: 0.7568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [207] - Total Loss: 0.7688: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [208] - Total Loss: 0.7628: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [209] - Total Loss: 0.7895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [210] - Total Loss: 0.8131: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [211] - Total Loss: 0.7497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [212] - Total Loss: 0.8156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [213] - Total Loss: 0.7679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [214] - Total Loss: 0.8178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [215] - Total Loss: 0.8200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [216] - Total Loss: 0.8031: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [217] - Total Loss: 0.7633: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [218] - Total Loss: 0.7514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [219] - Total Loss: 0.7446: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [220] - Total Loss: 0.8117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch220.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [221] - Total Loss: 0.7443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.71it/s]\n",
            "Epoch [222] - Total Loss: 0.7814: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [223] - Total Loss: 0.7754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [224] - Total Loss: 0.7566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.50it/s]\n",
            "Epoch [225] - Total Loss: 0.8199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.12it/s]\n",
            "Epoch [226] - Total Loss: 0.7762: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [227] - Total Loss: 0.7267: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [228] - Total Loss: 0.7687: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [229] - Total Loss: 0.7598: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [230] - Total Loss: 0.7938: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [231] - Total Loss: 0.7377: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [232] - Total Loss: 0.7929: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [233] - Total Loss: 0.7667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [234] - Total Loss: 0.7704: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [235] - Total Loss: 0.8037: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.92it/s]\n",
            "Epoch [236] - Total Loss: 0.7782: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.73it/s]\n",
            "Epoch [237] - Total Loss: 0.7726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [238] - Total Loss: 0.7918: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [239] - Total Loss: 0.8141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [240] - Total Loss: 0.8014: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch240.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [241] - Total Loss: 0.7452: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.49it/s]\n",
            "Epoch [242] - Total Loss: 0.7491: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [243] - Total Loss: 0.7863: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [244] - Total Loss: 0.7548: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.51it/s]\n",
            "Epoch [245] - Total Loss: 0.8132: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 11.52it/s]\n",
            "Epoch [246] - Total Loss: 0.7935: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [247] - Total Loss: 0.7839: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [248] - Total Loss: 0.7452: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.89it/s]\n",
            "Epoch [249] - Total Loss: 0.7397: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [250] - Total Loss: 0.7427: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [251] - Total Loss: 0.7896: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [252] - Total Loss: 0.7688: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [253] - Total Loss: 0.7889: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.53it/s]\n",
            "Epoch [254] - Total Loss: 0.8089: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [255] - Total Loss: 0.7591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [256] - Total Loss: 0.7399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [257] - Total Loss: 0.7626: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [258] - Total Loss: 0.8156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [259] - Total Loss: 0.8799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [260] - Total Loss: 0.7862: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch260.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [261] - Total Loss: 0.7510: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.00it/s]\n",
            "Epoch [262] - Total Loss: 0.7880: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [263] - Total Loss: 0.7939: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [264] - Total Loss: 0.7854: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [265] - Total Loss: 0.7422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 13.30it/s]\n",
            "Epoch [266] - Total Loss: 0.7717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [267] - Total Loss: 0.8133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [268] - Total Loss: 0.7361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [269] - Total Loss: 0.7348: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [270] - Total Loss: 0.7778: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [271] - Total Loss: 0.7779: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.86it/s]\n",
            "Epoch [272] - Total Loss: 0.7806: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [273] - Total Loss: 0.7371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [274] - Total Loss: 0.7732: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [275] - Total Loss: 0.7769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [276] - Total Loss: 0.7738: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [277] - Total Loss: 0.7307: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.50it/s]\n",
            "Epoch [278] - Total Loss: 0.7499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.74it/s]\n",
            "Epoch [279] - Total Loss: 0.7625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [280] - Total Loss: 0.7350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch280.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [281] - Total Loss: 0.7528: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.28it/s]\n",
            "Epoch [282] - Total Loss: 0.7587: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [283] - Total Loss: 0.7386: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.82it/s]\n",
            "Epoch [284] - Total Loss: 0.7828: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [285] - Total Loss: 0.8177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [286] - Total Loss: 0.7542: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [287] - Total Loss: 0.7459: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [288] - Total Loss: 0.7175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [289] - Total Loss: 0.7403: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [290] - Total Loss: 0.7462: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [291] - Total Loss: 0.8262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [292] - Total Loss: 0.7407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [293] - Total Loss: 0.7277: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.79it/s]\n",
            "Epoch [294] - Total Loss: 0.7268: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [295] - Total Loss: 0.7586: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [296] - Total Loss: 0.7690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.45it/s]\n",
            "Epoch [297] - Total Loss: 0.7296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [298] - Total Loss: 0.7319: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [299] - Total Loss: 0.7708: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [300] - Total Loss: 0.8011: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch300.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [301] - Total Loss: 0.7816: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.05it/s]\n",
            "Epoch [302] - Total Loss: 0.7656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.84it/s]\n",
            "Epoch [303] - Total Loss: 0.7236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [304] - Total Loss: 0.7214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [305] - Total Loss: 0.8032: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [306] - Total Loss: 0.6943: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [307] - Total Loss: 0.8095: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [308] - Total Loss: 0.7180: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.43it/s]\n",
            "Epoch [309] - Total Loss: 0.7874: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [310] - Total Loss: 0.7219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [311] - Total Loss: 0.7278: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [312] - Total Loss: 0.7601: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [313] - Total Loss: 0.7911: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [314] - Total Loss: 0.7547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [315] - Total Loss: 0.6975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [316] - Total Loss: 0.7485: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [317] - Total Loss: 0.6728: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [318] - Total Loss: 0.8182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [319] - Total Loss: 0.6865: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.49it/s]\n",
            "Epoch [320] - Total Loss: 0.8147: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch320.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [321] - Total Loss: 0.7784: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.87it/s]\n",
            "Epoch [322] - Total Loss: 0.7219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [323] - Total Loss: 0.7501: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [324] - Total Loss: 0.8006: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [325] - Total Loss: 0.7121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 10.57it/s]\n",
            "Epoch [326] - Total Loss: 0.7455: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [327] - Total Loss: 0.7923: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [328] - Total Loss: 0.7244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [329] - Total Loss: 0.7162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [330] - Total Loss: 0.7895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [331] - Total Loss: 0.7614: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [332] - Total Loss: 0.8064: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [333] - Total Loss: 0.7472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [334] - Total Loss: 0.7000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [335] - Total Loss: 0.7399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [336] - Total Loss: 0.7539: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [337] - Total Loss: 0.7374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [338] - Total Loss: 0.7022: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [339] - Total Loss: 0.7225: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [340] - Total Loss: 0.7430: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch340.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [341] - Total Loss: 0.8095: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.69it/s]\n",
            "Epoch [342] - Total Loss: 0.6980: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [343] - Total Loss: 0.7002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.47it/s]\n",
            "Epoch [344] - Total Loss: 0.7134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [345] - Total Loss: 0.7696: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 10.96it/s]\n",
            "Epoch [346] - Total Loss: 0.7889: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.54it/s]\n",
            "Epoch [347] - Total Loss: 0.6943: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [348] - Total Loss: 0.7449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.75it/s]\n",
            "Epoch [349] - Total Loss: 0.7514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [350] - Total Loss: 0.7616: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [351] - Total Loss: 0.7703: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [352] - Total Loss: 0.7461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [353] - Total Loss: 0.7290: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [354] - Total Loss: 0.6998: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [355] - Total Loss: 0.7145: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [356] - Total Loss: 0.6979: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [357] - Total Loss: 0.7420: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [358] - Total Loss: 0.7019: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [359] - Total Loss: 0.7243: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [360] - Total Loss: 0.7906: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch360.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [361] - Total Loss: 0.7980: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.90it/s]\n",
            "Epoch [362] - Total Loss: 0.7634: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [363] - Total Loss: 0.8061: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [364] - Total Loss: 0.7294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [365] - Total Loss: 0.7545: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 15.05it/s]\n",
            "Epoch [366] - Total Loss: 0.7995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [367] - Total Loss: 0.7424: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [368] - Total Loss: 0.7192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [369] - Total Loss: 0.7189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [370] - Total Loss: 0.7609: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [371] - Total Loss: 0.7316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [372] - Total Loss: 0.7275: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [373] - Total Loss: 0.6930: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [374] - Total Loss: 0.7245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [375] - Total Loss: 0.7001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.51it/s]\n",
            "Epoch [376] - Total Loss: 0.7180: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [377] - Total Loss: 0.7719: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [378] - Total Loss: 0.7296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [379] - Total Loss: 0.7148: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [380] - Total Loss: 0.7467: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch380.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [381] - Total Loss: 0.6885: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.54it/s]\n",
            "Epoch [382] - Total Loss: 0.7744: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [383] - Total Loss: 0.7584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [384] - Total Loss: 0.6696: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [385] - Total Loss: 0.6920: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 13.35it/s]\n",
            "Epoch [386] - Total Loss: 0.7458: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [387] - Total Loss: 0.7055: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [388] - Total Loss: 0.7645: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.44it/s]\n",
            "Epoch [389] - Total Loss: 0.6969: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [390] - Total Loss: 0.7647: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [391] - Total Loss: 0.7168: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [392] - Total Loss: 0.7535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [393] - Total Loss: 0.6858: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [394] - Total Loss: 0.7092: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [395] - Total Loss: 0.6985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [396] - Total Loss: 0.8039: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [397] - Total Loss: 0.7168: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [398] - Total Loss: 0.7259: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [399] - Total Loss: 0.6765: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [400] - Total Loss: 0.7303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch400.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [401] - Total Loss: 0.7268: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.49it/s]\n",
            "Epoch [402] - Total Loss: 0.6975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [403] - Total Loss: 0.7134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [404] - Total Loss: 0.7381: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [405] - Total Loss: 0.7230: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [406] - Total Loss: 0.7295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.79it/s]\n",
            "Epoch [407] - Total Loss: 0.6850: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [408] - Total Loss: 0.7234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.36it/s]\n",
            "Epoch [409] - Total Loss: 0.7677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [410] - Total Loss: 0.6782: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [411] - Total Loss: 0.7275: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [412] - Total Loss: 0.7276: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [413] - Total Loss: 0.7321: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [414] - Total Loss: 0.7007: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [415] - Total Loss: 0.7321: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [416] - Total Loss: 0.7192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [417] - Total Loss: 0.7872: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [418] - Total Loss: 0.6897: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [419] - Total Loss: 0.6947: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [420] - Total Loss: 0.6829: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch420.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [421] - Total Loss: 0.7730: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.60it/s]\n",
            "Epoch [422] - Total Loss: 0.7409: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.45it/s]\n",
            "Epoch [423] - Total Loss: 0.8054: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.36it/s]\n",
            "Epoch [424] - Total Loss: 0.6904: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [425] - Total Loss: 0.7788: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [426] - Total Loss: 0.7021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [427] - Total Loss: 0.7493: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [428] - Total Loss: 0.7069: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [429] - Total Loss: 0.7105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.61it/s]\n",
            "Epoch [430] - Total Loss: 0.7472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.92it/s]\n",
            "Epoch [431] - Total Loss: 0.7028: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [432] - Total Loss: 0.6793: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [433] - Total Loss: 0.7198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [434] - Total Loss: 0.6720: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.87it/s]\n",
            "Epoch [435] - Total Loss: 0.7331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [436] - Total Loss: 0.6960: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.55it/s]\n",
            "Epoch [437] - Total Loss: 0.6793: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.72it/s]\n",
            "Epoch [438] - Total Loss: 0.6923: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.79it/s]\n",
            "Epoch [439] - Total Loss: 0.6941: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.73it/s]\n",
            "Epoch [440] - Total Loss: 0.6879: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch440.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [441] - Total Loss: 0.6906: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.20it/s]\n",
            "Epoch [442] - Total Loss: 0.6983: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [443] - Total Loss: 0.6899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [444] - Total Loss: 0.7192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 12.92it/s]\n",
            "Epoch [445] - Total Loss: 0.7051: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [446] - Total Loss: 0.7578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [447] - Total Loss: 0.7422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [448] - Total Loss: 0.7098: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [449] - Total Loss: 0.6538: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.52it/s]\n",
            "Epoch [450] - Total Loss: 0.6704: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.55it/s]\n",
            "Epoch [451] - Total Loss: 0.6727: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [452] - Total Loss: 0.7288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [453] - Total Loss: 0.7331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [454] - Total Loss: 0.7351: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [455] - Total Loss: 0.6899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [456] - Total Loss: 0.6744: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [457] - Total Loss: 0.6712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [458] - Total Loss: 0.6585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.52it/s]\n",
            "Epoch [459] - Total Loss: 0.6993: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.50it/s]\n",
            "Epoch [460] - Total Loss: 0.7294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch460.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [461] - Total Loss: 0.7066: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.30it/s]\n",
            "Epoch [462] - Total Loss: 0.7190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [463] - Total Loss: 0.6646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [464] - Total Loss: 0.7120: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.65it/s]\n",
            "Epoch [465] - Total Loss: 0.7181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [466] - Total Loss: 0.6790: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [467] - Total Loss: 0.6983: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [468] - Total Loss: 0.7277: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [469] - Total Loss: 0.6819: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [470] - Total Loss: 0.6874: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [471] - Total Loss: 0.6694: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [472] - Total Loss: 0.7361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [473] - Total Loss: 0.6459: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [474] - Total Loss: 0.6631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [475] - Total Loss: 0.7366: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [476] - Total Loss: 0.6701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [477] - Total Loss: 0.6994: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [478] - Total Loss: 0.6888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [479] - Total Loss: 0.6815: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [480] - Total Loss: 0.7752: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch480.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [481] - Total Loss: 0.6664: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.38it/s]\n",
            "Epoch [482] - Total Loss: 0.7329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [483] - Total Loss: 0.7592: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [484] - Total Loss: 0.7119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [485] - Total Loss: 0.6927: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.84it/s]\n",
            "Epoch [486] - Total Loss: 0.7353: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [487] - Total Loss: 0.7855: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [488] - Total Loss: 0.6854: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [489] - Total Loss: 0.6870: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [490] - Total Loss: 0.6913: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [491] - Total Loss: 0.6797: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [492] - Total Loss: 0.7105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [493] - Total Loss: 0.6710: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [494] - Total Loss: 0.7467: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [495] - Total Loss: 0.7054: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [496] - Total Loss: 0.6874: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [497] - Total Loss: 0.6894: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [498] - Total Loss: 0.7425: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [499] - Total Loss: 0.7374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [500] - Total Loss: 0.7325: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch500.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [501] - Total Loss: 0.7706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  7.17it/s]\n",
            "Epoch [502] - Total Loss: 0.7628: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [503] - Total Loss: 0.7524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.46it/s]\n",
            "Epoch [504] - Total Loss: 0.6583: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 10.52it/s]\n",
            "Epoch [505] - Total Loss: 0.7011: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [506] - Total Loss: 0.7006: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [507] - Total Loss: 0.7948: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [508] - Total Loss: 0.7417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [509] - Total Loss: 0.7171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [510] - Total Loss: 0.7577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [511] - Total Loss: 0.6682: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.92it/s]\n",
            "Epoch [512] - Total Loss: 0.6739: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [513] - Total Loss: 0.6870: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [514] - Total Loss: 0.7568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [515] - Total Loss: 0.6894: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [516] - Total Loss: 0.7248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [517] - Total Loss: 0.7325: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [518] - Total Loss: 0.7043: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [519] - Total Loss: 0.7301: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [520] - Total Loss: 0.6832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch520.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [521] - Total Loss: 0.6865: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.60it/s]\n",
            "Epoch [522] - Total Loss: 0.6599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [523] - Total Loss: 0.7279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [524] - Total Loss: 0.7200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [525] - Total Loss: 0.6749: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [526] - Total Loss: 0.6989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [527] - Total Loss: 0.6932: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [528] - Total Loss: 0.7464: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [529] - Total Loss: 0.7338: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [530] - Total Loss: 0.7118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [531] - Total Loss: 0.7240: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [532] - Total Loss: 0.7407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [533] - Total Loss: 0.6561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [534] - Total Loss: 0.6762: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [535] - Total Loss: 0.6754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [536] - Total Loss: 0.6864: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [537] - Total Loss: 0.6723: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [538] - Total Loss: 0.7314: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [539] - Total Loss: 0.7235: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.50it/s]\n",
            "Epoch [540] - Total Loss: 0.6758: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch540.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [541] - Total Loss: 0.8191: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.74it/s]\n",
            "Epoch [542] - Total Loss: 0.7184: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [543] - Total Loss: 0.6898: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [544] - Total Loss: 0.6784: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [545] - Total Loss: 0.7442: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 13.66it/s]\n",
            "Epoch [546] - Total Loss: 0.6633: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [547] - Total Loss: 0.6565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.54it/s]\n",
            "Epoch [548] - Total Loss: 0.6983: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [549] - Total Loss: 0.6788: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [550] - Total Loss: 0.7027: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [551] - Total Loss: 0.7248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [552] - Total Loss: 0.6418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [553] - Total Loss: 0.7195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [554] - Total Loss: 0.6487: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [555] - Total Loss: 0.6487: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [556] - Total Loss: 0.6566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.49it/s]\n",
            "Epoch [557] - Total Loss: 0.7680: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [558] - Total Loss: 0.7372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [559] - Total Loss: 0.6941: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.87it/s]\n",
            "Epoch [560] - Total Loss: 0.7116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch560.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [561] - Total Loss: 0.7213: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.48it/s]\n",
            "Epoch [562] - Total Loss: 0.7109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.51it/s]\n",
            "Epoch [563] - Total Loss: 0.6803: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.88it/s]\n",
            "Epoch [564] - Total Loss: 0.7366: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [565] - Total Loss: 0.6709: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [566] - Total Loss: 0.6724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [567] - Total Loss: 0.6547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [568] - Total Loss: 0.6567: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [569] - Total Loss: 0.7613: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [570] - Total Loss: 0.6977: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [571] - Total Loss: 0.7380: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [572] - Total Loss: 0.6779: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.74it/s]\n",
            "Epoch [573] - Total Loss: 0.6702: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.69it/s]\n",
            "Epoch [574] - Total Loss: 0.6754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [575] - Total Loss: 0.6562: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [576] - Total Loss: 0.7421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [577] - Total Loss: 0.7430: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [578] - Total Loss: 0.6690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [579] - Total Loss: 0.6581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [580] - Total Loss: 0.7087: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch580.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [581] - Total Loss: 0.6384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.59it/s]\n",
            "Epoch [582] - Total Loss: 0.7289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [583] - Total Loss: 0.7188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [584] - Total Loss: 0.6980: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [585] - Total Loss: 0.6756: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 11.16it/s]\n",
            "Epoch [586] - Total Loss: 0.7254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [587] - Total Loss: 0.6758: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [588] - Total Loss: 0.6529: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [589] - Total Loss: 0.6626: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [590] - Total Loss: 0.7665: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [591] - Total Loss: 0.6867: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [592] - Total Loss: 0.6856: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [593] - Total Loss: 0.7632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [594] - Total Loss: 0.6858: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [595] - Total Loss: 0.6463: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.69it/s]\n",
            "Epoch [596] - Total Loss: 0.6565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [597] - Total Loss: 0.6990: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [598] - Total Loss: 0.6447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [599] - Total Loss: 0.6405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [600] - Total Loss: 0.6536: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch600.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [601] - Total Loss: 0.6699: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.17it/s]\n",
            "Epoch [602] - Total Loss: 0.6558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.48it/s]\n",
            "Epoch [603] - Total Loss: 0.7862: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [604] - Total Loss: 0.6896: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [605] - Total Loss: 0.6563: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 13.19it/s]\n",
            "Epoch [606] - Total Loss: 0.7202: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [607] - Total Loss: 0.6795: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [608] - Total Loss: 0.6903: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [609] - Total Loss: 0.6726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [610] - Total Loss: 0.7435: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [611] - Total Loss: 0.6815: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [612] - Total Loss: 0.6869: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [613] - Total Loss: 0.7230: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [614] - Total Loss: 0.6872: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.87it/s]\n",
            "Epoch [615] - Total Loss: 0.6754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [616] - Total Loss: 0.6499: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [617] - Total Loss: 0.6377: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [618] - Total Loss: 0.6899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [619] - Total Loss: 0.6740: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [620] - Total Loss: 0.6680: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch620.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [621] - Total Loss: 0.7433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.47it/s]\n",
            "Epoch [622] - Total Loss: 0.6547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [623] - Total Loss: 0.6821: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [624] - Total Loss: 0.6780: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [625] - Total Loss: 0.7175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [626] - Total Loss: 0.7624: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [627] - Total Loss: 0.6565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [628] - Total Loss: 0.6480: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [629] - Total Loss: 0.6704: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.67it/s]\n",
            "Epoch [630] - Total Loss: 0.6623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [631] - Total Loss: 0.6852: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [632] - Total Loss: 0.6584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [633] - Total Loss: 0.6955: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [634] - Total Loss: 0.6768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [635] - Total Loss: 0.7216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [636] - Total Loss: 0.7077: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [637] - Total Loss: 0.6397: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [638] - Total Loss: 0.7116: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.66it/s]\n",
            "Epoch [639] - Total Loss: 0.6571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [640] - Total Loss: 0.6888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch640.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [641] - Total Loss: 0.6849: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.73it/s]\n",
            "Epoch [642] - Total Loss: 0.6752: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [643] - Total Loss: 0.7530: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [644] - Total Loss: 0.6481: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [645] - Total Loss: 0.7138: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 10.85it/s]\n",
            "Epoch [646] - Total Loss: 0.7378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [647] - Total Loss: 0.6608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [648] - Total Loss: 0.6594: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.45it/s]\n",
            "Epoch [649] - Total Loss: 0.6522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [650] - Total Loss: 0.6298: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [651] - Total Loss: 0.7247: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [652] - Total Loss: 0.6769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [653] - Total Loss: 0.7530: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [654] - Total Loss: 0.6364: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [655] - Total Loss: 0.6493: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [656] - Total Loss: 0.7171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [657] - Total Loss: 0.6521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [658] - Total Loss: 0.6951: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [659] - Total Loss: 0.6822: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.68it/s]\n",
            "Epoch [660] - Total Loss: 0.6789: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch660.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [661] - Total Loss: 0.7181: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.37it/s]\n",
            "Epoch [662] - Total Loss: 0.6509: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [663] - Total Loss: 0.6371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [664] - Total Loss: 0.7088: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.84it/s]\n",
            "Epoch [665] - Total Loss: 0.6751: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 12.50it/s]\n",
            "Epoch [666] - Total Loss: 0.6954: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.55it/s]\n",
            "Epoch [667] - Total Loss: 0.6756: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [668] - Total Loss: 0.6547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [669] - Total Loss: 0.6540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [670] - Total Loss: 0.6853: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [671] - Total Loss: 0.6455: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [672] - Total Loss: 0.7346: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [673] - Total Loss: 0.7316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [674] - Total Loss: 0.6891: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [675] - Total Loss: 0.6403: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [676] - Total Loss: 0.6996: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [677] - Total Loss: 0.6707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [678] - Total Loss: 0.6773: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.89it/s]\n",
            "Epoch [679] - Total Loss: 0.7626: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [680] - Total Loss: 0.6232: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch680.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [681] - Total Loss: 0.6830: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.71it/s]\n",
            "Epoch [682] - Total Loss: 0.6821: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [683] - Total Loss: 0.6584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [684] - Total Loss: 0.6655: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.39it/s]\n",
            "Epoch [685] - Total Loss: 0.6772: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 15.92it/s]\n",
            "Epoch [686] - Total Loss: 0.6472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.87it/s]\n",
            "Epoch [687] - Total Loss: 0.7284: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [688] - Total Loss: 0.6818: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [689] - Total Loss: 0.6612: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [690] - Total Loss: 0.6372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [691] - Total Loss: 0.6758: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [692] - Total Loss: 0.7121: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [693] - Total Loss: 0.7066: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [694] - Total Loss: 0.6259: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [695] - Total Loss: 0.6976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.86it/s]\n",
            "Epoch [696] - Total Loss: 0.6820: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [697] - Total Loss: 0.6854: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [698] - Total Loss: 0.6904: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [699] - Total Loss: 0.6596: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [700] - Total Loss: 0.6674: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch700.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [701] - Total Loss: 0.6854: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.74it/s]\n",
            "Epoch [702] - Total Loss: 0.6365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [703] - Total Loss: 0.7038: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [704] - Total Loss: 0.6448: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [705] - Total Loss: 0.6875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 10.82it/s]\n",
            "Epoch [706] - Total Loss: 0.7182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [707] - Total Loss: 0.7466: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.88it/s]\n",
            "Epoch [708] - Total Loss: 0.6630: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [709] - Total Loss: 0.6807: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.86it/s]\n",
            "Epoch [710] - Total Loss: 0.6836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [711] - Total Loss: 0.6880: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [712] - Total Loss: 0.6689: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [713] - Total Loss: 0.6577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [714] - Total Loss: 0.7449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [715] - Total Loss: 0.6639: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [716] - Total Loss: 0.6311: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [717] - Total Loss: 0.6840: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [718] - Total Loss: 0.6571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [719] - Total Loss: 0.6204: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [720] - Total Loss: 0.6728: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch720.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [721] - Total Loss: 0.6930: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.50it/s]\n",
            "Epoch [722] - Total Loss: 0.7230: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [723] - Total Loss: 0.6566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [724] - Total Loss: 0.6496: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [725] - Total Loss: 0.7054: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 11.69it/s]\n",
            "Epoch [726] - Total Loss: 0.7046: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [727] - Total Loss: 0.6844: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [728] - Total Loss: 0.7152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [729] - Total Loss: 0.6537: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [730] - Total Loss: 0.7957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [731] - Total Loss: 0.6948: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [732] - Total Loss: 0.6609: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [733] - Total Loss: 0.6966: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [734] - Total Loss: 0.6809: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [735] - Total Loss: 0.6450: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [736] - Total Loss: 0.7493: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [737] - Total Loss: 0.7429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [738] - Total Loss: 0.6843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n",
            "Epoch [739] - Total Loss: 0.6434: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [740] - Total Loss: 0.6547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch740.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [741] - Total Loss: 0.6830: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.82it/s]\n",
            "Epoch [742] - Total Loss: 0.6632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.92it/s]\n",
            "Epoch [743] - Total Loss: 0.7338: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [744] - Total Loss: 0.6395: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 15.45it/s]\n",
            "Epoch [745] - Total Loss: 0.6427: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.36it/s]\n",
            "Epoch [746] - Total Loss: 0.7031: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [747] - Total Loss: 0.6867: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [748] - Total Loss: 0.7416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [749] - Total Loss: 0.6566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [750] - Total Loss: 0.7240: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [751] - Total Loss: 0.6570: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [752] - Total Loss: 0.7026: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [753] - Total Loss: 0.6422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [754] - Total Loss: 0.6693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [755] - Total Loss: 0.6373: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [756] - Total Loss: 0.7670: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [757] - Total Loss: 0.6799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [758] - Total Loss: 0.6789: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [759] - Total Loss: 0.6496: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [760] - Total Loss: 0.6505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch760.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [761] - Total Loss: 0.6286: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.62it/s]\n",
            "Epoch [762] - Total Loss: 0.6546: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [763] - Total Loss: 0.6317: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.89it/s]\n",
            "Epoch [764] - Total Loss: 0.6737: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [765] - Total Loss: 0.6214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [766] - Total Loss: 0.6828: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [767] - Total Loss: 0.7223: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [768] - Total Loss: 0.6272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [769] - Total Loss: 0.6683: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n",
            "Epoch [770] - Total Loss: 0.6768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [771] - Total Loss: 0.6465: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.83it/s]\n",
            "Epoch [772] - Total Loss: 0.7015: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [773] - Total Loss: 0.6242: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [774] - Total Loss: 0.5979: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [775] - Total Loss: 0.6666: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [776] - Total Loss: 0.6814: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [777] - Total Loss: 0.6564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [778] - Total Loss: 0.6752: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [779] - Total Loss: 0.6879: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [780] - Total Loss: 0.6385: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch780.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [781] - Total Loss: 0.6842: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.61it/s]\n",
            "Epoch [782] - Total Loss: 0.6375: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [783] - Total Loss: 0.7070: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [784] - Total Loss: 0.6405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [785] - Total Loss: 0.6420: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [786] - Total Loss: 0.6822: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [787] - Total Loss: 0.7655: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [788] - Total Loss: 0.6047: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [789] - Total Loss: 0.6952: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [790] - Total Loss: 0.6522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [791] - Total Loss: 0.6458: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [792] - Total Loss: 0.6214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [793] - Total Loss: 0.6899: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [794] - Total Loss: 0.6837: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.78it/s]\n",
            "Epoch [795] - Total Loss: 0.6241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [796] - Total Loss: 0.6965: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [797] - Total Loss: 0.6578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [798] - Total Loss: 0.6347: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [799] - Total Loss: 0.6912: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [800] - Total Loss: 0.6042: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch800.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [801] - Total Loss: 0.7120: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.57it/s]\n",
            "Epoch [802] - Total Loss: 0.7178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [803] - Total Loss: 0.6660: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [804] - Total Loss: 0.6237: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [805] - Total Loss: 0.7267: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [806] - Total Loss: 0.6401: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [807] - Total Loss: 0.6350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.24it/s]\n",
            "Epoch [808] - Total Loss: 0.6560: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [809] - Total Loss: 0.7652: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.77it/s]\n",
            "Epoch [810] - Total Loss: 0.6929: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [811] - Total Loss: 0.6712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [812] - Total Loss: 0.6808: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [813] - Total Loss: 0.6310: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [814] - Total Loss: 0.6593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [815] - Total Loss: 0.6755: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.73it/s]\n",
            "Epoch [816] - Total Loss: 0.6289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.35it/s]\n",
            "Epoch [817] - Total Loss: 0.7350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.45it/s]\n",
            "Epoch [818] - Total Loss: 0.6547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [819] - Total Loss: 0.6359: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [820] - Total Loss: 0.6886: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch820.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [821] - Total Loss: 0.6515: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  7.28it/s]\n",
            "Epoch [822] - Total Loss: 0.6115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [823] - Total Loss: 0.6213: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [824] - Total Loss: 0.6696: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [825] - Total Loss: 0.7252: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 11.40it/s]\n",
            "Epoch [826] - Total Loss: 0.7263: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [827] - Total Loss: 0.6429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [828] - Total Loss: 0.6469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [829] - Total Loss: 0.6484: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [830] - Total Loss: 0.6663: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.05it/s]\n",
            "Epoch [831] - Total Loss: 0.6915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [832] - Total Loss: 0.6855: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [833] - Total Loss: 0.6585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [834] - Total Loss: 0.7039: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [835] - Total Loss: 0.6489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [836] - Total Loss: 0.6460: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [837] - Total Loss: 0.6301: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [838] - Total Loss: 0.6175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [839] - Total Loss: 0.6200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.28it/s]\n",
            "Epoch [840] - Total Loss: 0.6420: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch840.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [841] - Total Loss: 0.6625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.42it/s]\n",
            "Epoch [842] - Total Loss: 0.6858: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [843] - Total Loss: 0.6426: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.42it/s]\n",
            "Epoch [844] - Total Loss: 0.6823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.48it/s]\n",
            "Epoch [845] - Total Loss: 0.6222: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.04it/s]\n",
            "Epoch [846] - Total Loss: 0.7405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [847] - Total Loss: 0.6588: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [848] - Total Loss: 0.6458: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [849] - Total Loss: 0.6522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [850] - Total Loss: 0.7555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.95it/s]\n",
            "Epoch [851] - Total Loss: 0.6739: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.92it/s]\n",
            "Epoch [852] - Total Loss: 0.6546: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.49it/s]\n",
            "Epoch [853] - Total Loss: 0.6613: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [854] - Total Loss: 0.6936: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.32it/s]\n",
            "Epoch [855] - Total Loss: 0.6902: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [856] - Total Loss: 0.6877: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [857] - Total Loss: 0.6263: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [858] - Total Loss: 0.6222: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [859] - Total Loss: 0.6517: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [860] - Total Loss: 0.7330: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch860.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [861] - Total Loss: 0.6689: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.47it/s]\n",
            "Epoch [862] - Total Loss: 0.6618: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [863] - Total Loss: 0.7540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [864] - Total Loss: 0.6484: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [865] - Total Loss: 0.6429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [866] - Total Loss: 0.7001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [867] - Total Loss: 0.6738: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [868] - Total Loss: 0.6340: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [869] - Total Loss: 0.6778: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [870] - Total Loss: 0.6554: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [871] - Total Loss: 0.6101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [872] - Total Loss: 0.7093: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [873] - Total Loss: 0.7114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [874] - Total Loss: 0.6553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [875] - Total Loss: 0.6349: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [876] - Total Loss: 0.6933: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [877] - Total Loss: 0.6197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [878] - Total Loss: 0.6512: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.37it/s]\n",
            "Epoch [879] - Total Loss: 0.6582: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [880] - Total Loss: 0.6546: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch880.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [881] - Total Loss: 0.6159: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.57it/s]\n",
            "Epoch [882] - Total Loss: 0.6667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [883] - Total Loss: 0.6810: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [884] - Total Loss: 0.6748: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.66it/s]\n",
            "Epoch [885] - Total Loss: 0.6388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 11.24it/s]\n",
            "Epoch [886] - Total Loss: 0.6422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.41it/s]\n",
            "Epoch [887] - Total Loss: 0.6172: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [888] - Total Loss: 0.6447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [889] - Total Loss: 0.6818: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [890] - Total Loss: 0.6913: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [891] - Total Loss: 0.7547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [892] - Total Loss: 0.6536: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [893] - Total Loss: 0.6053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.93it/s]\n",
            "Epoch [894] - Total Loss: 0.6293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [895] - Total Loss: 0.6843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [896] - Total Loss: 0.6555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [897] - Total Loss: 0.6235: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [898] - Total Loss: 0.7157: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n",
            "Epoch [899] - Total Loss: 0.6483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.85it/s]\n",
            "Epoch [900] - Total Loss: 0.7247: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch900.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [901] - Total Loss: 0.6991: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.40it/s]\n",
            "Epoch [902] - Total Loss: 0.7055: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [903] - Total Loss: 0.7682: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.40it/s]\n",
            "Epoch [904] - Total Loss: 0.6210: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.88it/s]\n",
            "Epoch [905] - Total Loss: 0.6392: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 12.29it/s]\n",
            "Epoch [906] - Total Loss: 0.6349: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.67it/s]\n",
            "Epoch [907] - Total Loss: 0.6209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [908] - Total Loss: 0.7216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.93it/s]\n",
            "Epoch [909] - Total Loss: 0.6406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [910] - Total Loss: 0.7074: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [911] - Total Loss: 0.6490: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [912] - Total Loss: 0.6218: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [913] - Total Loss: 0.6794: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [914] - Total Loss: 0.6421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [915] - Total Loss: 0.7149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [916] - Total Loss: 0.6560: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [917] - Total Loss: 0.5944: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [918] - Total Loss: 0.7291: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [919] - Total Loss: 0.7493: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [920] - Total Loss: 0.6497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch920.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [921] - Total Loss: 0.7235: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:04<00:00,  5.92it/s]\n",
            "Epoch [922] - Total Loss: 0.6143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [923] - Total Loss: 0.6450: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.38it/s]\n",
            "Epoch [924] - Total Loss: 0.6236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.19it/s]\n",
            "Epoch [925] - Total Loss: 0.7044: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.70it/s]\n",
            "Epoch [926] - Total Loss: 0.6717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [927] - Total Loss: 0.6672: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n",
            "Epoch [928] - Total Loss: 0.6770: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [929] - Total Loss: 0.6227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.90it/s]\n",
            "Epoch [930] - Total Loss: 0.5993: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [931] - Total Loss: 0.6538: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.21it/s]\n",
            "Epoch [932] - Total Loss: 0.6532: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [933] - Total Loss: 0.6801: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.17it/s]\n",
            "Epoch [934] - Total Loss: 0.6589: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [935] - Total Loss: 0.6698: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.18it/s]\n",
            "Epoch [936] - Total Loss: 0.6653: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.88it/s]\n",
            "Epoch [937] - Total Loss: 0.6662: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [938] - Total Loss: 0.6805: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [939] - Total Loss: 0.6402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [940] - Total Loss: 0.6428: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch940.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [941] - Total Loss: 0.7153: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  7.14it/s]\n",
            "Epoch [942] - Total Loss: 0.6891: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [943] - Total Loss: 0.6734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [944] - Total Loss: 0.7303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.68it/s]\n",
            "Epoch [945] - Total Loss: 0.6680: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:02<00:00, 10.67it/s]\n",
            "Epoch [946] - Total Loss: 0.6317: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.03it/s]\n",
            "Epoch [947] - Total Loss: 0.6659: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.86it/s]\n",
            "Epoch [948] - Total Loss: 0.6966: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.81it/s]\n",
            "Epoch [949] - Total Loss: 0.6775: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.85it/s]\n",
            "Epoch [950] - Total Loss: 0.6830: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [951] - Total Loss: 0.6691: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.36it/s]\n",
            "Epoch [952] - Total Loss: 0.7023: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.89it/s]\n",
            "Epoch [953] - Total Loss: 0.6289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [954] - Total Loss: 0.6222: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.31it/s]\n",
            "Epoch [955] - Total Loss: 0.6123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [956] - Total Loss: 0.6516: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [957] - Total Loss: 0.6706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.08it/s]\n",
            "Epoch [958] - Total Loss: 0.6367: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [959] - Total Loss: 0.6276: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.93it/s]\n",
            "Epoch [960] - Total Loss: 0.7048: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch960.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [961] - Total Loss: 0.6389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.37it/s]\n",
            "Epoch [962] - Total Loss: 0.6085: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.06it/s]\n",
            "Epoch [963] - Total Loss: 0.6361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [964] - Total Loss: 0.6271: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [965] - Total Loss: 0.6722: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 12.53it/s]\n",
            "Epoch [966] - Total Loss: 0.6714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [967] - Total Loss: 0.6269: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.14it/s]\n",
            "Epoch [968] - Total Loss: 0.6422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.25it/s]\n",
            "Epoch [969] - Total Loss: 0.6629: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.99it/s]\n",
            "Epoch [970] - Total Loss: 0.6076: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.97it/s]\n",
            "Epoch [971] - Total Loss: 0.6192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.16it/s]\n",
            "Epoch [972] - Total Loss: 0.6406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.22it/s]\n",
            "Epoch [973] - Total Loss: 0.6228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.33it/s]\n",
            "Epoch [974] - Total Loss: 0.6152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.12it/s]\n",
            "Epoch [975] - Total Loss: 0.6577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.36it/s]\n",
            "Epoch [976] - Total Loss: 0.7421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.29it/s]\n",
            "Epoch [977] - Total Loss: 0.6837: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [978] - Total Loss: 0.6173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.91it/s]\n",
            "Epoch [979] - Total Loss: 0.6262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.23it/s]\n",
            "Epoch [980] - Total Loss: 0.6578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch980.png and model checkpoints\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [981] - Total Loss: 0.6667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:03<00:00,  6.04it/s]\n",
            "Epoch [982] - Total Loss: 0.6314: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.13it/s]\n",
            "Epoch [983] - Total Loss: 0.6599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.98it/s]\n",
            "Epoch [984] - Total Loss: 0.6190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.09it/s]\n",
            "Epoch [985] - Total Loss: 0.6410: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 13.80it/s]\n",
            "Epoch [986] - Total Loss: 0.6510: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.11it/s]\n",
            "Epoch [987] - Total Loss: 0.7030: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.20it/s]\n",
            "Epoch [988] - Total Loss: 0.6308: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [989] - Total Loss: 0.7370: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [990] - Total Loss: 0.6802: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.44it/s]\n",
            "Epoch [991] - Total Loss: 0.6432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.96it/s]\n",
            "Epoch [992] - Total Loss: 0.6422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.87it/s]\n",
            "Epoch [993] - Total Loss: 0.6774: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 16.94it/s]\n",
            "Epoch [994] - Total Loss: 0.6707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.30it/s]\n",
            "Epoch [995] - Total Loss: 0.5937: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.00it/s]\n",
            "Epoch [996] - Total Loss: 0.7323: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.10it/s]\n",
            "Epoch [997] - Total Loss: 0.6426: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.27it/s]\n",
            "Epoch [998] - Total Loss: 0.7301: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.26it/s]\n",
            "Epoch [999] - Total Loss: 0.6041: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.15it/s]\n",
            "Epoch [1000] - Total Loss: 0.6179: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 17.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved: sample_epoch1000.png and model checkpoints\n"
          ]
        }
      ],
      "source": [
        "#FINAL EXECUTED CODE TRAINING USIN LATENT DIFFUSION MODEL\n",
        "# âœ… FINAL FIXED LDM + DDIM SAMPLING + EMA + CHECKPOINTING (IMPROVED CNN + KL + REALISTIC SAMPLING)\n",
        "import torch, os\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms as T\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch.amp import autocast, GradScaler\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# âœ… CONFIG\n",
        "IMG_SIZE = 512\n",
        "LATENT_DIM = 1024\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 1000\n",
        "WARMUP_EPOCHS = 100\n",
        "LR = 2e-4\n",
        "TIMESTEPS = 1000\n",
        "DATA_PATH = \"/content/drive/MyDrive/ANTHRECNOSE\"\n",
        "\n",
        "# âœ… DEVICE & OUTPUT\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "scaler = GradScaler()\n",
        "os.makedirs(\"ldm3_outputs\", exist_ok=True)\n",
        "\n",
        "# âœ… DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# âœ… LOADER\n",
        "dataset = SingleClassImageDataset(DATA_PATH, transform)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "# âœ… MODELS\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# âœ… TRAINING SETUP\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()) + list(unet.parameters()), lr=LR)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# âœ… KL Loss\n",
        "def kl_divergence(mu):\n",
        "    return -0.5 * torch.sum(1 + 0 - mu.pow(2) - 1, dim=1).mean()\n",
        "\n",
        "# âœ… TRAIN LOOP\n",
        "print(\"\\nðŸš€ Starting Training...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    encoder.train(); decoder.train(); unet.train()\n",
        "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    for images, _ in pbar:\n",
        "        images = images.to(device)\n",
        "        with autocast(device_type=device.type):\n",
        "            z = encoder(images)\n",
        "            recon = decoder(z)\n",
        "            recon_loss = F.mse_loss(recon, images)\n",
        "            kl_loss = kl_divergence(z)\n",
        "            loss_autoenc = recon_loss + 0.001 * kl_loss\n",
        "\n",
        "            t = torch.randint(0, TIMESTEPS, (z.size(0),), device=device).long()\n",
        "            noise = torch.randn_like(z)\n",
        "            alpha_hat = scheduler_alpha_hat[t][:, None]\n",
        "            noisy_z = (alpha_hat**0.5) * z + ((1 - alpha_hat)**0.5) * noise\n",
        "            pred = unet(noisy_z, t)\n",
        "            diffusion_loss = F.mse_loss(pred, noise)\n",
        "\n",
        "            total_loss = loss_autoenc + diffusion_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(total_loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        pbar.set_description(f\"Epoch [{epoch+1}] - Total Loss: {total_loss.item():.4f}\")\n",
        "\n",
        "    # Save every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        with torch.no_grad():\n",
        "            # Sample latents from real images\n",
        "            sample_images, _ = next(iter(dataloader))\n",
        "            z_sample = encoder(sample_images.to(device))\n",
        "            samples = decoder(z_sample)\n",
        "            save_image((samples + 1) / 2, f\"ldm3_outputs/sample_epoch{epoch+1}.png\", nrow=4)\n",
        "            torch.save(encoder.state_dict(), f\"ldm3_outputs/encoder_epoch{epoch+1}.pth\")\n",
        "            torch.save(decoder.state_dict(), f\"ldm3_outputs/decoder_epoch{epoch+1}.pth\")\n",
        "            torch.save(unet.state_dict(),    f\"ldm3_outputs/unet_epoch{epoch+1}.pth\")\n",
        "            print(f\"âœ… Saved: sample_epoch{epoch+1}.png and model checkpoints\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AfXRL3hkIwY",
        "outputId": "999eeaa8-bc3e-48a7-df14-7fc0d8a77185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… 50 images generated from real latents\n",
            "âœ… Zipped outputs at: ldm3_outputs/generated_best.zip\n"
          ]
        }
      ],
      "source": [
        "#FINAL EXECUTED CODE GENERATION\n",
        "# âœ… GENERATION CODE MATCHING TRAINING QUALITY (REAL LATENTS + DDIM OPTION + ZIP)\n",
        "import torch, os, zipfile\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import trange\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# âœ… CONFIG (same as training)\n",
        "LATENT_DIM = 1024\n",
        "TIMESTEPS = 1000\n",
        "IMG_SIZE = 512\n",
        "DATA_PATH = \"/content/drive/MyDrive/ANTHRECNOSE\"\n",
        "\n",
        "# âœ… DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… Schedulers (same as training)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# âœ… DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "dataset = SingleClassImageDataset(DATA_PATH, transform)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "\n",
        "# âœ… MODELS (same as training)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# âœ… Instantiate models\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "\n",
        "# âœ… Load trained weights\n",
        "encoder.load_state_dict(torch.load(\"ldm3_outputs/encoder_epoch1000.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"ldm3_outputs/decoder_epoch1000.pth\"))\n",
        "unet.load_state_dict(torch.load(\"ldm3_outputs/unet_epoch1000.pth\"))\n",
        "encoder.eval(); decoder.eval(); unet.eval()\n",
        "\n",
        "# âœ… OUTPUT FOLDER\n",
        "output_dir = \"ldm3_outputs/generated_best\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# âœ… Option 1: Sampling from real encoded latents\n",
        "@torch.no_grad()\n",
        "def generate_from_real_latents(encoder_model, decoder_model, dataloader, num_samples=50):\n",
        "    count = 0\n",
        "    for images, _ in dataloader:\n",
        "        z = encoder_model(images.to(device))\n",
        "        imgs = decoder_model(z)\n",
        "        imgs = (imgs + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(output_dir, f\"real_latent_{count + j + 1:05}.png\"))\n",
        "        count += len(imgs)\n",
        "        if count >= num_samples:\n",
        "            break\n",
        "    print(f\"âœ… {num_samples} images generated from real latents\")\n",
        "\n",
        "# âœ… Option 2: DDIM sampling from noise\n",
        "@torch.no_grad()\n",
        "def generate_ddim(unet_model, decoder_model, steps=200, batch_size=8, total=50):\n",
        "    for i in trange(0, total, batch_size):\n",
        "        bs = min(batch_size, total - i)\n",
        "        z = torch.randn(bs, LATENT_DIM).to(device)\n",
        "        for t in reversed(range(steps)):\n",
        "            t_tensor = torch.full((bs,), t, dtype=torch.long, device=device)\n",
        "            beta = scheduler_betas[t]\n",
        "            alpha = scheduler_alphas[t]\n",
        "            alpha_hat = scheduler_alpha_hat[t]\n",
        "            noise_pred = unet_model(z, t_tensor)\n",
        "            z = (z - beta / torch.sqrt(1 - alpha_hat) * noise_pred) / torch.sqrt(alpha)\n",
        "            if t > 0:\n",
        "                z += torch.randn_like(z) * beta.sqrt()\n",
        "        imgs = (decoder_model(z) + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(output_dir, f\"ddim_sample_{i + j + 1:05}.png\"))\n",
        "    print(f\"âœ… {total} images generated using DDIM\")\n",
        "\n",
        "# ðŸ” Select mode below:\n",
        "mode = \"real\"  # or \"ddim\"\n",
        "\n",
        "if mode == \"real\":\n",
        "    generate_from_real_latents(encoder, decoder, dataloader, num_samples=50)\n",
        "else:\n",
        "    generate_ddim(unet, decoder, steps=200, batch_size=8, total=50)\n",
        "\n",
        "# âœ… ZIP GENERATED IMAGES\n",
        "zip_path = output_dir + \".zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, _, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), arcname=file)\n",
        "print(f\"âœ… Zipped outputs at: {zip_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnJP30F902hQ",
        "outputId": "c7404b86-aaf5-4da1-b627-e5b17b9460f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… 5000 images generated from real latents\n",
            "âœ… Zipped outputs at: ldm9_outputs/generated_best.zip\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "âœ… LPIPS Diversity Score: 0.5961\n",
            "âœ… FID Score: 6.62\n"
          ]
        }
      ],
      "source": [
        "# âœ… GENERATION CODE MATCHING TRAINING QUALITY (REAL LATENTS + DDIM OPTION + ZIP + FID/LPIPS)\n",
        "import torch, os, zipfile\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import trange\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from scipy import linalg\n",
        "from itertools import cycle\n",
        "\n",
        "# âœ… CONFIG (same as training)\n",
        "LATENT_DIM = 1024\n",
        "TIMESTEPS = 1000\n",
        "IMG_SIZE = 512\n",
        "DATA_PATH = \"/content/drive/MyDrive/ANTHRECNOSE\"\n",
        "\n",
        "# âœ… DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… Schedulers (same as training)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# âœ… DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "ref_transform = T.Compose([\n",
        "    T.Resize((299, 299)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Real data loader for FID\n",
        "ref_dataset = SingleClassImageDataset(DATA_PATH, ref_transform)\n",
        "ref_loader = DataLoader(ref_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# âœ… MODELS (same as training)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# âœ… Instantiate models\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "\n",
        "# âœ… Load trained weights\n",
        "encoder.load_state_dict(torch.load(\"ldm3_outputs/encoder_epoch1000.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"ldm3_outputs/decoder_epoch1000.pth\"))\n",
        "unet.load_state_dict(torch.load(\"ldm3_outputs/unet_epoch1000.pth\"))\n",
        "encoder.eval(); decoder.eval(); unet.eval()\n",
        "\n",
        "# âœ… OUTPUT FOLDER\n",
        "output_dir = \"ldm9_outputs/generated_best\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# âœ… Generation function (real latents)\n",
        "@torch.no_grad()\n",
        "def generate_from_real_latents(encoder_model, decoder_model, dataloader, num_samples=5000):\n",
        "    count = 0\n",
        "    loop_loader = cycle(dataloader)  # Infinite loop over dataset\n",
        "    for images, _ in loop_loader:\n",
        "        z = encoder_model(images.to(device))\n",
        "        imgs = decoder_model(z)\n",
        "        imgs = (imgs + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(output_dir, f\"real_latent_{count + j + 1:05}.png\"))\n",
        "        count += len(imgs)\n",
        "        if count >= num_samples:\n",
        "            break\n",
        "    print(f\"âœ… {num_samples} images generated from real latents\")\n",
        "\n",
        "# âœ… Generation function (DDIM)\n",
        "@torch.no_grad()\n",
        "def generate_ddim(unet_model, decoder_model, steps=250, batch_size=8, total=5000):\n",
        "    for i in trange(0, total, batch_size):\n",
        "        bs = min(batch_size, total - i)\n",
        "        z = torch.randn(bs, LATENT_DIM).to(device)\n",
        "        for t in reversed(range(steps)):\n",
        "            t_tensor = torch.full((bs,), t, dtype=torch.long, device=device)\n",
        "            beta = scheduler_betas[t]\n",
        "            alpha = scheduler_alphas[t]\n",
        "            alpha_hat = scheduler_alpha_hat[t]\n",
        "            noise_pred = unet_model(z, t_tensor)\n",
        "            z = (z - beta / torch.sqrt(1 - alpha_hat) * noise_pred) / torch.sqrt(alpha)\n",
        "            if t > 0:\n",
        "                z += torch.randn_like(z) * beta.sqrt()\n",
        "        imgs = (decoder_model(z) + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(output_dir, f\"ddim_sample_{i + j + 1:05}.png\"))\n",
        "    print(f\"âœ… {total} images generated using DDIM\")\n",
        "\n",
        "# ðŸ” Mode selector\n",
        "mode = \"real\"\n",
        "if mode == \"real\":\n",
        "    generate_from_real_latents(encoder, decoder, DataLoader(SingleClassImageDataset(DATA_PATH, transform), batch_size=8, shuffle=True), num_samples=5000)\n",
        "else:\n",
        "    generate_ddim(unet, decoder, steps=250, batch_size=8, total=5000)\n",
        "\n",
        "# âœ… ZIP GENERATED IMAGES\n",
        "zip_path = output_dir + \".zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, _, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), arcname=file)\n",
        "print(f\"âœ… Zipped outputs at: {zip_path}\")\n",
        "\n",
        "# âœ… LPIPS Diversity\n",
        "!pip install lpips --quiet\n",
        "import lpips\n",
        "lpips_model = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "img_paths = sorted([os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(\".png\")])[:100]\n",
        "imgs = [transform(Image.open(p).convert(\"RGB\")).unsqueeze(0).to(device) for p in img_paths]\n",
        "\n",
        "div_sum = 0\n",
        "pairs = 0\n",
        "for i in range(len(imgs)):\n",
        "    for j in range(i+1, len(imgs)):\n",
        "        dist = lpips_model(imgs[i], imgs[j])\n",
        "        div_sum += dist.item()\n",
        "        pairs += 1\n",
        "print(f\"âœ… LPIPS Diversity Score: {div_sum/pairs:.4f}\")\n",
        "\n",
        "# âœ… FID Score\n",
        "@torch.no_grad()\n",
        "def get_activations(dataloader, model):\n",
        "    model.eval()\n",
        "    activations = []\n",
        "    up = T.Resize((299, 299))\n",
        "    for imgs, _ in dataloader:\n",
        "        imgs = up(imgs).to(device)\n",
        "        preds = model(imgs)\n",
        "        if isinstance(preds, tuple):\n",
        "            preds = preds[0]\n",
        "        preds = preds.view(preds.size(0), -1)\n",
        "        activations.append(preds.cpu().numpy())\n",
        "    return np.concatenate(activations, axis=0)\n",
        "\n",
        "inception = models.inception_v3(pretrained=True, transform_input=False).to(device)\n",
        "inception.fc = nn.Identity()\n",
        "inception.eval()\n",
        "\n",
        "# Generated loader for FID\n",
        "gen_dataset = SingleClassImageDataset(output_dir, ref_transform)\n",
        "gen_loader = DataLoader(gen_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "act1 = get_activations(ref_loader, inception)\n",
        "act2 = get_activations(gen_loader, inception)\n",
        "mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
        "mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
        "\n",
        "fid = np.sum((mu1 - mu2)**2) + np.trace(sigma1 + sigma2 - 2 * linalg.sqrtm(sigma1.dot(sigma2)).real)\n",
        "print(f\"âœ… FID Score: {fid:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YYOoN-We-cnd",
        "outputId": "4e014ae2-ed27-44db-b05a-48063b587522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… 5000 images generated from real latents\n",
            "âœ… Zipped outputs at: ldm10_outputs/generated_best_2.zip\n"
          ]
        }
      ],
      "source": [
        "#GENERATING NEXT 5000 IMAGES\n",
        "# âœ… GENERATION CODE MATCHING TRAINING QUALITY (REAL LATENTS + DDIM OPTION + ZIP + FID/LPIPS)\n",
        "import torch, os, zipfile\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import trange\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from scipy import linalg\n",
        "from itertools import cycle\n",
        "\n",
        "# âœ… CONFIG (same as training)\n",
        "LATENT_DIM = 1024\n",
        "TIMESTEPS = 1000\n",
        "IMG_SIZE = 512\n",
        "DATA_PATH = \"/content/drive/MyDrive/ANTHRECNOSE\"\n",
        "\n",
        "# âœ… DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… Schedulers (same as training)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# âœ… DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "ref_transform = T.Compose([\n",
        "    T.Resize((299, 299)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Real data loader for FID\n",
        "ref_dataset = SingleClassImageDataset(DATA_PATH, ref_transform)\n",
        "ref_loader = DataLoader(ref_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# âœ… MODELS (same as training)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# âœ… Instantiate models\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "\n",
        "# âœ… Load trained weights\n",
        "encoder.load_state_dict(torch.load(\"ldm3_outputs/encoder_epoch1000.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"ldm3_outputs/decoder_epoch1000.pth\"))\n",
        "unet.load_state_dict(torch.load(\"ldm3_outputs/unet_epoch1000.pth\"))\n",
        "encoder.eval(); decoder.eval(); unet.eval()\n",
        "\n",
        "# âœ… OUTPUT FOLDER\n",
        "output_dir = \"ldm10_outputs/generated_best_2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# âœ… Generation function (real latents)\n",
        "@torch.no_grad()\n",
        "def generate_from_real_latents(encoder_model, decoder_model, dataloader, num_samples=5000, offset=5000):\n",
        "    count = 0\n",
        "    loop_loader = cycle(dataloader)  # Infinite loop over dataset\n",
        "    for images, _ in loop_loader:\n",
        "        z = encoder_model(images.to(device))\n",
        "        imgs = decoder_model(z)\n",
        "        imgs = (imgs + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            index = offset + count + j + 1\n",
        "            save_image(img, os.path.join(output_dir, f\"real_latent_{index:05}.png\"))\n",
        "        count += len(imgs)\n",
        "        if count >= num_samples:\n",
        "            break\n",
        "    print(f\"âœ… {num_samples} images generated from real latents\")\n",
        "\n",
        "# âœ… Mode selector\n",
        "mode = \"real\"\n",
        "if mode == \"real\":\n",
        "    generate_from_real_latents(encoder, decoder, DataLoader(SingleClassImageDataset(DATA_PATH, transform), batch_size=8, shuffle=True), num_samples=5000, offset=5000)\n",
        "\n",
        "# âœ… ZIP GENERATED IMAGES\n",
        "zip_path = output_dir + \".zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, _, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), arcname=file)\n",
        "print(f\"âœ… Zipped outputs at: {zip_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}