{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d9iwlBR9kBW",
        "outputId": "8459296a-0448-401c-f59c-7f9c4deb89a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set your folder path in Drive\n",
        "folder_path = \"/content/drive/MyDrive/GALLMILDGEDAMAGE\"\n",
        "\n",
        "# Get list of image files (sorted)\n",
        "image_files = sorted([\n",
        "    f for f in os.listdir(folder_path)\n",
        "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
        "])\n",
        "\n",
        "# Rename files to format: GAL0001, GAL0002, ...\n",
        "for i, filename in enumerate(image_files, 1):\n",
        "    ext = os.path.splitext(filename)[1]\n",
        "    new_name = f\"GAL{i:04}{ext}\"\n",
        "    src = os.path.join(folder_path, filename)\n",
        "    dst = os.path.join(folder_path, new_name)\n",
        "    os.rename(src, dst)\n",
        "\n",
        "print(f\"âœ… Renamed {len(image_files)} files to GALxxxx format.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAvhCSkuMGzZ",
        "outputId": "e917b6ae-dba9-4b44-e28c-75ade2c2da6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Renamed 943 files to GALxxxx format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGFQ20hCPfwi",
        "outputId": "4165069d-face-4102-b8bb-ac890d88349b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸš€ Starting Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [1] - Total Loss: 1.0287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [01:02<00:00,  1.03s/it]\n",
            "Epoch [2] - Total Loss: 1.0721: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 15.68it/s]\n",
            "Epoch [3] - Total Loss: 1.0819: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [4] - Total Loss: 1.0517: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [5] - Total Loss: 1.0070: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.21it/s]\n",
            "Epoch [6] - Total Loss: 1.1016: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.44it/s]\n",
            "Epoch [7] - Total Loss: 1.0043: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [8] - Total Loss: 1.0420: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.20it/s]\n",
            "Epoch [9] - Total Loss: 1.0957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [10] - Total Loss: 1.0382: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [11] - Total Loss: 1.0632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.16it/s]\n",
            "Epoch [12] - Total Loss: 1.0071: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.02it/s]\n",
            "Epoch [13] - Total Loss: 1.0491: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [14] - Total Loss: 1.0148: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.05it/s]\n",
            "Epoch [15] - Total Loss: 1.0289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.27it/s]\n",
            "Epoch [16] - Total Loss: 0.9946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.49it/s]\n",
            "Epoch [17] - Total Loss: 1.0350: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.72it/s]\n",
            "Epoch [18] - Total Loss: 1.0004: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [19] - Total Loss: 0.9806: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.81it/s]\n",
            "Epoch [20] - Total Loss: 1.0174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch20.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [21] - Total Loss: 0.9955: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.12it/s]\n",
            "Epoch [22] - Total Loss: 1.0211: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.15it/s]\n",
            "Epoch [23] - Total Loss: 0.9189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [24] - Total Loss: 1.0709: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [25] - Total Loss: 0.9690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [26] - Total Loss: 0.9161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [27] - Total Loss: 0.9396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.34it/s]\n",
            "Epoch [28] - Total Loss: 0.9603: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [29] - Total Loss: 0.9017: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.12it/s]\n",
            "Epoch [30] - Total Loss: 0.8863: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [31] - Total Loss: 0.9868: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [32] - Total Loss: 0.8999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [33] - Total Loss: 0.8860: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [34] - Total Loss: 0.8931: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n",
            "Epoch [35] - Total Loss: 0.9178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.60it/s]\n",
            "Epoch [36] - Total Loss: 0.8872: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [37] - Total Loss: 0.8669: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.33it/s]\n",
            "Epoch [38] - Total Loss: 0.9302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [39] - Total Loss: 0.9436: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.75it/s]\n",
            "Epoch [40] - Total Loss: 0.8940: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch40.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [41] - Total Loss: 0.9175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.31it/s]\n",
            "Epoch [42] - Total Loss: 0.9204: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.57it/s]\n",
            "Epoch [43] - Total Loss: 0.9137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [44] - Total Loss: 0.8717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.53it/s]\n",
            "Epoch [45] - Total Loss: 0.8340: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.42it/s]\n",
            "Epoch [46] - Total Loss: 0.9078: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [47] - Total Loss: 0.8700: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [48] - Total Loss: 0.8585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [49] - Total Loss: 0.9124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.55it/s]\n",
            "Epoch [50] - Total Loss: 0.8700: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.65it/s]\n",
            "Epoch [51] - Total Loss: 0.8691: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [52] - Total Loss: 0.8465: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.20it/s]\n",
            "Epoch [53] - Total Loss: 0.9408: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [54] - Total Loss: 0.8775: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.94it/s]\n",
            "Epoch [55] - Total Loss: 0.8362: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.16it/s]\n",
            "Epoch [56] - Total Loss: 0.8943: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.64it/s]\n",
            "Epoch [57] - Total Loss: 0.9302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [58] - Total Loss: 0.8463: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [59] - Total Loss: 0.7878: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.39it/s]\n",
            "Epoch [60] - Total Loss: 0.8236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch60.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [61] - Total Loss: 0.8017: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.27it/s]\n",
            "Epoch [62] - Total Loss: 0.7984: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.58it/s]\n",
            "Epoch [63] - Total Loss: 0.8407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [64] - Total Loss: 0.7882: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [65] - Total Loss: 0.7767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [66] - Total Loss: 0.7945: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [67] - Total Loss: 0.7781: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [68] - Total Loss: 0.9152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [69] - Total Loss: 0.8378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [70] - Total Loss: 0.7357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.41it/s]\n",
            "Epoch [71] - Total Loss: 0.7658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [72] - Total Loss: 0.9005: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.65it/s]\n",
            "Epoch [73] - Total Loss: 0.9068: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.64it/s]\n",
            "Epoch [74] - Total Loss: 0.7916: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [75] - Total Loss: 0.7631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [76] - Total Loss: 0.7946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.57it/s]\n",
            "Epoch [77] - Total Loss: 0.9094: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.27it/s]\n",
            "Epoch [78] - Total Loss: 0.8035: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.64it/s]\n",
            "Epoch [79] - Total Loss: 0.7975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [80] - Total Loss: 1.0134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch80.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [81] - Total Loss: 0.7675: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.31it/s]\n",
            "Epoch [82] - Total Loss: 0.8233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [83] - Total Loss: 0.7697: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [84] - Total Loss: 0.8279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.07it/s]\n",
            "Epoch [85] - Total Loss: 0.7640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.33it/s]\n",
            "Epoch [86] - Total Loss: 0.7463: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.75it/s]\n",
            "Epoch [87] - Total Loss: 0.7520: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.04it/s]\n",
            "Epoch [88] - Total Loss: 0.7352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.94it/s]\n",
            "Epoch [89] - Total Loss: 0.8073: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.39it/s]\n",
            "Epoch [90] - Total Loss: 0.7604: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.13it/s]\n",
            "Epoch [91] - Total Loss: 0.7418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [92] - Total Loss: 0.7799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.40it/s]\n",
            "Epoch [93] - Total Loss: 0.7254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.11it/s]\n",
            "Epoch [94] - Total Loss: 0.8188: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [95] - Total Loss: 0.7565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.19it/s]\n",
            "Epoch [96] - Total Loss: 0.8877: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [97] - Total Loss: 0.7510: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [98] - Total Loss: 0.7578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.74it/s]\n",
            "Epoch [99] - Total Loss: 0.7733: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.50it/s]\n",
            "Epoch [100] - Total Loss: 0.7524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch100.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [101] - Total Loss: 0.6730: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.06it/s]\n",
            "Epoch [102] - Total Loss: 0.7410: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.07it/s]\n",
            "Epoch [103] - Total Loss: 0.9888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [104] - Total Loss: 1.0041: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [105] - Total Loss: 0.7783: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.10it/s]\n",
            "Epoch [106] - Total Loss: 0.7496: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.99it/s]\n",
            "Epoch [107] - Total Loss: 0.9652: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.40it/s]\n",
            "Epoch [108] - Total Loss: 0.7619: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [109] - Total Loss: 0.7201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.74it/s]\n",
            "Epoch [110] - Total Loss: 0.7282: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [111] - Total Loss: 0.7491: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [112] - Total Loss: 0.8744: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [113] - Total Loss: 0.7423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [114] - Total Loss: 0.7654: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [115] - Total Loss: 0.7623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.26it/s]\n",
            "Epoch [116] - Total Loss: 0.7432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [117] - Total Loss: 0.8250: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.38it/s]\n",
            "Epoch [118] - Total Loss: 0.7031: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.25it/s]\n",
            "Epoch [119] - Total Loss: 0.8446: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [120] - Total Loss: 0.7603: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch120.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [121] - Total Loss: 0.7606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00, 10.03it/s]\n",
            "Epoch [122] - Total Loss: 0.7069: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [123] - Total Loss: 0.6707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.16it/s]\n",
            "Epoch [124] - Total Loss: 0.7833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [125] - Total Loss: 0.7788: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.74it/s]\n",
            "Epoch [126] - Total Loss: 0.7113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [127] - Total Loss: 0.6888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.13it/s]\n",
            "Epoch [128] - Total Loss: 0.6783: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [129] - Total Loss: 0.7165: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [130] - Total Loss: 0.6781: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.06it/s]\n",
            "Epoch [131] - Total Loss: 0.7103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [132] - Total Loss: 0.7080: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.47it/s]\n",
            "Epoch [133] - Total Loss: 0.6756: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [134] - Total Loss: 0.6797: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [135] - Total Loss: 0.6894: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.58it/s]\n",
            "Epoch [136] - Total Loss: 0.8777: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.35it/s]\n",
            "Epoch [137] - Total Loss: 0.6570: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.05it/s]\n",
            "Epoch [138] - Total Loss: 0.7029: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [139] - Total Loss: 0.7141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.30it/s]\n",
            "Epoch [140] - Total Loss: 0.7141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch140.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [141] - Total Loss: 0.6400: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 10.39it/s]\n",
            "Epoch [142] - Total Loss: 0.7079: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 14.35it/s]\n",
            "Epoch [143] - Total Loss: 0.6658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [144] - Total Loss: 0.7127: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [145] - Total Loss: 0.7057: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [146] - Total Loss: 0.7219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [147] - Total Loss: 0.8436: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.32it/s]\n",
            "Epoch [148] - Total Loss: 0.7255: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.81it/s]\n",
            "Epoch [149] - Total Loss: 0.6917: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [150] - Total Loss: 0.6935: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [151] - Total Loss: 0.7166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [152] - Total Loss: 0.6893: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.52it/s]\n",
            "Epoch [153] - Total Loss: 0.7336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [154] - Total Loss: 0.7593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.30it/s]\n",
            "Epoch [155] - Total Loss: 0.6902: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [156] - Total Loss: 0.7546: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [157] - Total Loss: 0.7179: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.41it/s]\n",
            "Epoch [158] - Total Loss: 0.7260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [159] - Total Loss: 0.8396: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [160] - Total Loss: 0.6705: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch160.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [161] - Total Loss: 0.6582: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00, 10.10it/s]\n",
            "Epoch [162] - Total Loss: 0.7061: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 14.63it/s]\n",
            "Epoch [163] - Total Loss: 0.8227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.02it/s]\n",
            "Epoch [164] - Total Loss: 0.6565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.02it/s]\n",
            "Epoch [165] - Total Loss: 0.7255: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [166] - Total Loss: 0.7105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.65it/s]\n",
            "Epoch [167] - Total Loss: 0.6880: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [168] - Total Loss: 0.7033: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [169] - Total Loss: 0.6743: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [170] - Total Loss: 0.8772: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [171] - Total Loss: 0.6485: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [172] - Total Loss: 0.6803: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [173] - Total Loss: 0.6555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [174] - Total Loss: 0.6931: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.47it/s]\n",
            "Epoch [175] - Total Loss: 0.6757: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.62it/s]\n",
            "Epoch [176] - Total Loss: 0.6746: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.62it/s]\n",
            "Epoch [177] - Total Loss: 0.7004: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [178] - Total Loss: 0.6902: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [179] - Total Loss: 0.7870: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.50it/s]\n",
            "Epoch [180] - Total Loss: 0.7084: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch180.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [181] - Total Loss: 0.6413: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.17it/s]\n",
            "Epoch [182] - Total Loss: 0.7358: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [183] - Total Loss: 0.6298: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [184] - Total Loss: 0.8982: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.37it/s]\n",
            "Epoch [185] - Total Loss: 0.7616: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.41it/s]\n",
            "Epoch [186] - Total Loss: 0.6672: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [187] - Total Loss: 0.6457: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.36it/s]\n",
            "Epoch [188] - Total Loss: 0.7017: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [189] - Total Loss: 0.6670: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.65it/s]\n",
            "Epoch [190] - Total Loss: 0.7692: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [191] - Total Loss: 0.6853: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [192] - Total Loss: 0.7912: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.53it/s]\n",
            "Epoch [193] - Total Loss: 0.8105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [194] - Total Loss: 0.7676: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.43it/s]\n",
            "Epoch [195] - Total Loss: 0.6225: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [196] - Total Loss: 0.6781: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [197] - Total Loss: 0.6760: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.59it/s]\n",
            "Epoch [198] - Total Loss: 0.6658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.59it/s]\n",
            "Epoch [199] - Total Loss: 0.6693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [200] - Total Loss: 0.7916: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch200.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [201] - Total Loss: 0.6649: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.80it/s]\n",
            "Epoch [202] - Total Loss: 0.6546: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.59it/s]\n",
            "Epoch [203] - Total Loss: 0.6734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [204] - Total Loss: 0.6689: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.09it/s]\n",
            "Epoch [205] - Total Loss: 0.6921: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.36it/s]\n",
            "Epoch [206] - Total Loss: 0.6721: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.44it/s]\n",
            "Epoch [207] - Total Loss: 0.7891: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [208] - Total Loss: 0.6985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [209] - Total Loss: 0.6818: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [210] - Total Loss: 0.7397: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.56it/s]\n",
            "Epoch [211] - Total Loss: 0.6769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.54it/s]\n",
            "Epoch [212] - Total Loss: 0.7199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [213] - Total Loss: 0.7963: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [214] - Total Loss: 0.6507: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [215] - Total Loss: 0.7982: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [216] - Total Loss: 0.6773: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.49it/s]\n",
            "Epoch [217] - Total Loss: 0.7167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [218] - Total Loss: 0.7698: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [219] - Total Loss: 0.6441: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.22it/s]\n",
            "Epoch [220] - Total Loss: 0.7209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch220.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [221] - Total Loss: 0.6349: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 10.65it/s]\n",
            "Epoch [222] - Total Loss: 0.6489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 14.56it/s]\n",
            "Epoch [223] - Total Loss: 0.6965: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [224] - Total Loss: 0.6348: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [225] - Total Loss: 0.6374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.10it/s]\n",
            "Epoch [226] - Total Loss: 0.7402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [227] - Total Loss: 0.7071: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.74it/s]\n",
            "Epoch [228] - Total Loss: 0.6323: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.40it/s]\n",
            "Epoch [229] - Total Loss: 0.6358: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [230] - Total Loss: 0.6696: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.01it/s]\n",
            "Epoch [231] - Total Loss: 0.6465: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.64it/s]\n",
            "Epoch [232] - Total Loss: 0.6513: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [233] - Total Loss: 0.7269: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.57it/s]\n",
            "Epoch [234] - Total Loss: 0.6654: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.45it/s]\n",
            "Epoch [235] - Total Loss: 0.6766: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.06it/s]\n",
            "Epoch [236] - Total Loss: 0.6513: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [237] - Total Loss: 0.6482: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [238] - Total Loss: 0.6119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [239] - Total Loss: 0.6449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [240] - Total Loss: 0.6787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch240.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [241] - Total Loss: 0.7170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.31it/s]\n",
            "Epoch [242] - Total Loss: 0.6422: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [243] - Total Loss: 0.6297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [244] - Total Loss: 0.6061: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.12it/s]\n",
            "Epoch [245] - Total Loss: 0.6404: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.10it/s]\n",
            "Epoch [246] - Total Loss: 0.6796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.35it/s]\n",
            "Epoch [247] - Total Loss: 0.6203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [248] - Total Loss: 0.6720: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.55it/s]\n",
            "Epoch [249] - Total Loss: 0.6354: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [250] - Total Loss: 0.6214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [251] - Total Loss: 0.6695: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [252] - Total Loss: 0.6958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [253] - Total Loss: 0.6274: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.64it/s]\n",
            "Epoch [254] - Total Loss: 0.8262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [255] - Total Loss: 0.6166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [256] - Total Loss: 0.6147: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.39it/s]\n",
            "Epoch [257] - Total Loss: 0.6429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.81it/s]\n",
            "Epoch [258] - Total Loss: 0.6094: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [259] - Total Loss: 0.6438: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [260] - Total Loss: 0.6448: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch260.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [261] - Total Loss: 0.7248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.16it/s]\n",
            "Epoch [262] - Total Loss: 0.6644: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.04it/s]\n",
            "Epoch [263] - Total Loss: 0.6676: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.13it/s]\n",
            "Epoch [264] - Total Loss: 0.6555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n",
            "Epoch [265] - Total Loss: 0.6308: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.14it/s]\n",
            "Epoch [266] - Total Loss: 0.6198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.15it/s]\n",
            "Epoch [267] - Total Loss: 0.6520: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [268] - Total Loss: 0.6494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [269] - Total Loss: 0.6331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [270] - Total Loss: 0.6241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [271] - Total Loss: 0.6540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.15it/s]\n",
            "Epoch [272] - Total Loss: 0.8689: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [273] - Total Loss: 0.6133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [274] - Total Loss: 0.6132: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [275] - Total Loss: 0.6454: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [276] - Total Loss: 0.6330: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [277] - Total Loss: 0.6171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [278] - Total Loss: 0.8177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.17it/s]\n",
            "Epoch [279] - Total Loss: 0.6553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.17it/s]\n",
            "Epoch [280] - Total Loss: 0.7263: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch280.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [281] - Total Loss: 0.6747: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 10.37it/s]\n",
            "Epoch [282] - Total Loss: 0.6633: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 14.32it/s]\n",
            "Epoch [283] - Total Loss: 0.6028: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [284] - Total Loss: 0.6275: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [285] - Total Loss: 0.6327: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [286] - Total Loss: 0.7419: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.47it/s]\n",
            "Epoch [287] - Total Loss: 0.6564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [288] - Total Loss: 0.8725: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [289] - Total Loss: 0.8444: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.53it/s]\n",
            "Epoch [290] - Total Loss: 0.6406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [291] - Total Loss: 0.5890: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.06it/s]\n",
            "Epoch [292] - Total Loss: 0.6459: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [293] - Total Loss: 0.6170: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.28it/s]\n",
            "Epoch [294] - Total Loss: 0.6503: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [295] - Total Loss: 0.6009: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [296] - Total Loss: 0.7237: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [297] - Total Loss: 0.6848: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.12it/s]\n",
            "Epoch [298] - Total Loss: 0.7076: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [299] - Total Loss: 0.5968: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [300] - Total Loss: 0.6097: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch300.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [301] - Total Loss: 0.6986: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.90it/s]\n",
            "Epoch [302] - Total Loss: 0.6356: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [303] - Total Loss: 0.6363: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [304] - Total Loss: 0.7650: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [305] - Total Loss: 0.6306: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [306] - Total Loss: 0.6566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [307] - Total Loss: 0.6220: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [308] - Total Loss: 0.6462: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.74it/s]\n",
            "Epoch [309] - Total Loss: 0.7623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.75it/s]\n",
            "Epoch [310] - Total Loss: 0.5999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [311] - Total Loss: 0.6285: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.36it/s]\n",
            "Epoch [312] - Total Loss: 0.5890: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [313] - Total Loss: 0.7457: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.08it/s]\n",
            "Epoch [314] - Total Loss: 0.6330: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.74it/s]\n",
            "Epoch [315] - Total Loss: 0.6131: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [316] - Total Loss: 0.6204: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [317] - Total Loss: 0.7416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [318] - Total Loss: 0.6253: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.53it/s]\n",
            "Epoch [319] - Total Loss: 0.5991: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [320] - Total Loss: 0.6322: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch320.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [321] - Total Loss: 0.9619: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.14it/s]\n",
            "Epoch [322] - Total Loss: 0.6947: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.72it/s]\n",
            "Epoch [323] - Total Loss: 0.6874: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.42it/s]\n",
            "Epoch [324] - Total Loss: 0.6384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [325] - Total Loss: 0.6037: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.15it/s]\n",
            "Epoch [326] - Total Loss: 0.5956: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.62it/s]\n",
            "Epoch [327] - Total Loss: 0.6914: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.72it/s]\n",
            "Epoch [328] - Total Loss: 0.6241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [329] - Total Loss: 0.5884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.58it/s]\n",
            "Epoch [330] - Total Loss: 0.5923: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.55it/s]\n",
            "Epoch [331] - Total Loss: 0.8115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [332] - Total Loss: 0.6134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [333] - Total Loss: 0.6276: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [334] - Total Loss: 0.5838: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [335] - Total Loss: 0.5686: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [336] - Total Loss: 0.6215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [337] - Total Loss: 0.6394: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [338] - Total Loss: 0.6337: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [339] - Total Loss: 0.6557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [340] - Total Loss: 0.5787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch340.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [341] - Total Loss: 0.5916: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.75it/s]\n",
            "Epoch [342] - Total Loss: 0.6051: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 15.66it/s]\n",
            "Epoch [343] - Total Loss: 0.6252: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [344] - Total Loss: 0.6323: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [345] - Total Loss: 0.6119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [346] - Total Loss: 0.5994: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [347] - Total Loss: 0.5777: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [348] - Total Loss: 0.6276: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.52it/s]\n",
            "Epoch [349] - Total Loss: 0.6126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [350] - Total Loss: 0.6384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [351] - Total Loss: 0.6361: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [352] - Total Loss: 0.6871: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [353] - Total Loss: 0.7169: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.15it/s]\n",
            "Epoch [354] - Total Loss: 0.7771: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.18it/s]\n",
            "Epoch [355] - Total Loss: 0.5767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.47it/s]\n",
            "Epoch [356] - Total Loss: 0.6929: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.10it/s]\n",
            "Epoch [357] - Total Loss: 0.6431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.11it/s]\n",
            "Epoch [358] - Total Loss: 0.5762: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.55it/s]\n",
            "Epoch [359] - Total Loss: 0.7577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [360] - Total Loss: 0.7526: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch360.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [361] - Total Loss: 0.6518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00, 10.08it/s]\n",
            "Epoch [362] - Total Loss: 0.7500: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 15.15it/s]\n",
            "Epoch [363] - Total Loss: 0.7421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.65it/s]\n",
            "Epoch [364] - Total Loss: 0.6936: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [365] - Total Loss: 0.5796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [366] - Total Loss: 0.7152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.94it/s]\n",
            "Epoch [367] - Total Loss: 0.5799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [368] - Total Loss: 0.6149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.30it/s]\n",
            "Epoch [369] - Total Loss: 0.8243: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [370] - Total Loss: 0.5756: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [371] - Total Loss: 0.8126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.04it/s]\n",
            "Epoch [372] - Total Loss: 0.8149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.11it/s]\n",
            "Epoch [373] - Total Loss: 0.6032: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [374] - Total Loss: 0.8028: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [375] - Total Loss: 0.6276: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [376] - Total Loss: 0.6511: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [377] - Total Loss: 0.6617: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [378] - Total Loss: 0.7679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.02it/s]\n",
            "Epoch [379] - Total Loss: 0.5962: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [380] - Total Loss: 0.5977: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch380.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [381] - Total Loss: 0.7644: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.31it/s]\n",
            "Epoch [382] - Total Loss: 0.6157: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [383] - Total Loss: 0.6134: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [384] - Total Loss: 0.6063: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.19it/s]\n",
            "Epoch [385] - Total Loss: 0.6136: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [386] - Total Loss: 0.6240: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [387] - Total Loss: 0.6679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.13it/s]\n",
            "Epoch [388] - Total Loss: 0.5799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [389] - Total Loss: 0.6351: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [390] - Total Loss: 0.5787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [391] - Total Loss: 0.6197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [392] - Total Loss: 0.6010: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [393] - Total Loss: 0.6364: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.14it/s]\n",
            "Epoch [394] - Total Loss: 0.8015: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [395] - Total Loss: 0.6042: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.41it/s]\n",
            "Epoch [396] - Total Loss: 0.6715: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [397] - Total Loss: 0.5706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.10it/s]\n",
            "Epoch [398] - Total Loss: 0.6369: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.64it/s]\n",
            "Epoch [399] - Total Loss: 0.6376: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [400] - Total Loss: 0.5862: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch400.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [401] - Total Loss: 0.6975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.79it/s]\n",
            "Epoch [402] - Total Loss: 0.6663: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.99it/s]\n",
            "Epoch [403] - Total Loss: 0.7196: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.08it/s]\n",
            "Epoch [404] - Total Loss: 0.6157: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [405] - Total Loss: 0.5989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [406] - Total Loss: 0.6505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [407] - Total Loss: 0.5987: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.59it/s]\n",
            "Epoch [408] - Total Loss: 0.5754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [409] - Total Loss: 0.8233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [410] - Total Loss: 0.5704: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.65it/s]\n",
            "Epoch [411] - Total Loss: 0.6009: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [412] - Total Loss: 0.6224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [413] - Total Loss: 0.5975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [414] - Total Loss: 0.6874: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [415] - Total Loss: 0.6251: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.09it/s]\n",
            "Epoch [416] - Total Loss: 0.6167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [417] - Total Loss: 0.5951: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.50it/s]\n",
            "Epoch [418] - Total Loss: 0.5906: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [419] - Total Loss: 0.6266: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [420] - Total Loss: 0.6323: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch420.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [421] - Total Loss: 0.6126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 10.82it/s]\n",
            "Epoch [422] - Total Loss: 0.7870: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 13.45it/s]\n",
            "Epoch [423] - Total Loss: 0.5927: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.02it/s]\n",
            "Epoch [424] - Total Loss: 0.5843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.08it/s]\n",
            "Epoch [425] - Total Loss: 0.6365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.62it/s]\n",
            "Epoch [426] - Total Loss: 0.6047: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [427] - Total Loss: 0.5811: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [428] - Total Loss: 0.6074: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [429] - Total Loss: 0.6378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.62it/s]\n",
            "Epoch [430] - Total Loss: 0.7362: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [431] - Total Loss: 0.5571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [432] - Total Loss: 0.7479: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.44it/s]\n",
            "Epoch [433] - Total Loss: 0.7510: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [434] - Total Loss: 0.5663: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [435] - Total Loss: 0.7605: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [436] - Total Loss: 0.5847: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [437] - Total Loss: 0.6171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.99it/s]\n",
            "Epoch [438] - Total Loss: 0.6465: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [439] - Total Loss: 0.5771: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.42it/s]\n",
            "Epoch [440] - Total Loss: 0.6165: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch440.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [441] - Total Loss: 0.6816: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00, 10.15it/s]\n",
            "Epoch [442] - Total Loss: 0.6506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 15.70it/s]\n",
            "Epoch [443] - Total Loss: 0.6268: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.60it/s]\n",
            "Epoch [444] - Total Loss: 0.6287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.72it/s]\n",
            "Epoch [445] - Total Loss: 0.5950: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [446] - Total Loss: 0.6027: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.09it/s]\n",
            "Epoch [447] - Total Loss: 0.6123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [448] - Total Loss: 0.8005: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.02it/s]\n",
            "Epoch [449] - Total Loss: 0.7650: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [450] - Total Loss: 0.9272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [451] - Total Loss: 0.7794: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [452] - Total Loss: 0.6558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [453] - Total Loss: 0.6076: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [454] - Total Loss: 0.6282: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [455] - Total Loss: 0.8357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [456] - Total Loss: 0.6690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.09it/s]\n",
            "Epoch [457] - Total Loss: 0.8518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.50it/s]\n",
            "Epoch [458] - Total Loss: 0.5534: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [459] - Total Loss: 0.8171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [460] - Total Loss: 0.6032: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch460.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [461] - Total Loss: 0.6340: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 12.61it/s]\n",
            "Epoch [462] - Total Loss: 0.6477: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 13.19it/s]\n",
            "Epoch [463] - Total Loss: 0.5904: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [464] - Total Loss: 0.6203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [465] - Total Loss: 0.6286: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [466] - Total Loss: 0.6043: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [467] - Total Loss: 0.7227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.09it/s]\n",
            "Epoch [468] - Total Loss: 0.6129: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.17it/s]\n",
            "Epoch [469] - Total Loss: 0.6335: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [470] - Total Loss: 0.6723: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [471] - Total Loss: 0.6564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.12it/s]\n",
            "Epoch [472] - Total Loss: 0.5370: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [473] - Total Loss: 0.8030: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [474] - Total Loss: 0.5987: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [475] - Total Loss: 0.6074: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [476] - Total Loss: 0.7579: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [477] - Total Loss: 0.6272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.07it/s]\n",
            "Epoch [478] - Total Loss: 0.6017: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.06it/s]\n",
            "Epoch [479] - Total Loss: 0.5358: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.41it/s]\n",
            "Epoch [480] - Total Loss: 0.6448: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch480.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [481] - Total Loss: 0.5771: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.84it/s]\n",
            "Epoch [482] - Total Loss: 0.7179: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.16it/s]\n",
            "Epoch [483] - Total Loss: 0.7186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [484] - Total Loss: 0.6605: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.53it/s]\n",
            "Epoch [485] - Total Loss: 0.6028: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.94it/s]\n",
            "Epoch [486] - Total Loss: 0.6027: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [487] - Total Loss: 0.6023: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [488] - Total Loss: 0.6672: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [489] - Total Loss: 0.6219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [490] - Total Loss: 0.6496: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [491] - Total Loss: 0.7212: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.38it/s]\n",
            "Epoch [492] - Total Loss: 0.5958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.12it/s]\n",
            "Epoch [493] - Total Loss: 0.5988: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.15it/s]\n",
            "Epoch [494] - Total Loss: 0.7156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.17it/s]\n",
            "Epoch [495] - Total Loss: 0.6645: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [496] - Total Loss: 0.6105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [497] - Total Loss: 0.6205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [498] - Total Loss: 0.7484: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.59it/s]\n",
            "Epoch [499] - Total Loss: 0.5832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [500] - Total Loss: 0.6008: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch500.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [501] - Total Loss: 0.5895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 10.36it/s]\n",
            "Epoch [502] - Total Loss: 0.7693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 14.48it/s]\n",
            "Epoch [503] - Total Loss: 0.6071: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [504] - Total Loss: 0.5965: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.06it/s]\n",
            "Epoch [505] - Total Loss: 0.6557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [506] - Total Loss: 0.6571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.41it/s]\n",
            "Epoch [507] - Total Loss: 0.5690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.01it/s]\n",
            "Epoch [508] - Total Loss: 0.6047: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [509] - Total Loss: 0.6853: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.54it/s]\n",
            "Epoch [510] - Total Loss: 0.6048: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.15it/s]\n",
            "Epoch [511] - Total Loss: 0.6107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [512] - Total Loss: 0.5658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [513] - Total Loss: 0.5787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [514] - Total Loss: 0.5940: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.11it/s]\n",
            "Epoch [515] - Total Loss: 0.6308: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [516] - Total Loss: 0.5630: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.27it/s]\n",
            "Epoch [517] - Total Loss: 0.6177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [518] - Total Loss: 0.6190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [519] - Total Loss: 0.5989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [520] - Total Loss: 0.7608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch520.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [521] - Total Loss: 0.6109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.12it/s]\n",
            "Epoch [522] - Total Loss: 0.5734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [523] - Total Loss: 0.6136: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [524] - Total Loss: 0.6485: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [525] - Total Loss: 0.5662: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [526] - Total Loss: 0.6180: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [527] - Total Loss: 0.5868: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.55it/s]\n",
            "Epoch [528] - Total Loss: 0.6781: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.40it/s]\n",
            "Epoch [529] - Total Loss: 0.5816: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [530] - Total Loss: 0.7015: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [531] - Total Loss: 0.6572: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [532] - Total Loss: 0.7844: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.07it/s]\n",
            "Epoch [533] - Total Loss: 0.5660: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.62it/s]\n",
            "Epoch [534] - Total Loss: 0.8054: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n",
            "Epoch [535] - Total Loss: 0.5745: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [536] - Total Loss: 0.5623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [537] - Total Loss: 0.6911: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.23it/s]\n",
            "Epoch [538] - Total Loss: 0.6248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.47it/s]\n",
            "Epoch [539] - Total Loss: 0.5882: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [540] - Total Loss: 0.5877: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch540.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [541] - Total Loss: 0.6836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.21it/s]\n",
            "Epoch [542] - Total Loss: 0.5728: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [543] - Total Loss: 0.5938: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [544] - Total Loss: 0.5648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.17it/s]\n",
            "Epoch [545] - Total Loss: 0.6049: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.06it/s]\n",
            "Epoch [546] - Total Loss: 0.5753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.44it/s]\n",
            "Epoch [547] - Total Loss: 0.5841: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [548] - Total Loss: 0.5916: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [549] - Total Loss: 0.5540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.54it/s]\n",
            "Epoch [550] - Total Loss: 0.5681: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [551] - Total Loss: 0.6397: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [552] - Total Loss: 0.5906: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.05it/s]\n",
            "Epoch [553] - Total Loss: 0.6028: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.99it/s]\n",
            "Epoch [554] - Total Loss: 0.6073: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.29it/s]\n",
            "Epoch [555] - Total Loss: 0.6830: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [556] - Total Loss: 0.6040: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [557] - Total Loss: 0.6345: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.05it/s]\n",
            "Epoch [558] - Total Loss: 0.6041: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [559] - Total Loss: 0.5622: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [560] - Total Loss: 0.7747: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch560.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [561] - Total Loss: 0.7175: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00, 10.06it/s]\n",
            "Epoch [562] - Total Loss: 0.5695: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 14.74it/s]\n",
            "Epoch [563] - Total Loss: 0.6196: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [564] - Total Loss: 0.5732: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.72it/s]\n",
            "Epoch [565] - Total Loss: 0.6217: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [566] - Total Loss: 0.5713: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [567] - Total Loss: 0.8061: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [568] - Total Loss: 0.7632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [569] - Total Loss: 0.6357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [570] - Total Loss: 0.7189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [571] - Total Loss: 0.6150: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [572] - Total Loss: 0.5624: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [573] - Total Loss: 0.5769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [574] - Total Loss: 0.5976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [575] - Total Loss: 0.6151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.41it/s]\n",
            "Epoch [576] - Total Loss: 0.7540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.07it/s]\n",
            "Epoch [577] - Total Loss: 0.5971: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.07it/s]\n",
            "Epoch [578] - Total Loss: 0.5903: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [579] - Total Loss: 0.5578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [580] - Total Loss: 0.5914: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch580.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [581] - Total Loss: 0.5403: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.11it/s]\n",
            "Epoch [582] - Total Loss: 0.5818: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.09it/s]\n",
            "Epoch [583] - Total Loss: 0.6564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [584] - Total Loss: 0.7296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [585] - Total Loss: 0.6742: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [586] - Total Loss: 0.5325: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.55it/s]\n",
            "Epoch [587] - Total Loss: 0.6203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [588] - Total Loss: 0.7098: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [589] - Total Loss: 0.6012: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.59it/s]\n",
            "Epoch [590] - Total Loss: 0.5627: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [591] - Total Loss: 0.6173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [592] - Total Loss: 0.6594: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.02it/s]\n",
            "Epoch [593] - Total Loss: 0.5945: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [594] - Total Loss: 0.5760: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [595] - Total Loss: 0.6414: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.04it/s]\n",
            "Epoch [596] - Total Loss: 0.6258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [597] - Total Loss: 0.5695: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [598] - Total Loss: 0.5686: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.72it/s]\n",
            "Epoch [599] - Total Loss: 0.6071: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.19it/s]\n",
            "Epoch [600] - Total Loss: 0.5740: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch600.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [601] - Total Loss: 0.5437: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 10.96it/s]\n",
            "Epoch [602] - Total Loss: 0.5824: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 13.10it/s]\n",
            "Epoch [603] - Total Loss: 0.6252: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [604] - Total Loss: 0.5893: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.06it/s]\n",
            "Epoch [605] - Total Loss: 0.5958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [606] - Total Loss: 0.5936: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.05it/s]\n",
            "Epoch [607] - Total Loss: 0.5909: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [608] - Total Loss: 0.6542: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [609] - Total Loss: 0.6448: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [610] - Total Loss: 0.6007: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [611] - Total Loss: 0.5186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [612] - Total Loss: 0.7292: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.04it/s]\n",
            "Epoch [613] - Total Loss: 0.6045: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [614] - Total Loss: 0.7801: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [615] - Total Loss: 0.6195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [616] - Total Loss: 0.5207: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [617] - Total Loss: 0.5584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [618] - Total Loss: 0.5660: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.46it/s]\n",
            "Epoch [619] - Total Loss: 0.5915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.01it/s]\n",
            "Epoch [620] - Total Loss: 0.5810: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch620.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [621] - Total Loss: 0.5656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.57it/s]\n",
            "Epoch [622] - Total Loss: 0.5627: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [623] - Total Loss: 0.5389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.58it/s]\n",
            "Epoch [624] - Total Loss: 0.7244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.28it/s]\n",
            "Epoch [625] - Total Loss: 0.6909: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [626] - Total Loss: 0.6007: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [627] - Total Loss: 0.5446: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.58it/s]\n",
            "Epoch [628] - Total Loss: 0.7192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [629] - Total Loss: 0.7629: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [630] - Total Loss: 0.6954: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.62it/s]\n",
            "Epoch [631] - Total Loss: 0.5260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [632] - Total Loss: 0.6956: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.16it/s]\n",
            "Epoch [633] - Total Loss: 0.5690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.75it/s]\n",
            "Epoch [634] - Total Loss: 0.7753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [635] - Total Loss: 0.5566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.18it/s]\n",
            "Epoch [636] - Total Loss: 0.8751: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [637] - Total Loss: 0.5871: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [638] - Total Loss: 0.5833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [639] - Total Loss: 0.5730: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.08it/s]\n",
            "Epoch [640] - Total Loss: 0.6122: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch640.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [641] - Total Loss: 0.6158: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.54it/s]\n",
            "Epoch [642] - Total Loss: 0.5483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 15.64it/s]\n",
            "Epoch [643] - Total Loss: 0.5889: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [644] - Total Loss: 0.6193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.08it/s]\n",
            "Epoch [645] - Total Loss: 0.6018: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [646] - Total Loss: 0.5472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [647] - Total Loss: 0.6408: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [648] - Total Loss: 0.6298: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.06it/s]\n",
            "Epoch [649] - Total Loss: 0.6042: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [650] - Total Loss: 0.5751: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.12it/s]\n",
            "Epoch [651] - Total Loss: 0.5643: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [652] - Total Loss: 0.5456: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.59it/s]\n",
            "Epoch [653] - Total Loss: 0.5405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.05it/s]\n",
            "Epoch [654] - Total Loss: 0.5668: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [655] - Total Loss: 0.7337: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [656] - Total Loss: 0.8016: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [657] - Total Loss: 0.5774: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.15it/s]\n",
            "Epoch [658] - Total Loss: 0.5737: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.09it/s]\n",
            "Epoch [659] - Total Loss: 0.5658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [660] - Total Loss: 0.5555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch660.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [661] - Total Loss: 0.5904: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 11.23it/s]\n",
            "Epoch [662] - Total Loss: 0.5763: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 13.20it/s]\n",
            "Epoch [663] - Total Loss: 0.5692: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.99it/s]\n",
            "Epoch [664] - Total Loss: 0.6107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [665] - Total Loss: 0.5783: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [666] - Total Loss: 0.6041: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [667] - Total Loss: 0.6857: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [668] - Total Loss: 0.5801: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [669] - Total Loss: 0.5974: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.99it/s]\n",
            "Epoch [670] - Total Loss: 0.5669: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [671] - Total Loss: 0.6315: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [672] - Total Loss: 0.6947: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [673] - Total Loss: 0.6886: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [674] - Total Loss: 0.5894: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [675] - Total Loss: 0.6944: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [676] - Total Loss: 0.5818: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.02it/s]\n",
            "Epoch [677] - Total Loss: 0.6091: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.39it/s]\n",
            "Epoch [678] - Total Loss: 0.6533: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [679] - Total Loss: 0.6233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.08it/s]\n",
            "Epoch [680] - Total Loss: 0.5444: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch680.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [681] - Total Loss: 0.8107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.15it/s]\n",
            "Epoch [682] - Total Loss: 0.7050: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.25it/s]\n",
            "Epoch [683] - Total Loss: 0.5565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.09it/s]\n",
            "Epoch [684] - Total Loss: 0.5721: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.81it/s]\n",
            "Epoch [685] - Total Loss: 0.7886: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [686] - Total Loss: 0.5612: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [687] - Total Loss: 0.5619: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.47it/s]\n",
            "Epoch [688] - Total Loss: 0.5415: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.52it/s]\n",
            "Epoch [689] - Total Loss: 0.5709: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.50it/s]\n",
            "Epoch [690] - Total Loss: 0.5464: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [691] - Total Loss: 0.5795: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [692] - Total Loss: 0.5608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.25it/s]\n",
            "Epoch [693] - Total Loss: 0.5317: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [694] - Total Loss: 0.5598: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [695] - Total Loss: 0.5493: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.60it/s]\n",
            "Epoch [696] - Total Loss: 0.5866: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [697] - Total Loss: 0.5592: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [698] - Total Loss: 0.5688: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [699] - Total Loss: 0.7152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.43it/s]\n",
            "Epoch [700] - Total Loss: 0.5657: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch700.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [701] - Total Loss: 0.5647: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.92it/s]\n",
            "Epoch [702] - Total Loss: 0.5984: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [703] - Total Loss: 0.5939: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.49it/s]\n",
            "Epoch [704] - Total Loss: 0.6061: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.36it/s]\n",
            "Epoch [705] - Total Loss: 0.7316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [706] - Total Loss: 0.5693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [707] - Total Loss: 0.6772: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.31it/s]\n",
            "Epoch [708] - Total Loss: 0.5955: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.75it/s]\n",
            "Epoch [709] - Total Loss: 0.5387: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [710] - Total Loss: 0.6724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [711] - Total Loss: 0.5303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.49it/s]\n",
            "Epoch [712] - Total Loss: 0.6136: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [713] - Total Loss: 0.5584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.54it/s]\n",
            "Epoch [714] - Total Loss: 0.6245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.32it/s]\n",
            "Epoch [715] - Total Loss: 0.5745: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [716] - Total Loss: 0.5619: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.06it/s]\n",
            "Epoch [717] - Total Loss: 0.6825: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.40it/s]\n",
            "Epoch [718] - Total Loss: 0.5840: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [719] - Total Loss: 0.6186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.58it/s]\n",
            "Epoch [720] - Total Loss: 0.5706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch720.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [721] - Total Loss: 0.6972: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.31it/s]\n",
            "Epoch [722] - Total Loss: 0.5401: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n",
            "Epoch [723] - Total Loss: 0.7731: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [724] - Total Loss: 0.6082: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [725] - Total Loss: 0.5562: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [726] - Total Loss: 0.7309: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [727] - Total Loss: 0.6056: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.06it/s]\n",
            "Epoch [728] - Total Loss: 0.5653: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.57it/s]\n",
            "Epoch [729] - Total Loss: 0.5598: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.57it/s]\n",
            "Epoch [730] - Total Loss: 0.5924: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [731] - Total Loss: 0.5733: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [732] - Total Loss: 0.5734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.53it/s]\n",
            "Epoch [733] - Total Loss: 0.5781: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [734] - Total Loss: 0.5938: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [735] - Total Loss: 0.7178: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [736] - Total Loss: 0.8146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.49it/s]\n",
            "Epoch [737] - Total Loss: 0.5717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.65it/s]\n",
            "Epoch [738] - Total Loss: 0.5647: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.44it/s]\n",
            "Epoch [739] - Total Loss: 0.6518: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.36it/s]\n",
            "Epoch [740] - Total Loss: 0.5928: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch740.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [741] - Total Loss: 0.8358: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.82it/s]\n",
            "Epoch [742] - Total Loss: 0.8284: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.64it/s]\n",
            "Epoch [743] - Total Loss: 0.5821: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [744] - Total Loss: 0.6701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.42it/s]\n",
            "Epoch [745] - Total Loss: 0.6223: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.02it/s]\n",
            "Epoch [746] - Total Loss: 0.8406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [747] - Total Loss: 0.7637: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [748] - Total Loss: 0.6200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [749] - Total Loss: 0.5637: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.01it/s]\n",
            "Epoch [750] - Total Loss: 0.7599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.94it/s]\n",
            "Epoch [751] - Total Loss: 0.6016: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [752] - Total Loss: 0.5565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [753] - Total Loss: 0.8143: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [754] - Total Loss: 0.6589: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [755] - Total Loss: 0.6214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [756] - Total Loss: 0.5607: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.54it/s]\n",
            "Epoch [757] - Total Loss: 0.6217: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.54it/s]\n",
            "Epoch [758] - Total Loss: 0.5463: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [759] - Total Loss: 0.5893: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [760] - Total Loss: 0.5553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch760.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [761] - Total Loss: 0.5569: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.41it/s]\n",
            "Epoch [762] - Total Loss: 0.5680: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.50it/s]\n",
            "Epoch [763] - Total Loss: 0.7433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.05it/s]\n",
            "Epoch [764] - Total Loss: 0.5862: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [765] - Total Loss: 0.6269: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.04it/s]\n",
            "Epoch [766] - Total Loss: 0.5327: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [767] - Total Loss: 0.6075: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [768] - Total Loss: 0.5777: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [769] - Total Loss: 0.5700: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [770] - Total Loss: 0.6041: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [771] - Total Loss: 0.7635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.08it/s]\n",
            "Epoch [772] - Total Loss: 0.5391: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.60it/s]\n",
            "Epoch [773] - Total Loss: 0.7293: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [774] - Total Loss: 0.7222: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [775] - Total Loss: 0.5884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [776] - Total Loss: 0.7279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.46it/s]\n",
            "Epoch [777] - Total Loss: 0.5861: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [778] - Total Loss: 0.5514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [779] - Total Loss: 0.7131: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [780] - Total Loss: 0.5217: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch780.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [781] - Total Loss: 0.6219: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 10.49it/s]\n",
            "Epoch [782] - Total Loss: 0.5366: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 13.84it/s]\n",
            "Epoch [783] - Total Loss: 0.5523: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [784] - Total Loss: 0.5707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.60it/s]\n",
            "Epoch [785] - Total Loss: 0.5341: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.09it/s]\n",
            "Epoch [786] - Total Loss: 0.5942: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.13it/s]\n",
            "Epoch [787] - Total Loss: 0.5497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [788] - Total Loss: 0.5434: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.50it/s]\n",
            "Epoch [789] - Total Loss: 0.7215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.94it/s]\n",
            "Epoch [790] - Total Loss: 0.5388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.74it/s]\n",
            "Epoch [791] - Total Loss: 0.7060: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.53it/s]\n",
            "Epoch [792] - Total Loss: 0.5916: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [793] - Total Loss: 0.6833: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [794] - Total Loss: 0.5984: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.50it/s]\n",
            "Epoch [795] - Total Loss: 0.5642: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.01it/s]\n",
            "Epoch [796] - Total Loss: 0.5537: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [797] - Total Loss: 0.6796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [798] - Total Loss: 0.5645: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.45it/s]\n",
            "Epoch [799] - Total Loss: 0.6286: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [800] - Total Loss: 0.5691: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch800.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [801] - Total Loss: 0.6145: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.22it/s]\n",
            "Epoch [802] - Total Loss: 0.5686: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.54it/s]\n",
            "Epoch [803] - Total Loss: 0.6030: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [804] - Total Loss: 0.6893: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [805] - Total Loss: 0.6683: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [806] - Total Loss: 0.8146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.45it/s]\n",
            "Epoch [807] - Total Loss: 0.5752: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.75it/s]\n",
            "Epoch [808] - Total Loss: 0.5750: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.12it/s]\n",
            "Epoch [809] - Total Loss: 0.5989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.58it/s]\n",
            "Epoch [810] - Total Loss: 0.6823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.52it/s]\n",
            "Epoch [811] - Total Loss: 0.5852: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [812] - Total Loss: 0.6909: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [813] - Total Loss: 0.9526: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.29it/s]\n",
            "Epoch [814] - Total Loss: 0.5813: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [815] - Total Loss: 0.7152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.81it/s]\n",
            "Epoch [816] - Total Loss: 0.5287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.52it/s]\n",
            "Epoch [817] - Total Loss: 0.5946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [818] - Total Loss: 0.7797: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [819] - Total Loss: 0.5638: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [820] - Total Loss: 0.6021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch820.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [821] - Total Loss: 0.5830: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 10.27it/s]\n",
            "Epoch [822] - Total Loss: 0.6207: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 13.99it/s]\n",
            "Epoch [823] - Total Loss: 0.5953: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [824] - Total Loss: 0.5429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.60it/s]\n",
            "Epoch [825] - Total Loss: 0.5956: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [826] - Total Loss: 0.6964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [827] - Total Loss: 0.5890: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [828] - Total Loss: 0.5995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.65it/s]\n",
            "Epoch [829] - Total Loss: 0.7464: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [830] - Total Loss: 0.5639: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [831] - Total Loss: 0.6048: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n",
            "Epoch [832] - Total Loss: 0.5556: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [833] - Total Loss: 0.6535: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [834] - Total Loss: 0.5828: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.69it/s]\n",
            "Epoch [835] - Total Loss: 0.5721: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [836] - Total Loss: 0.5566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [837] - Total Loss: 0.5701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [838] - Total Loss: 0.6379: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.74it/s]\n",
            "Epoch [839] - Total Loss: 0.5635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [840] - Total Loss: 0.5868: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch840.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [841] - Total Loss: 0.5792: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.14it/s]\n",
            "Epoch [842] - Total Loss: 0.5767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n",
            "Epoch [843] - Total Loss: 0.5772: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 15.98it/s]\n",
            "Epoch [844] - Total Loss: 0.5827: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [845] - Total Loss: 0.5251: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.65it/s]\n",
            "Epoch [846] - Total Loss: 0.6438: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.42it/s]\n",
            "Epoch [847] - Total Loss: 0.5720: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.72it/s]\n",
            "Epoch [848] - Total Loss: 0.6137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.07it/s]\n",
            "Epoch [849] - Total Loss: 0.5932: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.64it/s]\n",
            "Epoch [850] - Total Loss: 0.6701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [851] - Total Loss: 0.5575: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.07it/s]\n",
            "Epoch [852] - Total Loss: 0.5684: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.07it/s]\n",
            "Epoch [853] - Total Loss: 0.5695: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [854] - Total Loss: 0.7195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [855] - Total Loss: 0.5865: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.20it/s]\n",
            "Epoch [856] - Total Loss: 0.6287: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.30it/s]\n",
            "Epoch [857] - Total Loss: 0.5689: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.85it/s]\n",
            "Epoch [858] - Total Loss: 0.7294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.30it/s]\n",
            "Epoch [859] - Total Loss: 0.5777: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.72it/s]\n",
            "Epoch [860] - Total Loss: 0.6551: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch860.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [861] - Total Loss: 0.5511: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.59it/s]\n",
            "Epoch [862] - Total Loss: 0.5677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 15.92it/s]\n",
            "Epoch [863] - Total Loss: 0.7476: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [864] - Total Loss: 0.6192: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [865] - Total Loss: 0.7960: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.61it/s]\n",
            "Epoch [866] - Total Loss: 0.8209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [867] - Total Loss: 0.6199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [868] - Total Loss: 0.6018: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.57it/s]\n",
            "Epoch [869] - Total Loss: 0.6991: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [870] - Total Loss: 0.5245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [871] - Total Loss: 0.5880: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.52it/s]\n",
            "Epoch [872] - Total Loss: 0.5442: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [873] - Total Loss: 0.5857: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.37it/s]\n",
            "Epoch [874] - Total Loss: 0.5644: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.57it/s]\n",
            "Epoch [875] - Total Loss: 0.5769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.47it/s]\n",
            "Epoch [876] - Total Loss: 0.5831: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [877] - Total Loss: 0.5830: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [878] - Total Loss: 0.5376: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.42it/s]\n",
            "Epoch [879] - Total Loss: 0.5521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [880] - Total Loss: 0.5332: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch880.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [881] - Total Loss: 0.5595: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 10.67it/s]\n",
            "Epoch [882] - Total Loss: 0.5258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 13.40it/s]\n",
            "Epoch [883] - Total Loss: 0.6845: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.47it/s]\n",
            "Epoch [884] - Total Loss: 0.5304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [885] - Total Loss: 0.5759: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [886] - Total Loss: 0.5767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n",
            "Epoch [887] - Total Loss: 0.5739: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [888] - Total Loss: 0.6617: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.74it/s]\n",
            "Epoch [889] - Total Loss: 0.5062: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [890] - Total Loss: 0.5592: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.59it/s]\n",
            "Epoch [891] - Total Loss: 0.6740: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.75it/s]\n",
            "Epoch [892] - Total Loss: 0.6137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.00it/s]\n",
            "Epoch [893] - Total Loss: 0.6257: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.70it/s]\n",
            "Epoch [894] - Total Loss: 0.5467: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [895] - Total Loss: 0.6152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [896] - Total Loss: 0.5622: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.31it/s]\n",
            "Epoch [897] - Total Loss: 0.5714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.07it/s]\n",
            "Epoch [898] - Total Loss: 0.5406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [899] - Total Loss: 0.6399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.40it/s]\n",
            "Epoch [900] - Total Loss: 0.7832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch900.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [901] - Total Loss: 0.5447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 11.16it/s]\n",
            "Epoch [902] - Total Loss: 0.7590: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 14.82it/s]\n",
            "Epoch [903] - Total Loss: 0.5329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [904] - Total Loss: 0.7062: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [905] - Total Loss: 0.6925: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.52it/s]\n",
            "Epoch [906] - Total Loss: 0.5713: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.05it/s]\n",
            "Epoch [907] - Total Loss: 0.5290: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [908] - Total Loss: 0.8057: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.51it/s]\n",
            "Epoch [909] - Total Loss: 0.7331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [910] - Total Loss: 0.5921: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.05it/s]\n",
            "Epoch [911] - Total Loss: 0.6180: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.55it/s]\n",
            "Epoch [912] - Total Loss: 0.7429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.90it/s]\n",
            "Epoch [913] - Total Loss: 0.5325: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.98it/s]\n",
            "Epoch [914] - Total Loss: 0.5251: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.75it/s]\n",
            "Epoch [915] - Total Loss: 0.6530: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.47it/s]\n",
            "Epoch [916] - Total Loss: 0.5769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.64it/s]\n",
            "Epoch [917] - Total Loss: 0.7606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.66it/s]\n",
            "Epoch [918] - Total Loss: 0.6613: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.38it/s]\n",
            "Epoch [919] - Total Loss: 0.5543: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.53it/s]\n",
            "Epoch [920] - Total Loss: 0.5955: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch920.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [921] - Total Loss: 0.5716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 11.02it/s]\n",
            "Epoch [922] - Total Loss: 0.6005: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 14.39it/s]\n",
            "Epoch [923] - Total Loss: 0.5781: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.31it/s]\n",
            "Epoch [924] - Total Loss: 0.8179: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.76it/s]\n",
            "Epoch [925] - Total Loss: 0.7108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [926] - Total Loss: 0.5823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.56it/s]\n",
            "Epoch [927] - Total Loss: 0.5902: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.37it/s]\n",
            "Epoch [928] - Total Loss: 0.6029: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.84it/s]\n",
            "Epoch [929] - Total Loss: 0.5410: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.81it/s]\n",
            "Epoch [930] - Total Loss: 0.7790: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.32it/s]\n",
            "Epoch [931] - Total Loss: 0.6476: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.49it/s]\n",
            "Epoch [932] - Total Loss: 0.5805: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n",
            "Epoch [933] - Total Loss: 0.5643: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.33it/s]\n",
            "Epoch [934] - Total Loss: 0.5425: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [935] - Total Loss: 0.5857: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.96it/s]\n",
            "Epoch [936] - Total Loss: 0.5427: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.63it/s]\n",
            "Epoch [937] - Total Loss: 0.5842: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [938] - Total Loss: 0.5417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [939] - Total Loss: 0.5579: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.01it/s]\n",
            "Epoch [940] - Total Loss: 0.5529: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch940.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [941] - Total Loss: 0.5643: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 11.26it/s]\n",
            "Epoch [942] - Total Loss: 0.5719: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 12.88it/s]\n",
            "Epoch [943] - Total Loss: 0.5310: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.08it/s]\n",
            "Epoch [944] - Total Loss: 0.5591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [945] - Total Loss: 0.7438: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.57it/s]\n",
            "Epoch [946] - Total Loss: 0.5251: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.64it/s]\n",
            "Epoch [947] - Total Loss: 0.5875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [948] - Total Loss: 0.5798: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [949] - Total Loss: 0.5544: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.95it/s]\n",
            "Epoch [950] - Total Loss: 0.6969: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.12it/s]\n",
            "Epoch [951] - Total Loss: 0.5659: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [952] - Total Loss: 0.6953: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.53it/s]\n",
            "Epoch [953] - Total Loss: 0.5417: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.77it/s]\n",
            "Epoch [954] - Total Loss: 0.5902: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [955] - Total Loss: 0.5488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.44it/s]\n",
            "Epoch [956] - Total Loss: 0.5269: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.19it/s]\n",
            "Epoch [957] - Total Loss: 0.6990: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.83it/s]\n",
            "Epoch [958] - Total Loss: 0.5842: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.82it/s]\n",
            "Epoch [959] - Total Loss: 0.7313: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.75it/s]\n",
            "Epoch [960] - Total Loss: 0.7234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch960.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [961] - Total Loss: 0.5652: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:06<00:00,  9.60it/s]\n",
            "Epoch [962] - Total Loss: 0.6998: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n",
            "Epoch [963] - Total Loss: 0.5751: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [964] - Total Loss: 0.6681: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.80it/s]\n",
            "Epoch [965] - Total Loss: 0.5920: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [966] - Total Loss: 0.7127: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.68it/s]\n",
            "Epoch [967] - Total Loss: 0.5289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.94it/s]\n",
            "Epoch [968] - Total Loss: 0.5881: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n",
            "Epoch [969] - Total Loss: 0.5539: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.62it/s]\n",
            "Epoch [970] - Total Loss: 0.6038: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.50it/s]\n",
            "Epoch [971] - Total Loss: 0.6037: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [972] - Total Loss: 0.5352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.89it/s]\n",
            "Epoch [973] - Total Loss: 0.5811: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.67it/s]\n",
            "Epoch [974] - Total Loss: 0.6262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.03it/s]\n",
            "Epoch [975] - Total Loss: 0.5541: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [976] - Total Loss: 0.5946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.91it/s]\n",
            "Epoch [977] - Total Loss: 0.7556: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.73it/s]\n",
            "Epoch [978] - Total Loss: 0.5548: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.44it/s]\n",
            "Epoch [979] - Total Loss: 0.5827: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.41it/s]\n",
            "Epoch [980] - Total Loss: 0.5416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch980.png and model checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [981] - Total Loss: 0.5468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:05<00:00, 10.35it/s]\n",
            "Epoch [982] - Total Loss: 0.7033: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:04<00:00, 13.67it/s]\n",
            "Epoch [983] - Total Loss: 0.6924: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.93it/s]\n",
            "Epoch [984] - Total Loss: 0.5406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.97it/s]\n",
            "Epoch [985] - Total Loss: 0.7257: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.28it/s]\n",
            "Epoch [986] - Total Loss: 0.7030: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.11it/s]\n",
            "Epoch [987] - Total Loss: 0.5686: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.87it/s]\n",
            "Epoch [988] - Total Loss: 0.6118: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.71it/s]\n",
            "Epoch [989] - Total Loss: 0.5483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.78it/s]\n",
            "Epoch [990] - Total Loss: 0.7977: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.20it/s]\n",
            "Epoch [991] - Total Loss: 0.5839: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.10it/s]\n",
            "Epoch [992] - Total Loss: 0.5551: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.48it/s]\n",
            "Epoch [993] - Total Loss: 0.8069: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.05it/s]\n",
            "Epoch [994] - Total Loss: 0.5769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 17.15it/s]\n",
            "Epoch [995] - Total Loss: 0.5822: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.44it/s]\n",
            "Epoch [996] - Total Loss: 0.8033: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.79it/s]\n",
            "Epoch [997] - Total Loss: 0.6750: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [998] - Total Loss: 0.5565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.88it/s]\n",
            "Epoch [999] - Total Loss: 0.5335: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.92it/s]\n",
            "Epoch [1000] - Total Loss: 0.6012: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:03<00:00, 16.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: sample_epoch1000.png and model checkpoints\n"
          ]
        }
      ],
      "source": [
        "#FINAL EXECUTED CODE TRAINING USIN LATENT DIFFUSION MODEL\n",
        "# âœ… FINAL FIXED LDM + DDIM SAMPLING + EMA + CHECKPOINTING (IMPROVED CNN + KL + REALISTIC SAMPLING)\n",
        "import torch, os\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms as T\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torch.amp import autocast, GradScaler\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# âœ… CONFIG\n",
        "IMG_SIZE = 512\n",
        "LATENT_DIM = 1024\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 1000\n",
        "WARMUP_EPOCHS = 100\n",
        "LR = 2e-4\n",
        "TIMESTEPS = 1000\n",
        "DATA_PATH = \"/content/drive/MyDrive/GALLMILDGEDAMAGE\"\n",
        "\n",
        "# âœ… DEVICE & OUTPUT\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "scaler = GradScaler()\n",
        "os.makedirs(\"ldmG_outputs\", exist_ok=True)\n",
        "\n",
        "# âœ… DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# âœ… LOADER\n",
        "dataset = SingleClassImageDataset(DATA_PATH, transform)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "# âœ… MODELS\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# âœ… TRAINING SETUP\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()) + list(unet.parameters()), lr=LR)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# âœ… KL Loss\n",
        "def kl_divergence(mu):\n",
        "    return -0.5 * torch.sum(1 + 0 - mu.pow(2) - 1, dim=1).mean()\n",
        "\n",
        "# âœ… TRAIN LOOP\n",
        "print(\"\\nðŸš€ Starting Training...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    encoder.train(); decoder.train(); unet.train()\n",
        "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    for images, _ in pbar:\n",
        "        images = images.to(device)\n",
        "        with autocast(device_type=device.type):\n",
        "            z = encoder(images)\n",
        "            recon = decoder(z)\n",
        "            recon_loss = F.mse_loss(recon, images)\n",
        "            kl_loss = kl_divergence(z)\n",
        "            loss_autoenc = recon_loss + 0.001 * kl_loss\n",
        "\n",
        "            t = torch.randint(0, TIMESTEPS, (z.size(0),), device=device).long()\n",
        "            noise = torch.randn_like(z)\n",
        "            alpha_hat = scheduler_alpha_hat[t][:, None]\n",
        "            noisy_z = (alpha_hat**0.5) * z + ((1 - alpha_hat)**0.5) * noise\n",
        "            pred = unet(noisy_z, t)\n",
        "            diffusion_loss = F.mse_loss(pred, noise)\n",
        "\n",
        "            total_loss = loss_autoenc + diffusion_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(total_loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        pbar.set_description(f\"Epoch [{epoch+1}] - Total Loss: {total_loss.item():.4f}\")\n",
        "\n",
        "    # Save every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        with torch.no_grad():\n",
        "            # Sample latents from real images\n",
        "            sample_images, _ = next(iter(dataloader))\n",
        "            z_sample = encoder(sample_images.to(device))\n",
        "            samples = decoder(z_sample)\n",
        "            save_image((samples + 1) / 2, f\"ldmG_outputs/sample_epoch{epoch+1}.png\", nrow=4)\n",
        "            torch.save(encoder.state_dict(), f\"ldmG_outputs/encoder_epoch{epoch+1}.pth\")\n",
        "            torch.save(decoder.state_dict(), f\"ldmG_outputs/decoder_epoch{epoch+1}.pth\")\n",
        "            torch.save(unet.state_dict(),    f\"ldmG_outputs/unet_epoch{epoch+1}.pth\")\n",
        "            print(f\"âœ… Saved: sample_epoch{epoch+1}.png and model checkpoints\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnJP30F902hQ",
        "outputId": "5dbca3a4-6873-4b4f-b3ed-39a2ab4f9496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… 5000 images generated from real latents\n",
            "âœ… Zipped outputs at: ldm1_outputs/generated_best.zip\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSetting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233M/233M [00:01<00:00, 207MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "âœ… LPIPS Diversity Score: 0.5576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104M/104M [00:00<00:00, 149MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… FID Score: 7.27\n"
          ]
        }
      ],
      "source": [
        "# âœ… GENERATION CODE MATCHING TRAINING QUALITY (REAL LATENTS + DDIM OPTION + ZIP + FID/LPIPS)\n",
        "import torch, os, zipfile\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import trange\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from scipy import linalg\n",
        "from itertools import cycle\n",
        "\n",
        "# âœ… CONFIG (same as training)\n",
        "LATENT_DIM = 1024\n",
        "TIMESTEPS = 1000\n",
        "IMG_SIZE = 512\n",
        "DATA_PATH = \"/content/drive/MyDrive/GALLMILDGEDAMAGE\"\n",
        "\n",
        "# âœ… DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… Schedulers (same as training)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# âœ… DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "ref_transform = T.Compose([\n",
        "    T.Resize((299, 299)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Real data loader for FID\n",
        "ref_dataset = SingleClassImageDataset(DATA_PATH, ref_transform)\n",
        "ref_loader = DataLoader(ref_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# âœ… MODELS (same as training)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# âœ… Instantiate models\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "\n",
        "# âœ… Load trained weights\n",
        "encoder.load_state_dict(torch.load(\"ldmG_outputs/encoder_epoch1000.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"ldmG_outputs/decoder_epoch1000.pth\"))\n",
        "unet.load_state_dict(torch.load(\"ldmG_outputs/unet_epoch1000.pth\"))\n",
        "encoder.eval(); decoder.eval(); unet.eval()\n",
        "\n",
        "# âœ… OUTPUT FOLDER\n",
        "output_dir = \"ldm1_outputs/generated_best\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# âœ… Generation function (real latents)\n",
        "@torch.no_grad()\n",
        "def generate_from_real_latents(encoder_model, decoder_model, dataloader, num_samples=5000):\n",
        "    count = 0\n",
        "    loop_loader = cycle(dataloader)  # Infinite loop over dataset\n",
        "    for images, _ in loop_loader:\n",
        "        z = encoder_model(images.to(device))\n",
        "        imgs = decoder_model(z)\n",
        "        imgs = (imgs + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(output_dir, f\"real_latent_{count + j + 1:05}.png\"))\n",
        "        count += len(imgs)\n",
        "        if count >= num_samples:\n",
        "            break\n",
        "    print(f\"âœ… {num_samples} images generated from real latents\")\n",
        "\n",
        "# âœ… Generation function (DDIM)\n",
        "@torch.no_grad()\n",
        "def generate_ddim(unet_model, decoder_model, steps=250, batch_size=8, total=5000):\n",
        "    for i in trange(0, total, batch_size):\n",
        "        bs = min(batch_size, total - i)\n",
        "        z = torch.randn(bs, LATENT_DIM).to(device)\n",
        "        for t in reversed(range(steps)):\n",
        "            t_tensor = torch.full((bs,), t, dtype=torch.long, device=device)\n",
        "            beta = scheduler_betas[t]\n",
        "            alpha = scheduler_alphas[t]\n",
        "            alpha_hat = scheduler_alpha_hat[t]\n",
        "            noise_pred = unet_model(z, t_tensor)\n",
        "            z = (z - beta / torch.sqrt(1 - alpha_hat) * noise_pred) / torch.sqrt(alpha)\n",
        "            if t > 0:\n",
        "                z += torch.randn_like(z) * beta.sqrt()\n",
        "        imgs = (decoder_model(z) + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            save_image(img, os.path.join(output_dir, f\"ddim_sample_{i + j + 1:05}.png\"))\n",
        "    print(f\"âœ… {total} images generated using DDIM\")\n",
        "\n",
        "# ðŸ” Mode selector\n",
        "mode = \"real\"\n",
        "if mode == \"real\":\n",
        "    generate_from_real_latents(encoder, decoder, DataLoader(SingleClassImageDataset(DATA_PATH, transform), batch_size=8, shuffle=True), num_samples=5000)\n",
        "else:\n",
        "    generate_ddim(unet, decoder, steps=250, batch_size=8, total=5000)\n",
        "\n",
        "# âœ… ZIP GENERATED IMAGES\n",
        "zip_path = output_dir + \".zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, _, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), arcname=file)\n",
        "print(f\"âœ… Zipped outputs at: {zip_path}\")\n",
        "\n",
        "# âœ… LPIPS Diversity\n",
        "!pip install lpips --quiet\n",
        "import lpips\n",
        "lpips_model = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "img_paths = sorted([os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(\".png\")])[:100]\n",
        "imgs = [transform(Image.open(p).convert(\"RGB\")).unsqueeze(0).to(device) for p in img_paths]\n",
        "\n",
        "div_sum = 0\n",
        "pairs = 0\n",
        "for i in range(len(imgs)):\n",
        "    for j in range(i+1, len(imgs)):\n",
        "        dist = lpips_model(imgs[i], imgs[j])\n",
        "        div_sum += dist.item()\n",
        "        pairs += 1\n",
        "print(f\"âœ… LPIPS Diversity Score: {div_sum/pairs:.4f}\")\n",
        "\n",
        "# âœ… FID Score\n",
        "@torch.no_grad()\n",
        "def get_activations(dataloader, model):\n",
        "    model.eval()\n",
        "    activations = []\n",
        "    up = T.Resize((299, 299))\n",
        "    for imgs, _ in dataloader:\n",
        "        imgs = up(imgs).to(device)\n",
        "        preds = model(imgs)\n",
        "        if isinstance(preds, tuple):\n",
        "            preds = preds[0]\n",
        "        preds = preds.view(preds.size(0), -1)\n",
        "        activations.append(preds.cpu().numpy())\n",
        "    return np.concatenate(activations, axis=0)\n",
        "\n",
        "inception = models.inception_v3(pretrained=True, transform_input=False).to(device)\n",
        "inception.fc = nn.Identity()\n",
        "inception.eval()\n",
        "\n",
        "# Generated loader for FID\n",
        "gen_dataset = SingleClassImageDataset(output_dir, ref_transform)\n",
        "gen_loader = DataLoader(gen_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "act1 = get_activations(ref_loader, inception)\n",
        "act2 = get_activations(gen_loader, inception)\n",
        "mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
        "mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
        "\n",
        "fid = np.sum((mu1 - mu2)**2) + np.trace(sigma1 + sigma2 - 2 * linalg.sqrtm(sigma1.dot(sigma2)).real)\n",
        "print(f\"âœ… FID Score: {fid:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path where you want to move the zip file in Drive\n",
        "drive_dest = \"/content/drive/MyDrive/GALLMIDGE2\"\n",
        "\n",
        "# Move zip from current dir to Drive\n",
        "shutil.move(\"/content/ldm2_outputs/generated_best.zip\", drive_dest)\n",
        "\n",
        "print(\"âœ… Moved to Google Drive at:\", drive_dest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi4uVXOUwogW",
        "outputId": "dba50557-8328-477d-beaf-6a6634d8599b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Moved to Google Drive at: /content/drive/MyDrive/GALLMIDGE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GENERATING NEXT 5000 IMAGES\n",
        "# âœ… GENERATION CODE MATCHING TRAINING QUALITY (REAL LATENTS + DDIM OPTION + ZIP + FID/LPIPS)\n",
        "import torch, os, zipfile\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import trange\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from scipy import linalg\n",
        "from itertools import cycle\n",
        "\n",
        "# âœ… CONFIG (same as training)\n",
        "LATENT_DIM = 1024\n",
        "TIMESTEPS = 1000\n",
        "IMG_SIZE = 512\n",
        "DATA_PATH = \"/content/drive/MyDrive/GALLMILDGEDAMAGE\"\n",
        "\n",
        "# âœ… DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… Schedulers (same as training)\n",
        "scheduler_betas = torch.linspace(1e-4, 0.02, TIMESTEPS).to(device)\n",
        "scheduler_alphas = 1. - scheduler_betas\n",
        "scheduler_alpha_hat = torch.cumprod(scheduler_alphas, dim=0)\n",
        "\n",
        "# âœ… DATASET\n",
        "class SingleClassImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith((\".png\", \".jpg\"))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, 0\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "ref_transform = T.Compose([\n",
        "    T.Resize((299, 299)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# Real data loader for FID\n",
        "ref_dataset = SingleClassImageDataset(DATA_PATH, ref_transform)\n",
        "ref_loader = DataLoader(ref_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# âœ… MODELS (same as training)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 16 * 16, latent_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 512 * 16 * 16)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 3, 4, 2, 1), nn.Tanh()\n",
        "        )\n",
        "    def forward(self, z): return self.net(self.fc(z).view(-1, 512, 16, 16))\n",
        "\n",
        "class LatentUNet(nn.Module):\n",
        "    def __init__(self, latent_dim, timesteps):\n",
        "        super().__init__()\n",
        "        self.time_embed = nn.Embedding(timesteps, latent_dim)\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, 1024), nn.ReLU(),\n",
        "            nn.Linear(1024, latent_dim)\n",
        "        )\n",
        "    def forward(self, x, t):\n",
        "        return self.fc1(x + self.time_embed(t))\n",
        "\n",
        "# âœ… Instantiate models\n",
        "encoder = Encoder(LATENT_DIM).to(device)\n",
        "decoder = Decoder(LATENT_DIM).to(device)\n",
        "unet = LatentUNet(LATENT_DIM, TIMESTEPS).to(device)\n",
        "\n",
        "# âœ… Load trained weights\n",
        "encoder.load_state_dict(torch.load(\"ldmG_outputs/encoder_epoch1000.pth\"))\n",
        "decoder.load_state_dict(torch.load(\"ldmG_outputs/decoder_epoch1000.pth\"))\n",
        "unet.load_state_dict(torch.load(\"ldmG_outputs/unet_epoch1000.pth\"))\n",
        "encoder.eval(); decoder.eval(); unet.eval()\n",
        "\n",
        "# âœ… OUTPUT FOLDER\n",
        "output_dir = \"ldm2_outputs/generated_best_2\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# âœ… Generation function (real latents)\n",
        "@torch.no_grad()\n",
        "def generate_from_real_latents(encoder_model, decoder_model, dataloader, num_samples=5000, offset=5000):\n",
        "    count = 0\n",
        "    loop_loader = cycle(dataloader)  # Infinite loop over dataset\n",
        "    for images, _ in loop_loader:\n",
        "        z = encoder_model(images.to(device))\n",
        "        imgs = decoder_model(z)\n",
        "        imgs = (imgs + 1) / 2\n",
        "        for j, img in enumerate(imgs):\n",
        "            index = offset + count + j + 1\n",
        "            save_image(img, os.path.join(output_dir, f\"real_latent_{index:05}.png\"))\n",
        "        count += len(imgs)\n",
        "        if count >= num_samples:\n",
        "            break\n",
        "    print(f\"âœ… {num_samples} images generated from real latents\")\n",
        "\n",
        "# âœ… Mode selector\n",
        "mode = \"real\"\n",
        "if mode == \"real\":\n",
        "    generate_from_real_latents(encoder, decoder, DataLoader(SingleClassImageDataset(DATA_PATH, transform), batch_size=8, shuffle=True), num_samples=5000, offset=5000)\n",
        "\n",
        "# âœ… ZIP GENERATED IMAGES\n",
        "zip_path = output_dir + \".zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for root, _, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            zipf.write(os.path.join(root, file), arcname=file)\n",
        "print(f\"âœ… Zipped outputs at: {zip_path}\")\n"
      ],
      "metadata": {
        "id": "V--H3ptPDYqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e2c8e0b-6626-42ed-ffce-ec1b205f36b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… 5000 images generated from real latents\n",
            "âœ… Zipped outputs at: ldm2_outputs/generated_best_2.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Path where you want to move the zip file in Drive\n",
        "drive_dest = \"/content/drive/MyDrive/GALLMIDGE2\"\n",
        "\n",
        "# Move zip from current dir to Drive\n",
        "shutil.move(\"/content/ldm2_outputs/generated_best_2.zip\", drive_dest)\n",
        "\n",
        "print(\"âœ… Moved to Google Drive at:\", drive_dest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_DNg1QHzqy9",
        "outputId": "507c01b3-f891-406f-aea3-3192eda47ce8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Moved to Google Drive at: /content/drive/MyDrive/GALLMIDGE2\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}